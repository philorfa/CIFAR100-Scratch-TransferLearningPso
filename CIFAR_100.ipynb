{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-100",
      "provenance": [],
      "collapsed_sections": [
        "JBiFc6QJy2ZT",
        "4au472lwW38g",
        "xjJqPkChW7vu",
        "HVibObQ9pfGa",
        "_5nts3LRCJzA",
        "eXBDuNP-hBVP"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RpvvmqcWzga"
      },
      "source": [
        "Δουλεύουμε στο Google Colab και η GPU που χρησιμοποιούμε φαίνεται παρακάτω "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_3xxCL2W9Ar",
        "outputId": "e0ac00a0-6d35-4768-fc12-d64d0083ee81"
      },
      "source": [
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  4 19:47:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpnEVMCYYlnD"
      },
      "source": [
        "# Βαθιά μάθηση στο CIFAR-100 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TeSvd-gx4Xm"
      },
      "source": [
        "Στο σημείο αυτό θα αναλύσουμε τη στρατηγική που θα ακολουθήσουμε έτσι ώστε να βελτιώσουμε την επίδοση στο πρόβλημα ταξινόμησης CIFAR-100.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Δημιουργία TFrecords\r\n",
        "*   Prefetch\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**1ο Μέρος**\r\n",
        "\r\n",
        "*   Transfer Learning σε 3 προεκπαιδευμένα μοντέλα που έχουν λίγες παραμέτρους (DenseNet121, ResNet50, Xceptin)\r\n",
        "*   Particle Swarm Optimization για παρατήρηση αρχιτεκτονικής που εμφανίζει τα καλύτερα αποτελέσματα\r\n",
        "*   Έχοντας σαν δεδομένα τις βέλτιστες αρχιτεκτονικές που αποφάνθηκε ο PSO αλγόριθμος, όπως επίσης και τις αντίστοιχες τιμές των μετρικών, θα προσπαθήσουμε να βελτιστοποιήσουμε το VGG 16 (Η αρχική μας σκέψη ήταν για το NASNetLarge αλλά υπάρχει [\"πρόβλημα\"](https://github.com/keras-team/keras-applications/issues/78) στην κατασκευή του που επιτρέπει μόνο (331,331,3) μέγεθος εικόνων και δεν επιθυμούσαμε να κάνουμε τόσο μεγάλες αλλαγές στο αρχικό (31,31,3) μέγεθος).\r\n",
        "\r\n",
        "**2ο Μέρος**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Μέσα απο μια παρόμοια σειρά πειραμάτων που πραγματοποιήσαμε στο 1ο Μέρος θα κατασκευάσουμε \"from scratch\" ένα DCNN που να επιτυγχάνει καλή απόδοση στο πρόβλημα ταξινόμησης.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STXQMBuN3nZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "92b12a2b-9575-42d5-80ba-08b0a9b8ee81"
      },
      "source": [
        "#@title\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "#@title\n",
        "!pip install --upgrade pyswarm\n",
        "!pip install pymc3\n",
        "!pip install --upgrade pactools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pyswarm import pso\n",
        "from os import path\n",
        "import os\n",
        "import requests\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import numpy\n",
        "import sys\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from numpy import array\n",
        "from numpy.random import choice\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import statistics\n",
        "import pandas\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import logging\n",
        "from pymc3 import *\n",
        "import pymc3 as pm\n",
        "from functools import reduce\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import geopy.distance\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from theano import shared\n",
        "from sklearn import preprocessing\n",
        "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "#TESNORFOW\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models\n",
        "#KERAS LIBRARIES\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout , Flatten,BatchNormalization,Conv2D,MaxPooling2D, Activation,LSTM,Embedding,Input,GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras import backend \n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading https://files.pythonhosted.org/packages/79/1e/254c108b5e65c65d57a83a9a448405ea8b6a6c5c10dada8bcab4e9d9a831/pyswarm-0.6.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarm) (1.19.5)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-cp37-none-any.whl size=4481 sha256=ffad7ca8bd3a34bf083ae9677b9428ab6c3b829fb72c513aebf73820cebf2b4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/c5/f6/b33b9ac00040cb95c1f00af982a4197334a672d6de43f4699f\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n",
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pymc3) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from pymc3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from pymc3) (1.19.5)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pymc3) (2.10.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pymc3) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.7/dist-packages (from pymc3) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pymc3) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pymc3) (2018.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano>=1.0.4->pymc3) (1.15.0)\n",
            "Collecting pactools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/14/4c4eba6e54408e536be27b9891cea68ea391d7d190936593aa71e5c6405e/pactools-0.3.1-py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from pactools) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from pactools) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pactools) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from pactools) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from pactools) (1.4.1)\n",
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/a8/7d8a10345082d4807907a268016b52dfa869b0c412cd84aa1d1de86e1e39/mne-0.22.0-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->pactools) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pactools) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pactools) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pactools) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pactools) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pactools) (1.3.1)\n",
            "Installing collected packages: mne, pactools\n",
            "Successfully installed mne-0.22.0 pactools-0.3.1\n",
            "Running on PyMC3 v3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBiFc6QJy2ZT"
      },
      "source": [
        "## Ανάγνωση Δεδεομένων και έτοιμες συναρτήσεις"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "X9X4_gV0sJcO"
      },
      "source": [
        "#@title\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "\tplt.figure(figsize=(8, 8))\n",
        "\tplt.suptitle('Training Curves')\n",
        "\t# plot loss\n",
        "\tplt.subplot(211)\n",
        "\tplt.title('Cross Entropy Loss')\n",
        "\tplt.plot(history.history['loss'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_loss'], color='orange', label='val')\n",
        "\tplt.legend(loc='upper right')\n",
        "\t# plot accuracy\n",
        "\tplt.subplot(212)\n",
        "\tplt.title('Classification Accuracy')\n",
        "\tplt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_accuracy'], color='orange', label='val')\n",
        "\tplt.legend(loc='lower right')\n",
        "\treturn plt\n",
        " \n",
        "# print test set evaluation metrics\n",
        "def model_evaluation(model, evaluation_steps):\n",
        "\tprint('\\nTest set evaluation metrics')\n",
        "\tloss0,accuracy0 = model.evaluate(test_ds, steps = evaluation_steps)\n",
        "\tprint(\"loss: {:.2f}\".format(loss0))\n",
        "\tprint(\"accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "def model_report(model, history, evaluation_steps = 10):\n",
        "\tplt = summarize_diagnostics(history)\n",
        "\tplt.show()\n",
        "\tmodel_evaluation(model, evaluation_steps)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD3yLgcQ6HJT",
        "cellView": "form"
      },
      "source": [
        "#@title\r\n",
        "# helper functions\r\n",
        "\r\n",
        "# select from from_list elements with index in index_list\r\n",
        "def select_from_list(from_list, index_list):\r\n",
        "  filtered_list= [from_list[i] for i in index_list]\r\n",
        "  return(filtered_list)\r\n",
        "\r\n",
        "# append in filtered_list the index of each element of unfilterd_list if it exists in in target_list\r\n",
        "def get_ds_index(unfiliterd_list, target_list):\r\n",
        "  index = 0\r\n",
        "  filtered_list=[]\r\n",
        "  for i_ in unfiliterd_list:\r\n",
        "    if i_[0] in target_list:\r\n",
        "      filtered_list.append(index)\r\n",
        "    index += 1\r\n",
        "  return(filtered_list)\r\n",
        "\r\n",
        "# select a url for a unique subset of CIFAR-100 with 20, 40, 60, or 80 classes\r\n",
        "def select_classes_number(classes_number = 20):\r\n",
        "  cifar100_20_classes_url = \"https://pastebin.com/raw/nzE1n98V\"\r\n",
        "  cifar100_40_classes_url = \"https://pastebin.com/raw/zGX4mCNP\"\r\n",
        "  cifar100_60_classes_url = \"https://pastebin.com/raw/nsDTd3Qn\"\r\n",
        "  cifar100_80_classes_url = \"https://pastebin.com/raw/SNbXz700\"\r\n",
        "  if classes_number == 20:\r\n",
        "    return cifar100_20_classes_url\r\n",
        "  elif classes_number == 40:\r\n",
        "    return cifar100_40_classes_url\r\n",
        "  elif classes_number == 60:\r\n",
        "    return cifar100_60_classes_url\r\n",
        "  elif classes_number == 80:\r\n",
        "    return cifar100_80_classes_url\r\n",
        "  else:\r\n",
        "    return -1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzwKdeyj73tt",
        "outputId": "d6c8d515-e014-467c-ff0e-6d45c2298fee"
      },
      "source": [
        "# load the entire dataset\r\n",
        "(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXK8XWYb7-8o"
      },
      "source": [
        "# REPLACE WITH YOUR C NUMBER\r\n",
        "team_sead = 195"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp6erfQE8CLA"
      },
      "source": [
        "# select the number of classes\r\n",
        "cifar100_classes_url = select_classes_number(80)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiFFEajy8HcE",
        "cellView": "form"
      },
      "source": [
        "#@title\r\n",
        "my_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)\r\n",
        "CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]\r\n",
        "\r\n",
        "our_index = my_classes.iloc[team_sead,:].values.tolist()\r\n",
        "our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)\r\n",
        "train_index = get_ds_index(y_train_all, our_index)\r\n",
        "test_index = get_ds_index(y_test_all, our_index)\r\n",
        "\r\n",
        "x_train_ds = np.asarray(select_from_list(x_train_all, train_index))\r\n",
        "y_train_ds = np.asarray(select_from_list(y_train_all, train_index))\r\n",
        "x_test_ds = np.asarray(select_from_list(x_test_all, test_index))\r\n",
        "y_test_ds = np.asarray(select_from_list(y_test_all, test_index))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ctt7aDy8M0Q",
        "outputId": "2f5ba631-3ce0-4a81-896e-275c886390d1"
      },
      "source": [
        "# print our classes\r\n",
        "print(our_classes)\r\n",
        "CLASSES_NUM=len(our_classes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['apple', ' aquarium_fish', ' baby', ' beaver', ' bed', ' bee', ' beetle', ' bottle', ' bowl', ' boy', ' bridge', ' bus', ' butterfly', ' camel', ' can', ' castle', ' cattle', ' chair', ' chimpanzee', ' clock', ' cloud', ' couch', ' crab', ' crocodile', ' cup', ' dinosaur', ' dolphin', ' elephant', ' forest', ' fox', ' girl', ' hamster', ' house', ' kangaroo', ' keyboard', ' leopard', ' lion', ' lizard', ' lobster', ' maple_tree', ' mountain', ' mouse', ' mushroom', ' oak_tree', ' orange', ' orchid', ' palm_tree', ' pear', ' pickup_truck', ' pine_tree', ' plain', ' poppy', ' porcupine', ' possum', ' rabbit', ' raccoon', ' ray', ' rocket', ' rose', ' sea', ' seal', ' skunk', ' snail', ' snake', ' spider', ' squirrel', ' streetcar', ' sunflower', ' sweet_pepper', ' table', ' tank', ' telephone', ' television', ' tiger', ' tractor', ' train', ' tulip', ' wardrobe', ' willow_tree', ' woman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c7frl60Y8PTC",
        "cellView": "form",
        "outputId": "ed12e10a-0e5b-458f-f05d-2d32b34a3aaf"
      },
      "source": [
        "#@title\r\n",
        "# get (train) dataset dimensions\r\n",
        "data_size, img_rows, img_cols, img_channels = x_train_ds.shape\r\n",
        "\r\n",
        "# set validation set percentage (wrt the training set size)\r\n",
        "validation_percentage = 0.15\r\n",
        "val_size = round(validation_percentage * data_size)\r\n",
        "\r\n",
        "# Reserve val_size samples for validation and normalize all values\r\n",
        "x_val = x_train_ds[-val_size:]/255\r\n",
        "y_val = y_train_ds[-val_size:]\r\n",
        "x_train = x_train_ds[:-val_size]/255\r\n",
        "y_train = y_train_ds[:-val_size]\r\n",
        "x_test = x_test_ds/255\r\n",
        "y_test = y_test_ds\r\n",
        "\r\n",
        "print(len(x_val))\r\n",
        "\r\n",
        "# summarize loaded dataset\r\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\r\n",
        "print('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))\r\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\r\n",
        "\r\n",
        "# get class label from class index\r\n",
        "def class_label_from_index(fine_category):\r\n",
        "  return(CIFAR100_LABELS_LIST[fine_category.item(0)])\r\n",
        "\r\n",
        "# plot first few images\r\n",
        "plt.figure(figsize=(6, 6))\r\n",
        "for i in range(9):\r\n",
        "\t# define subplot\r\n",
        "  plt.subplot(330 + 1 + i).set_title(class_label_from_index(y_train[i]))\r\n",
        "\t# plot raw pixel data\r\n",
        "  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\r\n",
        "  #show the figure\r\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "Train: X=(34000, 32, 32, 3), y=(34000, 1)\n",
            "Validation: X=(6000, 32, 32, 3), y=(6000, 1)\n",
            "Test: X=(8000, 32, 32, 3), y=(8000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z47Ug_j6Iu7L"
      },
      "source": [
        "## TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4au472lwW38g"
      },
      "source": [
        "### Write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3rtpij4M5BD"
      },
      "source": [
        "Στο στάδιο αυτό θα γίνει ο μετασχηματισμός του μεγέθους. Συνεπώς πρέπει να ορίσουμε ποια pretrained μοντέλα θα χρησιμοποιήσουμε. Αυτά είναι τα εξής :\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   DenseNet121 (min shape (32,32,3))\r\n",
        "*   Xception (min shape (71,71,3))\r\n",
        "*   ResNet152 (min shape (32,32,3))\r\n",
        "*   InceptionResNetV2(min shape(75,75,3))\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlFwhYBKOfFA"
      },
      "source": [
        "TARGET_SIZE_1 = (71,71,3)\r\n",
        "TARGET_SIZE_2 = (32,32,3)\r\n",
        "TARGET_SIZE_3 = (75,75,3)\r\n",
        "directory='/content/drive/My Drive/tfRecords'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FePZFuY7b_Ab",
        "outputId": "20109d5c-7755-4d7d-b894-8d95605ae7cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSEZYEsFLwT6"
      },
      "source": [
        "def _bytes_feature(value):\r\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
        "    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.\r\n",
        "    if isinstance(value, type(tf.constant(0))):\r\n",
        "        value = value.numpy() \r\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
        "\r\n",
        "def _int64_feature(value):\r\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuGvPVoNL1ZK"
      },
      "source": [
        "def serialize_example(image, label, image_shape):\r\n",
        "    feature = {\r\n",
        "        \"image\": _bytes_feature(image),\r\n",
        "        \"label\": _int64_feature(label),\r\n",
        "        'height': _int64_feature(image_shape[0]),\r\n",
        "        'width': _int64_feature(image_shape[1]),\r\n",
        "        'depth': _int64_feature(image_shape[2]),\r\n",
        "    }\r\n",
        "\r\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\r\n",
        "    return example_proto.SerializeToString()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAXko0xiL2cf"
      },
      "source": [
        "def write_TFR(tfrecord_dir, x, y, target_size):\r\n",
        "  with tf.io.TFRecordWriter(tfrecord_dir) as writer:\r\n",
        "      for img_array, label in zip(x, y):\r\n",
        "                \r\n",
        "          img_array = tf.image.resize(img_array, (target_size[0], target_size[1]))\r\n",
        "          \r\n",
        "          img_bytes = tf.io.serialize_tensor(img_array)\r\n",
        "          image_shape = img_array.shape\r\n",
        "          \r\n",
        "          example = serialize_example(img_bytes, label, image_shape)\r\n",
        "          writer.write(example)\r\n",
        "  return None"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uifCrvKNSFlg"
      },
      "source": [
        "write_TFR(directory + \"train32.tfrecords\", x_train, y_train,TARGET_SIZE_2)\r\n",
        "write_TFR(directory + \"validation32.tfrecords\", x_val, y_val,TARGET_SIZE_2)\r\n",
        "write_TFR(directory + \"test32.tfrecords\", x_test, y_test,TARGET_SIZE_2)\r\n",
        "\r\n",
        "write_TFR(directory + \"train71.tfrecords\", x_train, y_train,TARGET_SIZE_1)\r\n",
        "write_TFR(directory + \"validation71.tfrecords\", x_val, y_val,TARGET_SIZE_1)\r\n",
        "write_TFR(directory + \"test71.tfrecords\", x_test, y_test,TARGET_SIZE_1)\r\n",
        "\r\n",
        "write_TFR(directory + \"train75.tfrecords\", x_train, y_train,TARGET_SIZE_3)\r\n",
        "write_TFR(directory + \"validation75.tfrecords\", x_val, y_val,TARGET_SIZE_3)\r\n",
        "write_TFR(directory + \"test75.tfrecords\", x_test, y_test,TARGET_SIZE_3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjJqPkChW7vu"
      },
      "source": [
        "### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCbNVmm0W-i_"
      },
      "source": [
        "def _parse_function1(example_proto):\r\n",
        "    feature_description = {\r\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'height': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'depth': tf.io.FixedLenFeature([], tf.int64)\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\r\n",
        "\r\n",
        "    label = example[\"label\"]\r\n",
        "    image_shape = (71,71,3)\r\n",
        "\r\n",
        "    image = tf.io.parse_tensor(example[\"image\"], float)\r\n",
        "    image = tf.reshape(image, image_shape)\r\n",
        "\r\n",
        "\r\n",
        "    return  image , [label]\r\n",
        "\r\n",
        "def _parse_function2(example_proto):\r\n",
        "    feature_description = {\r\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'height': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'depth': tf.io.FixedLenFeature([], tf.int64)\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\r\n",
        "\r\n",
        "    label = example[\"label\"]\r\n",
        "    image_shape = (32,32,3)\r\n",
        "\r\n",
        "    image = tf.io.parse_tensor(example[\"image\"], float)\r\n",
        "    image = tf.reshape(image, image_shape)\r\n",
        "\r\n",
        "\r\n",
        "    return  (image , [label])\r\n",
        "\r\n",
        "def _parse_function3(example_proto):\r\n",
        "    feature_description = {\r\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'height': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "        'depth': tf.io.FixedLenFeature([], tf.int64)\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\r\n",
        "\r\n",
        "    label = example[\"label\"]\r\n",
        "    image_shape = (75,75,3)\r\n",
        "\r\n",
        "    image = tf.io.parse_tensor(example[\"image\"], float)\r\n",
        "    image = tf.reshape(image, image_shape)\r\n",
        "\r\n",
        "\r\n",
        "    return  (image , [label])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3G2anheXHm5"
      },
      "source": [
        "def read_dataset1(file):\r\n",
        "    dataset = tf.data.TFRecordDataset(file)\r\n",
        "    return dataset.map(_parse_function1)\r\n",
        "\r\n",
        "def read_dataset2(file):\r\n",
        "    dataset = tf.data.TFRecordDataset(file)\r\n",
        "    return dataset.map(_parse_function2)\r\n",
        "\r\n",
        "def read_dataset3(file):\r\n",
        "    dataset = tf.data.TFRecordDataset(file)\r\n",
        "    return dataset.map(_parse_function3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emYwTVDFXOph"
      },
      "source": [
        "train_71 = read_dataset1(directory + \"train71.tfrecords\")\r\n",
        "validation_71 = read_dataset1(directory + \"validation71.tfrecords\")\r\n",
        "test_71= read_dataset1(directory + \"test71.tfrecords\")\r\n",
        "\r\n",
        "\r\n",
        "train_32 = read_dataset2(directory + \"train32.tfrecords\")\r\n",
        "validation_32 = read_dataset2(directory + \"validation32.tfrecords\")\r\n",
        "test_32 = read_dataset2(directory + \"test32.tfrecords\")\r\n",
        "\r\n",
        "train_75 = read_dataset3(directory + \"train75.tfrecords\")\r\n",
        "validation_75 = read_dataset3(directory + \"validation75.tfrecords\")\r\n",
        "test_75 = read_dataset3(directory + \"test75.tfrecords\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVibObQ9pfGa"
      },
      "source": [
        "## PreFetch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yjwykDvhWMy"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\r\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\r\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06WUvvkpk5s"
      },
      "source": [
        "BATCH_SIZE = [256,128,64]\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # https://www.tensorflow.org/guide/data_performance\r\n",
        "\r\n",
        "def _input_fn(ds, BATCH_SIZE):\r\n",
        "  ds = ds.shuffle(buffer_size=data_size)\r\n",
        "  ds = ds.repeat()\r\n",
        "  ds = ds.batch(BATCH_SIZE)\r\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\r\n",
        "  #ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\r\n",
        "  return ds"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-FCfyLcp6HN"
      },
      "source": [
        "train_32_b64 = _input_fn(train_32, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "validation_32_b64 =_input_fn(validation_32, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "test_32_b64 =_input_fn(test_32, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_32_b128 = _input_fn(train_32, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "validation_32_b128 =_input_fn(validation_32, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "test_32_b128 =_input_fn(test_32, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_32_b256 = _input_fn(train_32, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "validation_32_b256 =_input_fn(validation_32, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "test_32_b256 =_input_fn(test_32, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_71_b64 = _input_fn(train_71, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "validation_71_b64 =_input_fn(validation_71, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "test_71_b64 =_input_fn(test_71, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_71_b128 = _input_fn(train_71, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "validation_71_b128 =_input_fn(validation_71, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "test_71_b128 =_input_fn(test_71, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_71_b256 = _input_fn(train_71, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "validation_71_b256 =_input_fn(validation_71, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "test_71_b256 =_input_fn(test_71, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_75_b64 = _input_fn(train_75, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "validation_75_b64 =_input_fn(validation_75, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "test_75_b64 =_input_fn(test_75, BATCH_SIZE[2]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_75_b128 = _input_fn(train_75, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "validation_75_b128 =_input_fn(validation_75, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "test_75_b128 =_input_fn(test_75, BATCH_SIZE[1]) #PrefetchDataset object\r\n",
        "\r\n",
        "train_75_b256 = _input_fn(train_75, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "validation_75_b256 =_input_fn(validation_75, BATCH_SIZE[0]) #PrefetchDataset object\r\n",
        "test_75_b256 =_input_fn(test_75, BATCH_SIZE[0]) #PrefetchDataset object"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc38O5pgtZm3"
      },
      "source": [
        "## Transfer Learning - Setting Particle Swarm Optimization Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dykYFMDT1g7H"
      },
      "source": [
        "Οι υπερπαράμετροι που θέτουμε στον αλγόριθμο και εκφράζονται μέσα από το διάνυσμα x είναι οι εξής:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Αριθμός από Layers που θα είναι trainable\r\n",
        "*   Ύστερα από την έξοδο του pretrained μοντέλου μας πρέπει να φέρουμε τον τένσορα στις κατάλληλες διάστάσεις , χρησιμοποιούμε είτε Flatten layer είτε GlobalAveragePooling2D\r\n",
        "*   Πόσα Dense layers θα χρησιμοποιήσουμε πριν το τελικό στρώμα ταξινόμησης.\r\n",
        "*   Dropout1 rate\r\n",
        "*   Dropout2 rate\r\n",
        "*   Τιμή του Learning rate\r\n",
        "*   Επιλογή Optimizer , Adam ή SGD.\r\n",
        "*   Batch Size\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "O αλγόριθμος προσπαθέι να ελαχιστοποιήσει το 1/(1+accuracy).Δηλαδή να μεγιστοποιήσει το accuracy. Τέλος για λόγους χρονικής πολυπλοκότητας αλλά και για να αποφύγουμε το overfitting χρησιμοποιούμε Early Stopping με patience=4 στην μετρική validation_accuracy\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdcvw0YeteyU"
      },
      "source": [
        "EarlyStopper = EarlyStopping(patience=6, monitor='val_accuracy', mode='max')\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,patience=2, min_lr=0.000001)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5nts3LRCJzA"
      },
      "source": [
        "### DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qlkye-kK842"
      },
      "source": [
        "count=0\r\n",
        "max=0\r\n",
        "lb=[0,0,0,0,0,0.001,0,0]\r\n",
        "ub=[120,1,3,0.65,0.65,0.2,1,3]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrE0WVRhCJJB"
      },
      "source": [
        "def create_model_dense(x):\r\n",
        "  print(x[0],x[1],x[2],x[3],x[4],x[5],x[6])\r\n",
        "  IMG_SHAPE1=(32,32,3) \r\n",
        "\r\n",
        "  dense=tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE1,\r\n",
        "                                               include_top=False,\r\n",
        "                                               weights='imagenet') \r\n",
        "  tempre=dense\r\n",
        "  for layer in tempre.layers[:(-1)*int(round(x[0]))]:\r\n",
        "    layer.trainable = False\r\n",
        "  \r\n",
        "  model = tf.keras.Sequential()\r\n",
        "  model.add(tempre)\r\n",
        "  if (int(round(x[1]))):\r\n",
        "    model.add(keras.layers.Flatten())\r\n",
        "  else:\r\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\r\n",
        "  \r\n",
        "  if (int(round(x[2]))==3):\r\n",
        "    model.add(keras.layers.Dense(2048, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(0.5))\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==2):\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==1):\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "\r\n",
        "\r\n",
        "  for layer in model.layers:\r\n",
        "    print(layer, layer.trainable)\r\n",
        "  model.add(keras.layers.Dense(100,activation=\"softmax\"))\r\n",
        "  if x[5]< 0.003:\r\n",
        "    learning_rate = 0.0000005\r\n",
        "  elif x[5]< 0.0075:\r\n",
        "    learning_rate = 0.000001\r\n",
        "  elif x[5]< 0.015:\r\n",
        "    learning_rate = 0.000005\r\n",
        "  elif x[5]< 0.035:\r\n",
        "    learning_rate = 0.00001\r\n",
        "  elif x[5]< 0.075:\r\n",
        "    learning_rate = 0.00005\r\n",
        "  elif x[5]< 0.125:\r\n",
        "    learning_rate = 0.0001\r\n",
        "  elif x[5]< 0.175:\r\n",
        "    learning_rate = 0.0005\r\n",
        "  else:\r\n",
        "    learning_rate = 0.001\r\n",
        "  \r\n",
        "  if (x[6]<0.5):\r\n",
        "    opt = keras.optimizers.SGD(learning_rate=learning_rate)\r\n",
        "  else:\r\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVgEH4TsLDfd"
      },
      "source": [
        "def apple(x):\r\n",
        "  global max\r\n",
        "  model = create_model_dense(x)\r\n",
        "  if (x[7]<1):\r\n",
        "    model.fit(train_32_b64, epochs=30, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_32_b64,validation_steps=94,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b64, verbose=1,steps=128)\r\n",
        "  elif (x[7]<2):\r\n",
        "    model.fit(train_32_b128, epochs=30, batch_size=128,steps_per_epoch=264 ,verbose=1,validation_data=validation_32_b128,validation_steps=47,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b128, verbose=1,steps=64)\r\n",
        "  else:\r\n",
        "    model.fit(train_32_b256, epochs=30, batch_size=256, steps_per_epoch=132, verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "  if acc>max:\r\n",
        "    global count \r\n",
        "    max=acc\r\n",
        "    count = count+1\r\n",
        "    print(\"Model N.\",count,\"  Accuracy = \",acc,\"Loss = \",loss, \"parameters = \",x,\"\\n\")\r\n",
        "  return (1/(1+acc))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io63PutpOnf0",
        "outputId": "45235c3b-9951-4c1d-ca1d-6e1c85f547ad"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6939408806941687 0.7297930790001836 2.304861396154323 0.3106119444085365 0.6250729614752298 0.19144754730253377 0.647783277249397\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791be3c90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9a2006db90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9a2006dd90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce35b310> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99ce374c90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce361050> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 20s 44ms/step - loss: 2.2284 - accuracy: 0.3751 - val_loss: 1.2668 - val_accuracy: 0.5997\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 10s 36ms/step - loss: 1.0360 - accuracy: 0.6599 - val_loss: 1.2433 - val_accuracy: 0.6253\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 10s 36ms/step - loss: 0.6631 - accuracy: 0.7769 - val_loss: 1.3639 - val_accuracy: 0.6262\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 10s 37ms/step - loss: 0.4129 - accuracy: 0.8606 - val_loss: 1.5660 - val_accuracy: 0.6303\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 10s 37ms/step - loss: 0.2714 - accuracy: 0.9093 - val_loss: 1.6943 - val_accuracy: 0.6315\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 10s 36ms/step - loss: 0.2004 - accuracy: 0.9335 - val_loss: 1.7800 - val_accuracy: 0.6293\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 10s 37ms/step - loss: 0.1658 - accuracy: 0.9462 - val_loss: 1.9346 - val_accuracy: 0.6307\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 9s 36ms/step - loss: 0.1215 - accuracy: 0.9594 - val_loss: 2.0445 - val_accuracy: 0.6293\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 9s 36ms/step - loss: 0.1168 - accuracy: 0.9624 - val_loss: 2.1246 - val_accuracy: 0.6213\n",
            "64/64 [==============================] - 2s 27ms/step - loss: 2.2086 - accuracy: 0.6083\n",
            "Model N. 1   Accuracy =  0.6082763671875 Loss =  2.2086143493652344 parameters =  [3.69394088 0.72979308 2.3048614  0.31061194 0.62507296 0.19144755\n",
            " 0.64778328 1.7858305 ] \n",
            "\n",
            "60.49171067398821 0.4799282773733917 0.5191188773732847 0.5506440518475813 0.043283260573121325 0.022648011945331715 0.6376536396865014\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97910236d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e2fdf10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e304850> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e287f50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 28s 39ms/step - loss: 5.1850 - accuracy: 0.0410 - val_loss: 2.8676 - val_accuracy: 0.2706\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 18s 35ms/step - loss: 3.1660 - accuracy: 0.2066 - val_loss: 2.2176 - val_accuracy: 0.3930\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 2.5078 - accuracy: 0.3077 - val_loss: 1.9345 - val_accuracy: 0.4446\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 2.1341 - accuracy: 0.3783 - val_loss: 1.7772 - val_accuracy: 0.4771\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.9231 - accuracy: 0.4329 - val_loss: 1.6723 - val_accuracy: 0.5042\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.7460 - accuracy: 0.4759 - val_loss: 1.5958 - val_accuracy: 0.5198\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.6193 - accuracy: 0.5099 - val_loss: 1.5341 - val_accuracy: 0.5321\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.4989 - accuracy: 0.5378 - val_loss: 1.4857 - val_accuracy: 0.5440\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.3852 - accuracy: 0.5688 - val_loss: 1.4426 - val_accuracy: 0.5514\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.2884 - accuracy: 0.5938 - val_loss: 1.4085 - val_accuracy: 0.5603\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.2081 - accuracy: 0.6178 - val_loss: 1.3822 - val_accuracy: 0.5643\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.1373 - accuracy: 0.6374 - val_loss: 1.3569 - val_accuracy: 0.5705\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.0695 - accuracy: 0.6571 - val_loss: 1.3410 - val_accuracy: 0.5715\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.9987 - accuracy: 0.6821 - val_loss: 1.3241 - val_accuracy: 0.5795\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.9375 - accuracy: 0.7013 - val_loss: 1.3074 - val_accuracy: 0.5828\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.8861 - accuracy: 0.7162 - val_loss: 1.2960 - val_accuracy: 0.5859\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.8224 - accuracy: 0.7362 - val_loss: 1.2882 - val_accuracy: 0.5924\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 19s 37ms/step - loss: 0.7786 - accuracy: 0.7517 - val_loss: 1.2818 - val_accuracy: 0.5944\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.7155 - accuracy: 0.7695 - val_loss: 1.2791 - val_accuracy: 0.5981\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.6690 - accuracy: 0.7859 - val_loss: 1.2749 - val_accuracy: 0.6052\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.6316 - accuracy: 0.7981 - val_loss: 1.2734 - val_accuracy: 0.6061\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.5822 - accuracy: 0.8158 - val_loss: 1.2779 - val_accuracy: 0.6046\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.5350 - accuracy: 0.8317 - val_loss: 1.2828 - val_accuracy: 0.6089\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.4952 - accuracy: 0.8435 - val_loss: 1.2885 - val_accuracy: 0.6120\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 19s 37ms/step - loss: 0.4668 - accuracy: 0.8526 - val_loss: 1.2904 - val_accuracy: 0.6132\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.4224 - accuracy: 0.8674 - val_loss: 1.3034 - val_accuracy: 0.6149\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.3819 - accuracy: 0.8844 - val_loss: 1.3143 - val_accuracy: 0.6193\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.3555 - accuracy: 0.8923 - val_loss: 1.3290 - val_accuracy: 0.6242\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.3230 - accuracy: 0.9031 - val_loss: 1.3424 - val_accuracy: 0.6175\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.2955 - accuracy: 0.9118 - val_loss: 1.3511 - val_accuracy: 0.6243\n",
            "128/128 [==============================] - 4s 23ms/step - loss: 1.3910 - accuracy: 0.6188\n",
            "Model N. 2   Accuracy =  0.6187744140625 Loss =  1.3910167217254639 parameters =  [6.04917107e+01 4.79928277e-01 5.19118877e-01 5.50644052e-01\n",
            " 4.32832606e-02 2.26480119e-02 6.37653640e-01 7.25559558e-01] \n",
            "\n",
            "84.67155995324887 0.9489282168441422 2.0421270715762088 0.10015114447509597 0.14802156822378612 0.10438037673865588 0.11337407280056722\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97916f3050> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b6cf990> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97929c7fd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979101a510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791084650> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97929c9110> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 17s 71ms/step - loss: 5.1737 - accuracy: 0.0027 - val_loss: 4.7030 - val_accuracy: 6.5104e-04\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 8s 57ms/step - loss: 4.9247 - accuracy: 0.0081 - val_loss: 4.5696 - val_accuracy: 0.0146\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 8s 57ms/step - loss: 4.6916 - accuracy: 0.0157 - val_loss: 4.4304 - val_accuracy: 0.0311\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 8s 57ms/step - loss: 4.5005 - accuracy: 0.0266 - val_loss: 4.2701 - val_accuracy: 0.0470\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 4.3225 - accuracy: 0.0454 - val_loss: 4.1126 - val_accuracy: 0.0675\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 4.1647 - accuracy: 0.0617 - val_loss: 3.9646 - val_accuracy: 0.0942\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 7s 57ms/step - loss: 4.0093 - accuracy: 0.0796 - val_loss: 3.8246 - val_accuracy: 0.1167\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 7s 57ms/step - loss: 3.8795 - accuracy: 0.0968 - val_loss: 3.6970 - val_accuracy: 0.1405\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 3.7477 - accuracy: 0.1138 - val_loss: 3.5799 - val_accuracy: 0.1556\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 3.6339 - accuracy: 0.1334 - val_loss: 3.4681 - val_accuracy: 0.1694\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 3.5321 - accuracy: 0.1429 - val_loss: 3.3672 - val_accuracy: 0.1862\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 7s 57ms/step - loss: 3.4257 - accuracy: 0.1606 - val_loss: 3.2765 - val_accuracy: 0.2048\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 3.3177 - accuracy: 0.1746 - val_loss: 3.1883 - val_accuracy: 0.2205\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 3.2424 - accuracy: 0.1861 - val_loss: 3.1070 - val_accuracy: 0.2305\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 7s 56ms/step - loss: 3.1651 - accuracy: 0.1974 - val_loss: 3.0279 - val_accuracy: 0.2425\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 8s 57ms/step - loss: 3.0745 - accuracy: 0.2138 - val_loss: 2.9588 - val_accuracy: 0.2620\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 7s 57ms/step - loss: 3.0073 - accuracy: 0.2225 - val_loss: 2.8935 - val_accuracy: 0.2795\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 2.9425 - accuracy: 0.2354 - val_loss: 2.8308 - val_accuracy: 0.2892\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 2.8815 - accuracy: 0.2460 - val_loss: 2.7701 - val_accuracy: 0.3001\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 2.8176 - accuracy: 0.2522 - val_loss: 2.7161 - val_accuracy: 0.3132\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 7s 56ms/step - loss: 2.7599 - accuracy: 0.2654 - val_loss: 2.6640 - val_accuracy: 0.3252\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 2.7184 - accuracy: 0.2764 - val_loss: 2.6175 - val_accuracy: 0.3306\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 2.6690 - accuracy: 0.2779 - val_loss: 2.5690 - val_accuracy: 0.3384\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 2.6168 - accuracy: 0.2891 - val_loss: 2.5249 - val_accuracy: 0.3483\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 2.5758 - accuracy: 0.2996 - val_loss: 2.4885 - val_accuracy: 0.3527\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 2.5228 - accuracy: 0.3128 - val_loss: 2.4469 - val_accuracy: 0.3564\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 2.4785 - accuracy: 0.3185 - val_loss: 2.4119 - val_accuracy: 0.3623\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 2.4579 - accuracy: 0.3174 - val_loss: 2.3797 - val_accuracy: 0.3691\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 7s 52ms/step - loss: 2.4173 - accuracy: 0.3239 - val_loss: 2.3472 - val_accuracy: 0.3760\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 2.3776 - accuracy: 0.3336 - val_loss: 2.3169 - val_accuracy: 0.3813\n",
            "32/32 [==============================] - 2s 35ms/step - loss: 2.3606 - accuracy: 0.3539\n",
            "106.32973871384682 0.8259859033117485 1.4849942212360923 0.5279752907094488 0.4836794718390415 0.19509136881124287 0.2122810640779128\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b6cef50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792a07810> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791027d90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979161c110> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 21s 52ms/step - loss: 4.9544 - accuracy: 0.0603 - val_loss: 2.8574 - val_accuracy: 0.3411\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.7072 - accuracy: 0.2936 - val_loss: 1.9718 - val_accuracy: 0.4420\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 2.0945 - accuracy: 0.4007 - val_loss: 1.7304 - val_accuracy: 0.4809\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.8091 - accuracy: 0.4645 - val_loss: 1.6109 - val_accuracy: 0.5125\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.6258 - accuracy: 0.5081 - val_loss: 1.5344 - val_accuracy: 0.5274\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 1.4731 - accuracy: 0.5463 - val_loss: 1.4789 - val_accuracy: 0.5397\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.3750 - accuracy: 0.5718 - val_loss: 1.4389 - val_accuracy: 0.5497\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.2747 - accuracy: 0.6029 - val_loss: 1.4035 - val_accuracy: 0.5608\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 1.1821 - accuracy: 0.6311 - val_loss: 1.3751 - val_accuracy: 0.5713\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 1.1094 - accuracy: 0.6490 - val_loss: 1.3537 - val_accuracy: 0.5795\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 1.0363 - accuracy: 0.6716 - val_loss: 1.3375 - val_accuracy: 0.5838\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.9857 - accuracy: 0.6897 - val_loss: 1.3197 - val_accuracy: 0.5886\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.9272 - accuracy: 0.7094 - val_loss: 1.3065 - val_accuracy: 0.5906\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.8711 - accuracy: 0.7233 - val_loss: 1.2941 - val_accuracy: 0.5994\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.8260 - accuracy: 0.7379 - val_loss: 1.2884 - val_accuracy: 0.6056\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.7756 - accuracy: 0.7568 - val_loss: 1.2811 - val_accuracy: 0.6080\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.7343 - accuracy: 0.7673 - val_loss: 1.2775 - val_accuracy: 0.6062\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 0.6967 - accuracy: 0.7776 - val_loss: 1.2762 - val_accuracy: 0.6092\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.6630 - accuracy: 0.7907 - val_loss: 1.2743 - val_accuracy: 0.6130\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.6160 - accuracy: 0.8069 - val_loss: 1.2763 - val_accuracy: 0.6112\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.5812 - accuracy: 0.8199 - val_loss: 1.2741 - val_accuracy: 0.6154\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.5459 - accuracy: 0.8301 - val_loss: 1.2779 - val_accuracy: 0.6184\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.5190 - accuracy: 0.8398 - val_loss: 1.2789 - val_accuracy: 0.6165\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.5016 - accuracy: 0.8453 - val_loss: 1.2762 - val_accuracy: 0.6180\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.4640 - accuracy: 0.8580 - val_loss: 1.2807 - val_accuracy: 0.6135\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.4317 - accuracy: 0.8689 - val_loss: 1.2862 - val_accuracy: 0.6177\n",
            "64/64 [==============================] - 3s 29ms/step - loss: 1.3255 - accuracy: 0.6057\n",
            "23.107811323084576 0.28858179414923923 2.0448328706721486 0.206587627344716 0.2532704671724027 0.10294241132462649 0.284764900513898\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979277a850> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978cfc4890> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ce0bd90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978cef7f90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ce17790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d860110> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 27s 35ms/step - loss: 4.9686 - accuracy: 0.0162 - val_loss: 4.0659 - val_accuracy: 0.0687\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 4.1486 - accuracy: 0.0600 - val_loss: 3.5247 - val_accuracy: 0.1529\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.6684 - accuracy: 0.1027 - val_loss: 3.1640 - val_accuracy: 0.1927\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 3.3586 - accuracy: 0.1308 - val_loss: 2.9092 - val_accuracy: 0.2440\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.1305 - accuracy: 0.1629 - val_loss: 2.7233 - val_accuracy: 0.2847\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.9489 - accuracy: 0.1911 - val_loss: 2.5767 - val_accuracy: 0.3072\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.8136 - accuracy: 0.2182 - val_loss: 2.4587 - val_accuracy: 0.3261\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.7044 - accuracy: 0.2354 - val_loss: 2.3649 - val_accuracy: 0.3398\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.6091 - accuracy: 0.2547 - val_loss: 2.2813 - val_accuracy: 0.3609\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.5320 - accuracy: 0.2685 - val_loss: 2.2093 - val_accuracy: 0.3780\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.4389 - accuracy: 0.2836 - val_loss: 2.1511 - val_accuracy: 0.3853\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.3818 - accuracy: 0.2999 - val_loss: 2.0980 - val_accuracy: 0.3996\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.3162 - accuracy: 0.3141 - val_loss: 2.0495 - val_accuracy: 0.4109\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.2686 - accuracy: 0.3225 - val_loss: 2.0066 - val_accuracy: 0.4212\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.2164 - accuracy: 0.3354 - val_loss: 1.9679 - val_accuracy: 0.4285\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.1842 - accuracy: 0.3464 - val_loss: 1.9330 - val_accuracy: 0.4365\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.1377 - accuracy: 0.3541 - val_loss: 1.9021 - val_accuracy: 0.4392\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.1078 - accuracy: 0.3560 - val_loss: 1.8757 - val_accuracy: 0.4478\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0681 - accuracy: 0.3738 - val_loss: 1.8494 - val_accuracy: 0.4541\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.0311 - accuracy: 0.3794 - val_loss: 1.8260 - val_accuracy: 0.4571\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9979 - accuracy: 0.3878 - val_loss: 1.8030 - val_accuracy: 0.4624\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9772 - accuracy: 0.3920 - val_loss: 1.7818 - val_accuracy: 0.4668\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9479 - accuracy: 0.4017 - val_loss: 1.7640 - val_accuracy: 0.4724\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9123 - accuracy: 0.4122 - val_loss: 1.7452 - val_accuracy: 0.4786\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.8922 - accuracy: 0.4109 - val_loss: 1.7283 - val_accuracy: 0.4789\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8706 - accuracy: 0.4245 - val_loss: 1.7140 - val_accuracy: 0.4812\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8458 - accuracy: 0.4282 - val_loss: 1.6972 - val_accuracy: 0.4819\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8237 - accuracy: 0.4340 - val_loss: 1.6862 - val_accuracy: 0.4842\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8089 - accuracy: 0.4355 - val_loss: 1.6733 - val_accuracy: 0.4867\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.7790 - accuracy: 0.4444 - val_loss: 1.6600 - val_accuracy: 0.4912\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.6493 - accuracy: 0.4910\n",
            "77.54106486740386 0.8143784426682376 0.44029608546306087 0.6202682002990809 0.02471541078819729 0.16785108189696213 0.9580588001514504\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978db054d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f280f10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 30s 42ms/step - loss: 1.4548 - accuracy: 0.6006 - val_loss: 1.3192 - val_accuracy: 0.6137\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0847 - accuracy: 0.9870 - val_loss: 1.4424 - val_accuracy: 0.6321\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0205 - accuracy: 0.9979 - val_loss: 1.8066 - val_accuracy: 0.6006\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.1274 - accuracy: 0.9613 - val_loss: 1.8051 - val_accuracy: 0.6307\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 1.7266 - val_accuracy: 0.6428\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 1.7994 - val_accuracy: 0.6521\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 2.4385 - val_accuracy: 0.5979\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.1085 - accuracy: 0.9672 - val_loss: 2.1512 - val_accuracy: 0.6115\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 1.9666 - val_accuracy: 0.6431\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 20s 38ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 2.0076 - val_accuracy: 0.6411\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.9826 - accuracy: 0.6270\n",
            "Model N. 3   Accuracy =  0.626953125 Loss =  1.9826475381851196 parameters =  [7.75410649e+01 8.14378443e-01 4.40296085e-01 6.20268200e-01\n",
            " 2.47154108e-02 1.67851082e-01 9.58058800e-01 1.39473096e-01] \n",
            "\n",
            "24.315799232966096 0.3132165482188036 2.391130792450996 0.1615337431481013 0.011973418119706442 0.044997677889626664 0.11071807312687809\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b70f350> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9792cd71d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e039090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b388f50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ce1b550> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d9a0a90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 28s 36ms/step - loss: 5.0173 - accuracy: 0.0125 - val_loss: 4.5043 - val_accuracy: 0.0389\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 4.4596 - accuracy: 0.0313 - val_loss: 4.0736 - val_accuracy: 0.0688\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 4.0536 - accuracy: 0.0592 - val_loss: 3.7393 - val_accuracy: 0.0989\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.7385 - accuracy: 0.0868 - val_loss: 3.4772 - val_accuracy: 0.1368\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 3.4887 - accuracy: 0.1144 - val_loss: 3.2652 - val_accuracy: 0.1684\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 3.2917 - accuracy: 0.1386 - val_loss: 3.0906 - val_accuracy: 0.1877\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.1196 - accuracy: 0.1627 - val_loss: 2.9461 - val_accuracy: 0.2151\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 2.9859 - accuracy: 0.1866 - val_loss: 2.8235 - val_accuracy: 0.2407\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 2.8634 - accuracy: 0.2118 - val_loss: 2.7261 - val_accuracy: 0.2543\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.7659 - accuracy: 0.2300 - val_loss: 2.6352 - val_accuracy: 0.2656\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.6732 - accuracy: 0.2488 - val_loss: 2.5585 - val_accuracy: 0.2749\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.6110 - accuracy: 0.2576 - val_loss: 2.4928 - val_accuracy: 0.2931\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.5347 - accuracy: 0.2786 - val_loss: 2.4335 - val_accuracy: 0.3059\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4627 - accuracy: 0.2969 - val_loss: 2.3802 - val_accuracy: 0.3240\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4127 - accuracy: 0.3057 - val_loss: 2.3290 - val_accuracy: 0.3359\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.3636 - accuracy: 0.3172 - val_loss: 2.2827 - val_accuracy: 0.3481\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.3177 - accuracy: 0.3264 - val_loss: 2.2385 - val_accuracy: 0.3546\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.2671 - accuracy: 0.3428 - val_loss: 2.2001 - val_accuracy: 0.3622\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.2282 - accuracy: 0.3497 - val_loss: 2.1661 - val_accuracy: 0.3652\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.1857 - accuracy: 0.3633 - val_loss: 2.1332 - val_accuracy: 0.3708\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1564 - accuracy: 0.3638 - val_loss: 2.1005 - val_accuracy: 0.3808\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1152 - accuracy: 0.3734 - val_loss: 2.0719 - val_accuracy: 0.3865\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0893 - accuracy: 0.3847 - val_loss: 2.0456 - val_accuracy: 0.3983\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.0611 - accuracy: 0.3858 - val_loss: 2.0204 - val_accuracy: 0.4026\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.0282 - accuracy: 0.3960 - val_loss: 1.9974 - val_accuracy: 0.4072\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.0062 - accuracy: 0.4012 - val_loss: 1.9747 - val_accuracy: 0.4134\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9836 - accuracy: 0.4064 - val_loss: 1.9541 - val_accuracy: 0.4200\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9602 - accuracy: 0.4124 - val_loss: 1.9346 - val_accuracy: 0.4235\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9337 - accuracy: 0.4186 - val_loss: 1.9133 - val_accuracy: 0.4312\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9139 - accuracy: 0.4274 - val_loss: 1.8969 - val_accuracy: 0.4352\n",
            "128/128 [==============================] - 4s 23ms/step - loss: 1.8972 - accuracy: 0.4398\n",
            "29.882232569466247 0.7211144232247682 2.076952387356394 0.4711911023424486 0.33657460745225676 0.13631591092226558 0.24051304832304554\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b57f550> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792afa210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792afa190> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792acb110> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792af5850> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792ae5ad0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 27s 36ms/step - loss: 4.5730 - accuracy: 0.0521 - val_loss: 2.8414 - val_accuracy: 0.2472\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 18s 33ms/step - loss: 3.1597 - accuracy: 0.1637 - val_loss: 2.3460 - val_accuracy: 0.3557\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.7139 - accuracy: 0.2375 - val_loss: 2.0996 - val_accuracy: 0.4053\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.4564 - accuracy: 0.2859 - val_loss: 1.9424 - val_accuracy: 0.4395\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.2604 - accuracy: 0.3323 - val_loss: 1.8386 - val_accuracy: 0.4631\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.1305 - accuracy: 0.3567 - val_loss: 1.7590 - val_accuracy: 0.4782\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.0208 - accuracy: 0.3844 - val_loss: 1.7007 - val_accuracy: 0.4940\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9235 - accuracy: 0.4068 - val_loss: 1.6474 - val_accuracy: 0.5025\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8554 - accuracy: 0.4257 - val_loss: 1.6032 - val_accuracy: 0.5170\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.7859 - accuracy: 0.4414 - val_loss: 1.5699 - val_accuracy: 0.5196\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.7157 - accuracy: 0.4556 - val_loss: 1.5351 - val_accuracy: 0.5274\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.6722 - accuracy: 0.4730 - val_loss: 1.5045 - val_accuracy: 0.5387\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.6263 - accuracy: 0.4887 - val_loss: 1.4794 - val_accuracy: 0.5399\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.5801 - accuracy: 0.4969 - val_loss: 1.4556 - val_accuracy: 0.5522\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.5543 - accuracy: 0.5036 - val_loss: 1.4347 - val_accuracy: 0.5525\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.5026 - accuracy: 0.5188 - val_loss: 1.4149 - val_accuracy: 0.5547\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.4735 - accuracy: 0.5317 - val_loss: 1.3967 - val_accuracy: 0.5587\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.4480 - accuracy: 0.5294 - val_loss: 1.3835 - val_accuracy: 0.5625\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 18s 33ms/step - loss: 1.4091 - accuracy: 0.5453 - val_loss: 1.3669 - val_accuracy: 0.5637\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 18s 33ms/step - loss: 1.3793 - accuracy: 0.5523 - val_loss: 1.3555 - val_accuracy: 0.5653\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.3495 - accuracy: 0.5637 - val_loss: 1.3424 - val_accuracy: 0.5701\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.3225 - accuracy: 0.5687 - val_loss: 1.3291 - val_accuracy: 0.5736\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.2806 - accuracy: 0.5791 - val_loss: 1.3163 - val_accuracy: 0.5746\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 18s 33ms/step - loss: 1.2739 - accuracy: 0.5844 - val_loss: 1.3063 - val_accuracy: 0.5808\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.2495 - accuracy: 0.5893 - val_loss: 1.2977 - val_accuracy: 0.5803\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.2356 - accuracy: 0.5978 - val_loss: 1.2904 - val_accuracy: 0.5821\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.1928 - accuracy: 0.6052 - val_loss: 1.2825 - val_accuracy: 0.5854\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1719 - accuracy: 0.6124 - val_loss: 1.2721 - val_accuracy: 0.5848\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1551 - accuracy: 0.6194 - val_loss: 1.2677 - val_accuracy: 0.5853\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1305 - accuracy: 0.6219 - val_loss: 1.2608 - val_accuracy: 0.5849\n",
            "128/128 [==============================] - 4s 22ms/step - loss: 1.2725 - accuracy: 0.5876\n",
            "41.609797976760426 0.9680593489624634 1.5246000537883275 0.5942516853926012 0.47323547476076794 0.1587163631613819 0.5531576669715854\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f84590> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978cf11a10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978da3b9d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97917e86d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978cf3bf10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97917e8b50> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 21s 47ms/step - loss: 2.5040 - accuracy: 0.3286 - val_loss: 1.2459 - val_accuracy: 0.6074\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 11s 41ms/step - loss: 0.8867 - accuracy: 0.7075 - val_loss: 1.3634 - val_accuracy: 0.6233\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 0.3545 - accuracy: 0.8794 - val_loss: 1.8288 - val_accuracy: 0.6208\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 10s 40ms/step - loss: 0.1542 - accuracy: 0.9497 - val_loss: 2.1446 - val_accuracy: 0.6147\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 11s 41ms/step - loss: 0.1042 - accuracy: 0.9662 - val_loss: 2.3570 - val_accuracy: 0.6090\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 11s 41ms/step - loss: 0.0842 - accuracy: 0.9743 - val_loss: 2.4041 - val_accuracy: 0.6139\n",
            "64/64 [==============================] - 3s 29ms/step - loss: 2.5474 - accuracy: 0.6165\n",
            "1.8036573828468327 0.7173742696256686 0.9423253426546636 0.42222896299093365 0.3338508911150411 0.18329440780763565 0.5234647535581965\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dea3790> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979148a6d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979148a8d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4dded0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 16s 62ms/step - loss: 2.2404 - accuracy: 0.3968 - val_loss: 1.2668 - val_accuracy: 0.5915\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.9535 - accuracy: 0.6859 - val_loss: 1.2004 - val_accuracy: 0.6139\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 6s 49ms/step - loss: 0.6449 - accuracy: 0.7867 - val_loss: 1.2239 - val_accuracy: 0.6232\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.4419 - accuracy: 0.8572 - val_loss: 1.2425 - val_accuracy: 0.6343\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.3105 - accuracy: 0.9057 - val_loss: 1.3039 - val_accuracy: 0.6307\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 6s 49ms/step - loss: 0.2116 - accuracy: 0.9414 - val_loss: 1.3572 - val_accuracy: 0.6310\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.1578 - accuracy: 0.9557 - val_loss: 1.4244 - val_accuracy: 0.6297\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 0.1201 - accuracy: 0.9691 - val_loss: 1.4864 - val_accuracy: 0.6325\n",
            "32/32 [==============================] - 2s 35ms/step - loss: 1.5278 - accuracy: 0.6217\n",
            "95.28716118240123 0.8938097036209269 1.1742888370284525 0.33122710127967225 0.13233702301971834 0.1933884436882111 0.4058596493010289\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792c97690> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b6b2510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d5ba0d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b6b2410> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 30s 41ms/step - loss: 3.7720 - accuracy: 0.1486 - val_loss: 1.9482 - val_accuracy: 0.4530\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 1.8542 - accuracy: 0.4527 - val_loss: 1.6044 - val_accuracy: 0.5170\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 1.4742 - accuracy: 0.5422 - val_loss: 1.4771 - val_accuracy: 0.5467\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 1.2671 - accuracy: 0.6025 - val_loss: 1.4115 - val_accuracy: 0.5711\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 1.1046 - accuracy: 0.6465 - val_loss: 1.3620 - val_accuracy: 0.5859\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.9874 - accuracy: 0.6816 - val_loss: 1.3364 - val_accuracy: 0.5974\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 0.8869 - accuracy: 0.7172 - val_loss: 1.3150 - val_accuracy: 0.6057\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.8002 - accuracy: 0.7466 - val_loss: 1.3023 - val_accuracy: 0.6092\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.7194 - accuracy: 0.7739 - val_loss: 1.2955 - val_accuracy: 0.6154\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.6513 - accuracy: 0.7938 - val_loss: 1.2949 - val_accuracy: 0.6175\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.5862 - accuracy: 0.8167 - val_loss: 1.3029 - val_accuracy: 0.6174\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.5328 - accuracy: 0.8365 - val_loss: 1.3123 - val_accuracy: 0.6217\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 0.4814 - accuracy: 0.8509 - val_loss: 1.3208 - val_accuracy: 0.6215\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.4387 - accuracy: 0.8696 - val_loss: 1.3242 - val_accuracy: 0.6215\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.3897 - accuracy: 0.8859 - val_loss: 1.3392 - val_accuracy: 0.6207\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 0.3571 - accuracy: 0.8987 - val_loss: 1.3490 - val_accuracy: 0.6193\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.3360 - accuracy: 0.6171\n",
            "58.40152240611086 0.39145384697455776 0.0 0.65 0.13711276552045817 0.08336544249362947 0.6836697642938129\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799014e50> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978dd610d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 17s 71ms/step - loss: 3.7102 - accuracy: 0.2067 - val_loss: 2.2345 - val_accuracy: 0.4123\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 8s 57ms/step - loss: 1.1443 - accuracy: 0.6689 - val_loss: 1.6237 - val_accuracy: 0.5298\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 7s 56ms/step - loss: 0.6679 - accuracy: 0.8240 - val_loss: 1.3986 - val_accuracy: 0.5846\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 0.3908 - accuracy: 0.9265 - val_loss: 1.3353 - val_accuracy: 0.5964\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 0.2219 - accuracy: 0.9787 - val_loss: 1.3321 - val_accuracy: 0.6058\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 0.1282 - accuracy: 0.9948 - val_loss: 1.3486 - val_accuracy: 0.6077\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 0.0779 - accuracy: 0.9997 - val_loss: 1.3627 - val_accuracy: 0.6105\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 7s 56ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.6092\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 7s 54ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 1.3947 - val_accuracy: 0.6172\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.4214 - val_accuracy: 0.6147\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.4418 - val_accuracy: 0.6123\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 7s 55ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.6149\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 7s 53ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.4634 - val_accuracy: 0.6143\n",
            "32/32 [==============================] - 2s 36ms/step - loss: 1.4534 - accuracy: 0.6207\n",
            "49.048081155453644 0.7451304551075166 2.165196322665268 0.6182672847033588 0.34098054307790043 0.19466177041805738 0.9956657214751343\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f63f2d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97927d83d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798ff9950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97991cff10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798f08d50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979146f750> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 28s 38ms/step - loss: 2.0225 - accuracy: 0.4154 - val_loss: 1.2450 - val_accuracy: 0.6145\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 18s 34ms/step - loss: 0.7895 - accuracy: 0.7435 - val_loss: 1.4873 - val_accuracy: 0.6089\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 18s 34ms/step - loss: 0.4575 - accuracy: 0.8506 - val_loss: 1.6739 - val_accuracy: 0.6077\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.3124 - accuracy: 0.9033 - val_loss: 1.9349 - val_accuracy: 0.6112\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.2334 - accuracy: 0.9321 - val_loss: 1.8514 - val_accuracy: 0.6323\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1936 - accuracy: 0.9417 - val_loss: 2.0596 - val_accuracy: 0.6210\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1739 - accuracy: 0.9501 - val_loss: 2.1074 - val_accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1557 - accuracy: 0.9546 - val_loss: 2.1217 - val_accuracy: 0.6242\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 18s 35ms/step - loss: 0.1428 - accuracy: 0.9605 - val_loss: 2.1981 - val_accuracy: 0.6177\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1333 - accuracy: 0.9638 - val_loss: 2.0572 - val_accuracy: 0.6451\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1296 - accuracy: 0.9655 - val_loss: 2.3147 - val_accuracy: 0.6280\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1245 - accuracy: 0.9657 - val_loss: 2.2006 - val_accuracy: 0.6238\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1140 - accuracy: 0.9697 - val_loss: 2.1837 - val_accuracy: 0.6380\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.1116 - accuracy: 0.9711 - val_loss: 2.3531 - val_accuracy: 0.6395\n",
            "128/128 [==============================] - 4s 25ms/step - loss: 2.5566 - accuracy: 0.6055\n",
            "54.8898237922757 1.0 0.7198690239122955 0.34130598140978724 0.65 0.18842187471716854 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978df6b150> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f45e5d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b36fe10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979154fb90> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 23s 50ms/step - loss: 1.7071 - accuracy: 0.5181 - val_loss: 1.3386 - val_accuracy: 0.6134\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.2553 - accuracy: 0.9164 - val_loss: 1.8752 - val_accuracy: 0.6064\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 0.1098 - accuracy: 0.9635 - val_loss: 2.0102 - val_accuracy: 0.6237\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.0739 - accuracy: 0.9769 - val_loss: 2.3780 - val_accuracy: 0.6052\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.0790 - accuracy: 0.9743 - val_loss: 2.4800 - val_accuracy: 0.6180\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.0517 - accuracy: 0.9828 - val_loss: 2.4839 - val_accuracy: 0.6125\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 2.7453 - val_accuracy: 0.6074\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 2.7155 - accuracy: 0.6104\n",
            "118.92475485953699 0.6038267830397426 1.2302396125233817 0.65 0.0 0.0701381483391239 0.39971223265512257\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b4356d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97918e9f90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f086790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f051f10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 32s 45ms/step - loss: 6.2432 - accuracy: 0.0129 - val_loss: 4.7891 - val_accuracy: 0.0381\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 5.6134 - accuracy: 0.0257 - val_loss: 4.3679 - val_accuracy: 0.0778\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 5.1239 - accuracy: 0.0394 - val_loss: 3.9853 - val_accuracy: 0.1247\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.7220 - accuracy: 0.0613 - val_loss: 3.6757 - val_accuracy: 0.1669\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.3952 - accuracy: 0.0871 - val_loss: 3.4166 - val_accuracy: 0.2118\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.1139 - accuracy: 0.1112 - val_loss: 3.2050 - val_accuracy: 0.2460\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.8842 - accuracy: 0.1372 - val_loss: 3.0274 - val_accuracy: 0.2716\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.6850 - accuracy: 0.1603 - val_loss: 2.8750 - val_accuracy: 0.2937\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 3.5254 - accuracy: 0.1828 - val_loss: 2.7410 - val_accuracy: 0.3170\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 3.3571 - accuracy: 0.2003 - val_loss: 2.6301 - val_accuracy: 0.3288\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 3.2280 - accuracy: 0.2186 - val_loss: 2.5302 - val_accuracy: 0.3416\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 3.1077 - accuracy: 0.2383 - val_loss: 2.4473 - val_accuracy: 0.3600\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.0082 - accuracy: 0.2474 - val_loss: 2.3690 - val_accuracy: 0.3682\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.9090 - accuracy: 0.2647 - val_loss: 2.2998 - val_accuracy: 0.3785\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.8204 - accuracy: 0.2772 - val_loss: 2.2387 - val_accuracy: 0.3954\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.7531 - accuracy: 0.2890 - val_loss: 2.1843 - val_accuracy: 0.4106\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 2.6821 - accuracy: 0.3006 - val_loss: 2.1347 - val_accuracy: 0.4224\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.6318 - accuracy: 0.3115 - val_loss: 2.0908 - val_accuracy: 0.4337\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.5425 - accuracy: 0.3264 - val_loss: 2.0487 - val_accuracy: 0.4445\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.4999 - accuracy: 0.3338 - val_loss: 2.0118 - val_accuracy: 0.4475\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.4586 - accuracy: 0.3353 - val_loss: 1.9794 - val_accuracy: 0.4546\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.4034 - accuracy: 0.3487 - val_loss: 1.9467 - val_accuracy: 0.4599\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.3460 - accuracy: 0.3613 - val_loss: 1.9177 - val_accuracy: 0.4671\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.3081 - accuracy: 0.3694 - val_loss: 1.8896 - val_accuracy: 0.4659\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 2.2599 - accuracy: 0.3750 - val_loss: 1.8610 - val_accuracy: 0.4711\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 2.2458 - accuracy: 0.3785 - val_loss: 1.8418 - val_accuracy: 0.4756\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 2.1897 - accuracy: 0.3895 - val_loss: 1.8175 - val_accuracy: 0.4776\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.1653 - accuracy: 0.3938 - val_loss: 1.7950 - val_accuracy: 0.4844\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 2.1473 - accuracy: 0.3946 - val_loss: 1.7775 - val_accuracy: 0.4904\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 2.1249 - accuracy: 0.3992 - val_loss: 1.7610 - val_accuracy: 0.4914\n",
            "128/128 [==============================] - 4s 25ms/step - loss: 1.7468 - accuracy: 0.5006\n",
            "120.0 0.8848322325427451 0.017558408032942507 0.65 0.0 0.12378947807302793 0.5838530408358955\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97918e85d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e4b6950> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 24s 59ms/step - loss: 2.4892 - accuracy: 0.4208 - val_loss: 1.4622 - val_accuracy: 0.5806\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.3338 - accuracy: 0.9387 - val_loss: 1.2217 - val_accuracy: 0.6395\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0855 - accuracy: 0.9981 - val_loss: 1.2446 - val_accuracy: 0.6428\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0350 - accuracy: 0.9999 - val_loss: 1.2761 - val_accuracy: 0.6499\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.6559\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3151 - val_accuracy: 0.6594\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3375 - val_accuracy: 0.6596\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.6591\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.6641\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3846 - val_accuracy: 0.6619\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.6642\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4232 - val_accuracy: 0.6667\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4328 - val_accuracy: 0.6652\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4532 - val_accuracy: 0.6632\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 0.6619\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 8.2235e-04 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 0.6597\n",
            "64/64 [==============================] - 2s 27ms/step - loss: 1.5065 - accuracy: 0.6672\n",
            "Model N. 4   Accuracy =  0.667236328125 Loss =  1.5065138339996338 parameters =  [1.20000000e+02 8.84832233e-01 1.75584080e-02 6.50000000e-01\n",
            " 0.00000000e+00 1.23789478e-01 5.83853041e-01 1.37280331e+00] \n",
            "\n",
            "120.0 0.8211036110786365 1.5539459808907607 0.4945228627330208 0.2448498955996163 0.08702858659097407 0.7572902381932791\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f3ede10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e47c2d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d40f110> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f096710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f051b90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d429bd0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 23s 55ms/step - loss: 2.9683 - accuracy: 0.2375 - val_loss: 1.4350 - val_accuracy: 0.5788\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.9742 - accuracy: 0.6833 - val_loss: 1.2377 - val_accuracy: 0.6375\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.3977 - accuracy: 0.8710 - val_loss: 1.4230 - val_accuracy: 0.6476\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.1290 - accuracy: 0.9634 - val_loss: 1.6593 - val_accuracy: 0.6473\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0495 - accuracy: 0.9865 - val_loss: 1.8352 - val_accuracy: 0.6423\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 1.9686 - val_accuracy: 0.6536\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 2.1253 - val_accuracy: 0.6514\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 2.2300 - val_accuracy: 0.6503\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 2.2774 - val_accuracy: 0.6484\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 2.3542 - val_accuracy: 0.6444\n",
            "64/64 [==============================] - 3s 29ms/step - loss: 2.3127 - accuracy: 0.6471\n",
            "60.1736243720326 0.5852782930422431 2.2514424762949616 0.4093439023967134 0.338140153271437 0.2 0.12183493233358897\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f087b10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d270210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978eea1f90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978cf02650> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dba0d10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978ba94150> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 29s 39ms/step - loss: 4.1712 - accuracy: 0.0789 - val_loss: 2.3168 - val_accuracy: 0.3680\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 2.4844 - accuracy: 0.2751 - val_loss: 1.8795 - val_accuracy: 0.4443\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 2.0814 - accuracy: 0.3744 - val_loss: 1.6799 - val_accuracy: 0.4917\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.8239 - accuracy: 0.4331 - val_loss: 1.5600 - val_accuracy: 0.5155\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.6586 - accuracy: 0.4821 - val_loss: 1.4880 - val_accuracy: 0.5339\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 18s 35ms/step - loss: 1.5200 - accuracy: 0.5155 - val_loss: 1.4296 - val_accuracy: 0.5455\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.4307 - accuracy: 0.5411 - val_loss: 1.3909 - val_accuracy: 0.5573\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.3350 - accuracy: 0.5700 - val_loss: 1.3573 - val_accuracy: 0.5756\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 18s 35ms/step - loss: 1.2610 - accuracy: 0.5923 - val_loss: 1.3323 - val_accuracy: 0.5831\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 1.1988 - accuracy: 0.6091 - val_loss: 1.3100 - val_accuracy: 0.5874\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.1297 - accuracy: 0.6289 - val_loss: 1.2930 - val_accuracy: 0.5903\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.0682 - accuracy: 0.6535 - val_loss: 1.2744 - val_accuracy: 0.6077\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 1.0042 - accuracy: 0.6728 - val_loss: 1.2671 - val_accuracy: 0.6089\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.9657 - accuracy: 0.6755 - val_loss: 1.2597 - val_accuracy: 0.6170\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.9073 - accuracy: 0.7012 - val_loss: 1.2513 - val_accuracy: 0.6179\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.8515 - accuracy: 0.7170 - val_loss: 1.2525 - val_accuracy: 0.6248\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.8068 - accuracy: 0.7338 - val_loss: 1.2514 - val_accuracy: 0.6232\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 18s 34ms/step - loss: 0.7643 - accuracy: 0.7466 - val_loss: 1.2517 - val_accuracy: 0.6310\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.7303 - accuracy: 0.7567 - val_loss: 1.2565 - val_accuracy: 0.6272\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 18s 35ms/step - loss: 0.6839 - accuracy: 0.7725 - val_loss: 1.2611 - val_accuracy: 0.6340\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.6510 - accuracy: 0.7839 - val_loss: 1.2681 - val_accuracy: 0.6343\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.6034 - accuracy: 0.8004 - val_loss: 1.2825 - val_accuracy: 0.6305\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.5760 - accuracy: 0.8091 - val_loss: 1.2886 - val_accuracy: 0.6282\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 19s 35ms/step - loss: 0.5346 - accuracy: 0.8209 - val_loss: 1.3061 - val_accuracy: 0.6227\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.4991 - accuracy: 0.8341 - val_loss: 1.3190 - val_accuracy: 0.6270\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.3525 - accuracy: 0.6208\n",
            "101.75242813776507 1.0 1.4917664767812187 0.4028334876764438 0.29900708324954317 0.10470222776648491 0.259858016912847\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d5218d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798f45e90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799249d90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799265c90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 31s 44ms/step - loss: 5.4858 - accuracy: 0.0139 - val_loss: 4.2463 - val_accuracy: 0.0743\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 4.4008 - accuracy: 0.0658 - val_loss: 3.5034 - val_accuracy: 0.1927\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 3.7030 - accuracy: 0.1435 - val_loss: 3.0085 - val_accuracy: 0.2708\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 3.2205 - accuracy: 0.2085 - val_loss: 2.6741 - val_accuracy: 0.3225\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 22s 40ms/step - loss: 2.8655 - accuracy: 0.2616 - val_loss: 2.4363 - val_accuracy: 0.3580\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 2.6157 - accuracy: 0.3052 - val_loss: 2.2656 - val_accuracy: 0.3878\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 2.4552 - accuracy: 0.3318 - val_loss: 2.1341 - val_accuracy: 0.4086\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 21s 39ms/step - loss: 2.2904 - accuracy: 0.3573 - val_loss: 2.0384 - val_accuracy: 0.4287\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 2.1935 - accuracy: 0.3779 - val_loss: 1.9604 - val_accuracy: 0.4451\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 2.0918 - accuracy: 0.3983 - val_loss: 1.8950 - val_accuracy: 0.4563\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 22s 40ms/step - loss: 2.0174 - accuracy: 0.4117 - val_loss: 1.8418 - val_accuracy: 0.4663\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.9500 - accuracy: 0.4288 - val_loss: 1.7989 - val_accuracy: 0.4701\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.8748 - accuracy: 0.4456 - val_loss: 1.7572 - val_accuracy: 0.4767\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.8211 - accuracy: 0.4605 - val_loss: 1.7222 - val_accuracy: 0.4842\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.7657 - accuracy: 0.4680 - val_loss: 1.6934 - val_accuracy: 0.4934\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.7318 - accuracy: 0.4765 - val_loss: 1.6657 - val_accuracy: 0.4940\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.6927 - accuracy: 0.4893 - val_loss: 1.6429 - val_accuracy: 0.4980\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.6603 - accuracy: 0.4926 - val_loss: 1.6213 - val_accuracy: 0.5065\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.6241 - accuracy: 0.5046 - val_loss: 1.6009 - val_accuracy: 0.5121\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.5864 - accuracy: 0.5151 - val_loss: 1.5837 - val_accuracy: 0.5153\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.5534 - accuracy: 0.5214 - val_loss: 1.5686 - val_accuracy: 0.5244\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.5094 - accuracy: 0.5362 - val_loss: 1.5510 - val_accuracy: 0.5279\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.5039 - accuracy: 0.5357 - val_loss: 1.5365 - val_accuracy: 0.5273\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 1.4596 - accuracy: 0.5447 - val_loss: 1.5222 - val_accuracy: 0.5369\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.4494 - accuracy: 0.5502 - val_loss: 1.5093 - val_accuracy: 0.5394\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.4181 - accuracy: 0.5596 - val_loss: 1.4991 - val_accuracy: 0.5464\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.3990 - accuracy: 0.5587 - val_loss: 1.4872 - val_accuracy: 0.5462\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 1.3704 - accuracy: 0.5706 - val_loss: 1.4801 - val_accuracy: 0.5515\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.3452 - accuracy: 0.5793 - val_loss: 1.4689 - val_accuracy: 0.5535\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 21s 40ms/step - loss: 1.3326 - accuracy: 0.5830 - val_loss: 1.4614 - val_accuracy: 0.5567\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.4496 - accuracy: 0.5479\n",
            "120.0 0.841698353024767 0.23990182803575855 0.49639233370653224 0.5496561406866676 0.2 0.5170262016756055\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f50c50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978dd550d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 34s 47ms/step - loss: 1.3488 - accuracy: 0.6156 - val_loss: 1.2715 - val_accuracy: 0.6802\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.1478 - accuracy: 0.9519 - val_loss: 1.7449 - val_accuracy: 0.6549\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.1057 - accuracy: 0.9665 - val_loss: 1.7486 - val_accuracy: 0.6789\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 1.7190 - val_accuracy: 0.6968\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 0.0661 - accuracy: 0.9779 - val_loss: 2.0462 - val_accuracy: 0.6759\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.0806 - accuracy: 0.9732 - val_loss: 1.8830 - val_accuracy: 0.6945\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 1.9587 - val_accuracy: 0.6908\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 2.2652 - val_accuracy: 0.6647\n",
            "128/128 [==============================] - 4s 23ms/step - loss: 2.1985 - accuracy: 0.6581\n",
            "120.0 0.9696698654062921 0.03935203234907392 0.5706904276786219 0.0 0.16925989764892851 0.43390928241039484\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978ef8b8d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792b31b90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 34s 46ms/step - loss: 4.3859 - accuracy: 0.1354 - val_loss: 2.2892 - val_accuracy: 0.4171\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 1.8512 - accuracy: 0.4881 - val_loss: 1.7944 - val_accuracy: 0.4865\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 1.3816 - accuracy: 0.5937 - val_loss: 1.6196 - val_accuracy: 0.5281\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 1.1564 - accuracy: 0.6464 - val_loss: 1.5206 - val_accuracy: 0.5517\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.9871 - accuracy: 0.6970 - val_loss: 1.4651 - val_accuracy: 0.5637\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.8769 - accuracy: 0.7348 - val_loss: 1.4187 - val_accuracy: 0.5781\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.7627 - accuracy: 0.7707 - val_loss: 1.3897 - val_accuracy: 0.5823\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.6880 - accuracy: 0.7989 - val_loss: 1.3671 - val_accuracy: 0.5924\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.6237 - accuracy: 0.8230 - val_loss: 1.3532 - val_accuracy: 0.5991\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.5624 - accuracy: 0.8473 - val_loss: 1.3426 - val_accuracy: 0.6057\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 22s 41ms/step - loss: 0.5144 - accuracy: 0.8622 - val_loss: 1.3304 - val_accuracy: 0.6084\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.4592 - accuracy: 0.8864 - val_loss: 1.3289 - val_accuracy: 0.6054\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.4165 - accuracy: 0.9022 - val_loss: 1.3241 - val_accuracy: 0.6052\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.3836 - accuracy: 0.9105 - val_loss: 1.3214 - val_accuracy: 0.6119\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.3549 - accuracy: 0.9227 - val_loss: 1.3200 - val_accuracy: 0.6129\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.3230 - accuracy: 0.9328 - val_loss: 1.3198 - val_accuracy: 0.6105\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.2971 - accuracy: 0.9419 - val_loss: 1.3183 - val_accuracy: 0.6127\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.2709 - accuracy: 0.9507 - val_loss: 1.3198 - val_accuracy: 0.6120\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 0.2504 - accuracy: 0.9566 - val_loss: 1.3201 - val_accuracy: 0.6174\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.2274 - accuracy: 0.9659 - val_loss: 1.3234 - val_accuracy: 0.6182\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.2137 - accuracy: 0.9682 - val_loss: 1.3271 - val_accuracy: 0.6155\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.1992 - accuracy: 0.9713 - val_loss: 1.3280 - val_accuracy: 0.6174\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 0.1852 - accuracy: 0.9746 - val_loss: 1.3339 - val_accuracy: 0.6157\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.1702 - accuracy: 0.9799 - val_loss: 1.3316 - val_accuracy: 0.6110\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 1.3541 - accuracy: 0.6060\n",
            "100.49429504609789 0.4582106876473189 0.0 0.65 0.13757731645628488 0.11686919049814504 0.6857195258091681\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e528c50> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97914bd190> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 19s 76ms/step - loss: 3.1400 - accuracy: 0.3061 - val_loss: 2.1343 - val_accuracy: 0.4884\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 8s 63ms/step - loss: 0.7358 - accuracy: 0.8050 - val_loss: 1.5124 - val_accuracy: 0.5828\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 8s 62ms/step - loss: 0.3235 - accuracy: 0.9543 - val_loss: 1.3214 - val_accuracy: 0.6130\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 8s 63ms/step - loss: 0.1470 - accuracy: 0.9951 - val_loss: 1.3264 - val_accuracy: 0.6147\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0740 - accuracy: 0.9996 - val_loss: 1.3520 - val_accuracy: 0.6239\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.6240\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.6294\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 8s 63ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.4237 - val_accuracy: 0.6289\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 8s 62ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 0.6304\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 8s 59ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.6348\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 8s 62ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.6330\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.4847 - val_accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 8s 62ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.6336\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5040 - val_accuracy: 0.6322\n",
            "32/32 [==============================] - 2s 36ms/step - loss: 1.5238 - accuracy: 0.6071\n",
            "65.08222397892587 0.7129477434652175 1.0315773908541142 0.65 0.30363441495809784 0.18239611473802675 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e15f610> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792d1bad0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792d1bbd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97914ac190> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 28s 39ms/step - loss: 2.0089 - accuracy: 0.4532 - val_loss: 1.2806 - val_accuracy: 0.6278\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.6506 - accuracy: 0.7867 - val_loss: 1.6674 - val_accuracy: 0.6297\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.3386 - accuracy: 0.8879 - val_loss: 1.7729 - val_accuracy: 0.6415\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.2254 - accuracy: 0.9293 - val_loss: 1.9954 - val_accuracy: 0.6326\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 19s 37ms/step - loss: 0.1868 - accuracy: 0.9397 - val_loss: 2.1653 - val_accuracy: 0.6295\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 19s 36ms/step - loss: 0.1540 - accuracy: 0.9530 - val_loss: 2.3517 - val_accuracy: 0.6248\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 19s 37ms/step - loss: 0.1318 - accuracy: 0.9569 - val_loss: 2.3033 - val_accuracy: 0.6331\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 2.3901 - accuracy: 0.6234\n",
            "85.55942930601027 1.0 0.0 0.3920031691278818 0.582864221251566 0.1435049672790679 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d974cd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798e476d0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 22s 51ms/step - loss: 1.6052 - accuracy: 0.5838 - val_loss: 1.2570 - val_accuracy: 0.6218\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.0552 - accuracy: 0.9979 - val_loss: 1.3429 - val_accuracy: 0.6325\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4537 - val_accuracy: 0.6428\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5162 - val_accuracy: 0.6426\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.6403\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6034 - val_accuracy: 0.6353\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.6383\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 1.6406 - accuracy: 0.6462\n",
            "120.0 0.8797651008951516 0.0 0.65 0.0 0.06617545430316094 0.5495859879431875\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d73f290> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798ff9690> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 24s 55ms/step - loss: 3.2973 - accuracy: 0.2826 - val_loss: 1.7398 - val_accuracy: 0.5449\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.7617 - accuracy: 0.7930 - val_loss: 1.3318 - val_accuracy: 0.5944\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.3448 - accuracy: 0.9395 - val_loss: 1.2815 - val_accuracy: 0.6222\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.1607 - accuracy: 0.9899 - val_loss: 1.2776 - val_accuracy: 0.6237\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0826 - accuracy: 0.9990 - val_loss: 1.2865 - val_accuracy: 0.6300\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 0.0495 - accuracy: 0.9998 - val_loss: 1.2928 - val_accuracy: 0.6360\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.6380\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.6398\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3389 - val_accuracy: 0.6416\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3575 - val_accuracy: 0.6403\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 14s 51ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.3670 - val_accuracy: 0.6461\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.6438\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.6441\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.6423\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4318 - val_accuracy: 0.6464\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4444 - val_accuracy: 0.6501\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.6479\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 13s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.6488\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4792 - val_accuracy: 0.6491\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5004 - val_accuracy: 0.6509\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5130 - val_accuracy: 0.6471\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5287 - val_accuracy: 0.6488\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 13s 50ms/step - loss: 9.0578e-04 - accuracy: 1.0000 - val_loss: 1.5457 - val_accuracy: 0.6468\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 7.5397e-04 - accuracy: 1.0000 - val_loss: 1.5614 - val_accuracy: 0.6483\n",
            "64/64 [==============================] - 3s 29ms/step - loss: 1.5565 - accuracy: 0.6545\n",
            "120.0 0.920059127479999 0.0 0.65 0.0 0.10175867616106082 0.39675016117811807\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d927fd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b91bb10> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 22s 54ms/step - loss: 5.5510 - accuracy: 0.0166 - val_loss: 4.6157 - val_accuracy: 0.0379\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 4.7452 - accuracy: 0.0510 - val_loss: 4.2259 - val_accuracy: 0.1077\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 4.0348 - accuracy: 0.1258 - val_loss: 3.7162 - val_accuracy: 0.1833\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 3.5035 - accuracy: 0.2140 - val_loss: 3.3058 - val_accuracy: 0.2543\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 3.0895 - accuracy: 0.2873 - val_loss: 2.9932 - val_accuracy: 0.3002\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.7771 - accuracy: 0.3444 - val_loss: 2.7545 - val_accuracy: 0.3318\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.5225 - accuracy: 0.3798 - val_loss: 2.5659 - val_accuracy: 0.3675\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.3299 - accuracy: 0.4132 - val_loss: 2.4149 - val_accuracy: 0.3876\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.1656 - accuracy: 0.4419 - val_loss: 2.2945 - val_accuracy: 0.4024\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.0432 - accuracy: 0.4607 - val_loss: 2.1979 - val_accuracy: 0.4200\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 1.9134 - accuracy: 0.4835 - val_loss: 2.1164 - val_accuracy: 0.4287\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 1.8368 - accuracy: 0.4999 - val_loss: 2.0522 - val_accuracy: 0.4377\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.7354 - accuracy: 0.5164 - val_loss: 1.9933 - val_accuracy: 0.4481\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 1.6793 - accuracy: 0.5268 - val_loss: 1.9449 - val_accuracy: 0.4558\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 1.6199 - accuracy: 0.5375 - val_loss: 1.9022 - val_accuracy: 0.4558\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 13s 47ms/step - loss: 1.5753 - accuracy: 0.5493 - val_loss: 1.8650 - val_accuracy: 0.4623\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.5170 - accuracy: 0.5606 - val_loss: 1.8310 - val_accuracy: 0.4679\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.4729 - accuracy: 0.5720 - val_loss: 1.8014 - val_accuracy: 0.4737\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 13s 47ms/step - loss: 1.4283 - accuracy: 0.5833 - val_loss: 1.7728 - val_accuracy: 0.4827\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.3933 - accuracy: 0.5909 - val_loss: 1.7522 - val_accuracy: 0.4850\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.3545 - accuracy: 0.5969 - val_loss: 1.7276 - val_accuracy: 0.4862\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 1.3271 - accuracy: 0.6046 - val_loss: 1.7072 - val_accuracy: 0.4937\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.2923 - accuracy: 0.6177 - val_loss: 1.6884 - val_accuracy: 0.4958\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.2522 - accuracy: 0.6282 - val_loss: 1.6734 - val_accuracy: 0.4929\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.2338 - accuracy: 0.6321 - val_loss: 1.6560 - val_accuracy: 0.5013\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.2011 - accuracy: 0.6410 - val_loss: 1.6385 - val_accuracy: 0.5023\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.1761 - accuracy: 0.6476 - val_loss: 1.6259 - val_accuracy: 0.5048\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.1575 - accuracy: 0.6541 - val_loss: 1.6114 - val_accuracy: 0.5083\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 1.1403 - accuracy: 0.6599 - val_loss: 1.5989 - val_accuracy: 0.5121\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 1.1130 - accuracy: 0.6657 - val_loss: 1.5859 - val_accuracy: 0.5171\n",
            "64/64 [==============================] - 2s 27ms/step - loss: 1.5895 - accuracy: 0.5189\n",
            "120.0 1.0 0.13336471056338817 0.65 0.308256760524795 0.11729558917728405 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b187750> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9799067ed0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 18s 77ms/step - loss: 3.0337 - accuracy: 0.3436 - val_loss: 1.9994 - val_accuracy: 0.5329\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 8s 63ms/step - loss: 0.4803 - accuracy: 0.8967 - val_loss: 1.4238 - val_accuracy: 0.6003\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.1489 - accuracy: 0.9934 - val_loss: 1.2639 - val_accuracy: 0.6221\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0596 - accuracy: 0.9999 - val_loss: 1.2831 - val_accuracy: 0.6276\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.6338\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.6403\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 8s 59ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.6377\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 8s 59ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3589 - val_accuracy: 0.6419\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.6432\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 8s 62ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.6427\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.6431\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 8s 61ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4127 - val_accuracy: 0.6460\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4219 - val_accuracy: 0.6465\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4395 - val_accuracy: 0.6455\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4509 - val_accuracy: 0.6486\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 8s 59ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4403 - val_accuracy: 0.6517\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.6488\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 8s 60ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4645 - val_accuracy: 0.6515\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 7s 56ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4818 - val_accuracy: 0.6497\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 8s 58ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.6506\n",
            "32/32 [==============================] - 2s 36ms/step - loss: 1.5013 - accuracy: 0.6552\n",
            "88.15193205304541 0.7169192967566058 1.011099486778332 0.42274724137880576 0.25930652361085327 0.1905250587753177 0.11614950051126322\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e3a8a90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b7b6dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f11c850> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d63a2d0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 20s 47ms/step - loss: 4.8508 - accuracy: 0.0678 - val_loss: 2.7381 - val_accuracy: 0.3504\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 2.5947 - accuracy: 0.3125 - val_loss: 1.9939 - val_accuracy: 0.4382\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 2.0258 - accuracy: 0.4174 - val_loss: 1.7616 - val_accuracy: 0.4707\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 1.7508 - accuracy: 0.4770 - val_loss: 1.6382 - val_accuracy: 0.5020\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 1.5671 - accuracy: 0.5224 - val_loss: 1.5615 - val_accuracy: 0.5189\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 1.4453 - accuracy: 0.5511 - val_loss: 1.5062 - val_accuracy: 0.5349\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 11s 42ms/step - loss: 1.3482 - accuracy: 0.5793 - val_loss: 1.4655 - val_accuracy: 0.5472\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 11s 41ms/step - loss: 1.2424 - accuracy: 0.6088 - val_loss: 1.4351 - val_accuracy: 0.5620\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 1.1595 - accuracy: 0.6308 - val_loss: 1.4085 - val_accuracy: 0.5718\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 1.0965 - accuracy: 0.6502 - val_loss: 1.3853 - val_accuracy: 0.5745\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 1.0389 - accuracy: 0.6687 - val_loss: 1.3655 - val_accuracy: 0.5780\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.9705 - accuracy: 0.6901 - val_loss: 1.3505 - val_accuracy: 0.5811\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.9296 - accuracy: 0.7010 - val_loss: 1.3412 - val_accuracy: 0.5864\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.8561 - accuracy: 0.7264 - val_loss: 1.3306 - val_accuracy: 0.5888\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.8215 - accuracy: 0.7401 - val_loss: 1.3224 - val_accuracy: 0.5918\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 11s 43ms/step - loss: 0.7808 - accuracy: 0.7545 - val_loss: 1.3168 - val_accuracy: 0.5928\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.7402 - accuracy: 0.7665 - val_loss: 1.3116 - val_accuracy: 0.5956\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.6979 - accuracy: 0.7824 - val_loss: 1.3067 - val_accuracy: 0.5989\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.6641 - accuracy: 0.7915 - val_loss: 1.3041 - val_accuracy: 0.6051\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.6334 - accuracy: 0.8037 - val_loss: 1.3021 - val_accuracy: 0.6059\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.5933 - accuracy: 0.8157 - val_loss: 1.2999 - val_accuracy: 0.6057\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 0.5637 - accuracy: 0.8313 - val_loss: 1.3022 - val_accuracy: 0.6095\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.5413 - accuracy: 0.8343 - val_loss: 1.3034 - val_accuracy: 0.6147\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.5074 - accuracy: 0.8465 - val_loss: 1.3026 - val_accuracy: 0.6182\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.4867 - accuracy: 0.8513 - val_loss: 1.3059 - val_accuracy: 0.6167\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.4539 - accuracy: 0.8656 - val_loss: 1.3060 - val_accuracy: 0.6192\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.4296 - accuracy: 0.8740 - val_loss: 1.3092 - val_accuracy: 0.6237\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 12s 45ms/step - loss: 0.4179 - accuracy: 0.8771 - val_loss: 1.3135 - val_accuracy: 0.6238\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.3898 - accuracy: 0.8883 - val_loss: 1.3181 - val_accuracy: 0.6247\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 12s 44ms/step - loss: 0.3742 - accuracy: 0.8912 - val_loss: 1.3229 - val_accuracy: 0.6232\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 1.3091 - accuracy: 0.6121\n",
            "120.0 1.0 1.1325350120506736 0.5253668246300633 0.19357447645168743 0.10651775132599338 0.27080396917424804\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dc3d950> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792d74590> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792d89d90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e3e2490> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 22s 55ms/step - loss: 5.7726 - accuracy: 0.0110 - val_loss: 4.5912 - val_accuracy: 0.0239\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 5.1709 - accuracy: 0.0269 - val_loss: 4.2638 - val_accuracy: 0.0593\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 4.6946 - accuracy: 0.0518 - val_loss: 3.8964 - val_accuracy: 0.1237\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 13s 47ms/step - loss: 4.2861 - accuracy: 0.0875 - val_loss: 3.5877 - val_accuracy: 0.1712\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 3.9670 - accuracy: 0.1177 - val_loss: 3.3334 - val_accuracy: 0.2058\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 3.7117 - accuracy: 0.1503 - val_loss: 3.1269 - val_accuracy: 0.2404\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 3.4802 - accuracy: 0.1780 - val_loss: 2.9506 - val_accuracy: 0.2758\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 3.2855 - accuracy: 0.2080 - val_loss: 2.8033 - val_accuracy: 0.2989\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 3.1285 - accuracy: 0.2269 - val_loss: 2.6731 - val_accuracy: 0.3233\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.9736 - accuracy: 0.2571 - val_loss: 2.5607 - val_accuracy: 0.3374\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.8535 - accuracy: 0.2689 - val_loss: 2.4646 - val_accuracy: 0.3546\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 12s 46ms/step - loss: 2.7523 - accuracy: 0.2802 - val_loss: 2.3789 - val_accuracy: 0.3634\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.6454 - accuracy: 0.3018 - val_loss: 2.3047 - val_accuracy: 0.3768\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 2.5585 - accuracy: 0.3204 - val_loss: 2.2391 - val_accuracy: 0.3860\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 13s 47ms/step - loss: 2.4799 - accuracy: 0.3258 - val_loss: 2.1799 - val_accuracy: 0.3951\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.3921 - accuracy: 0.3468 - val_loss: 2.1279 - val_accuracy: 0.4043\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 13s 47ms/step - loss: 2.3379 - accuracy: 0.3575 - val_loss: 2.0797 - val_accuracy: 0.4174\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 2.2900 - accuracy: 0.3598 - val_loss: 2.0401 - val_accuracy: 0.4252\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.2346 - accuracy: 0.3761 - val_loss: 2.0031 - val_accuracy: 0.4342\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.1870 - accuracy: 0.3887 - val_loss: 1.9658 - val_accuracy: 0.4395\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 13s 48ms/step - loss: 2.1252 - accuracy: 0.4023 - val_loss: 1.9343 - val_accuracy: 0.4486\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.0878 - accuracy: 0.4124 - val_loss: 1.9064 - val_accuracy: 0.4573\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 2.0345 - accuracy: 0.4223 - val_loss: 1.8793 - val_accuracy: 0.4626\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 12s 47ms/step - loss: 1.9998 - accuracy: 0.4231 - val_loss: 1.8542 - val_accuracy: 0.4671\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.9614 - accuracy: 0.4323 - val_loss: 1.8307 - val_accuracy: 0.4724\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.9344 - accuracy: 0.4392 - val_loss: 1.8092 - val_accuracy: 0.4759\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.8886 - accuracy: 0.4540 - val_loss: 1.7901 - val_accuracy: 0.4822\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.8691 - accuracy: 0.4573 - val_loss: 1.7720 - val_accuracy: 0.4884\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.8328 - accuracy: 0.4627 - val_loss: 1.7538 - val_accuracy: 0.4902\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 13s 49ms/step - loss: 1.7912 - accuracy: 0.4725 - val_loss: 1.7377 - val_accuracy: 0.4950\n",
            "64/64 [==============================] - 3s 30ms/step - loss: 1.7161 - accuracy: 0.4960\n",
            "120.0 0.9428534390551151 0.0 0.5515554841323576 0.2741821347018553 0.2 0.5748032819006894\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d273cd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b261d50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 35s 48ms/step - loss: 1.3330 - accuracy: 0.6167 - val_loss: 1.4536 - val_accuracy: 0.6531\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 24s 44ms/step - loss: 0.1633 - accuracy: 0.9468 - val_loss: 1.5422 - val_accuracy: 0.6732\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.1078 - accuracy: 0.9651 - val_loss: 1.6590 - val_accuracy: 0.6823\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0775 - accuracy: 0.9741 - val_loss: 1.6598 - val_accuracy: 0.6767\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 1.8438 - val_accuracy: 0.6830\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0763 - accuracy: 0.9744 - val_loss: 2.1158 - val_accuracy: 0.6672\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 1.8832 - val_accuracy: 0.6907\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 2.0552 - val_accuracy: 0.6838\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 2.0063 - val_accuracy: 0.6740\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 2.1830 - val_accuracy: 0.6799\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 2.1950 - val_accuracy: 0.6956\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 2.2289 - val_accuracy: 0.6910\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 24s 45ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 2.3782 - val_accuracy: 0.6734\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0522 - accuracy: 0.9845 - val_loss: 2.3333 - val_accuracy: 0.6782\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 23s 44ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 2.2813 - val_accuracy: 0.6927\n",
            "128/128 [==============================] - 4s 24ms/step - loss: 2.3117 - accuracy: 0.6830\n",
            "Model N. 5   Accuracy =  0.6829833984375 Loss =  2.3116912841796875 parameters =  [120.           0.94285344   0.           0.55155548   0.27418213\n",
            "   0.2          0.57480328   0.4656209 ] \n",
            "\n",
            "Stopping search: Swarm best position change less than 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXBDuNP-hBVP"
      },
      "source": [
        "### Resnet50V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlXJxXopha2z"
      },
      "source": [
        "count=0\r\n",
        "max=0\r\n",
        "lb=[0,0,0,0,0,0.001,0,0]\r\n",
        "ub=[49,1,3,0.65,0.65,0.2,1,3]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV4YwiJ-hbFx"
      },
      "source": [
        "def create_model_resnet(x):\r\n",
        "  print(x[0],x[1],x[2],x[3],x[4],x[5],x[6])\r\n",
        "  IMG_SHAPE1=(32,32,3) \r\n",
        "\r\n",
        "  dense=tf.keras.applications.ResNet50V2(input_shape=IMG_SHAPE1,\r\n",
        "                                               include_top=False,\r\n",
        "                                               weights='imagenet') \r\n",
        "  tempre=dense\r\n",
        "  for layer in tempre.layers[:(-1)*int(round(x[0]))]:\r\n",
        "    layer.trainable = False\r\n",
        "  \r\n",
        "  #vgg19.trainable=False\r\n",
        "  model = tf.keras.Sequential()\r\n",
        "  model.add(tempre)\r\n",
        "  if (int(round(x[1]))):\r\n",
        "    model.add(keras.layers.Flatten())\r\n",
        "  else:\r\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\r\n",
        "  \r\n",
        "  if (int(round(x[2]))==3):\r\n",
        "    model.add(keras.layers.Dense(2048, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(0.5))\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==2):\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==1):\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "\r\n",
        "  for layer in model.layers:\r\n",
        "    print(layer, layer.trainable)\r\n",
        "  model.add(keras.layers.Dense(100,activation=\"softmax\"))\r\n",
        "  if x[5]< 0.003:\r\n",
        "    learning_rate = 0.0000005\r\n",
        "  elif x[5]< 0.0075:\r\n",
        "    learning_rate = 0.000001\r\n",
        "  elif x[5]< 0.015:\r\n",
        "    learning_rate = 0.000005\r\n",
        "  elif x[5]< 0.035:\r\n",
        "    learning_rate = 0.00001\r\n",
        "  elif x[5]< 0.075:\r\n",
        "    learning_rate = 0.00005\r\n",
        "  elif x[5]< 0.125:\r\n",
        "    learning_rate = 0.0001\r\n",
        "  elif x[5]< 0.175:\r\n",
        "    learning_rate = 0.0005\r\n",
        "  else:\r\n",
        "    learning_rate = 0.001\r\n",
        "\r\n",
        "  if (x[6]<0.5):\r\n",
        "    opt = keras.optimizers.SGD(learning_rate=learning_rate)\r\n",
        "  else:\r\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRVpWDdUhbYb"
      },
      "source": [
        "def apple(x):\r\n",
        "  global max\r\n",
        "  model = create_model_resnet(x)\r\n",
        "  if (x[7]<1):\r\n",
        "    model.fit(train_32_b64, epochs=30, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_32_b64,validation_steps=94,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b64, verbose=1,steps=128)\r\n",
        "  elif (x[7]<2):\r\n",
        "    model.fit(train_32_b128, epochs=30, batch_size=128,steps_per_epoch=264 ,verbose=1,validation_data=validation_32_b128,validation_steps=47,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b128, verbose=1,steps=64)\r\n",
        "  else:\r\n",
        "    model.fit(train_32_b256, epochs=30, batch_size=256, steps_per_epoch=132, verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "  if acc>max:\r\n",
        "    global count \r\n",
        "    max=acc\r\n",
        "    count = count+1\r\n",
        "    print(\"Model N.\",count,\"  Accuracy = \",acc,\"Loss = \",loss, \"parameters = \",x,\"\\n\")\r\n",
        "  return (1/(1+acc))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLkISOYIhbne",
        "outputId": "9a0f6158-31c0-40ab-cd51-d1baa961d03b"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34.7191434981271 0.6203340708447013 0.21264130734858122 0.2498512578443716 0.09773406440466369 0.11329705383635899 0.3752216497000024\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d271a90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97918c5ad0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 5.0067 - accuracy: 0.0136 - val_loss: 4.5468 - val_accuracy: 0.0293\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 4.4656 - accuracy: 0.0455 - val_loss: 4.3564 - val_accuracy: 0.0647\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 4.2302 - accuracy: 0.0877 - val_loss: 4.1314 - val_accuracy: 0.1014\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 3.9874 - accuracy: 0.1326 - val_loss: 3.9414 - val_accuracy: 0.1385\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 3.7415 - accuracy: 0.1842 - val_loss: 3.7627 - val_accuracy: 0.1621\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 3.5245 - accuracy: 0.2193 - val_loss: 3.6116 - val_accuracy: 0.1890\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 3.3110 - accuracy: 0.2638 - val_loss: 3.4769 - val_accuracy: 0.2121\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 3.1277 - accuracy: 0.2983 - val_loss: 3.3376 - val_accuracy: 0.2354\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.9447 - accuracy: 0.3344 - val_loss: 3.2173 - val_accuracy: 0.2507\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.7912 - accuracy: 0.3567 - val_loss: 3.1140 - val_accuracy: 0.2729\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.6392 - accuracy: 0.3919 - val_loss: 3.0241 - val_accuracy: 0.2816\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.4923 - accuracy: 0.4174 - val_loss: 2.9281 - val_accuracy: 0.2977\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.3522 - accuracy: 0.4426 - val_loss: 2.8356 - val_accuracy: 0.3105\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.2262 - accuracy: 0.4685 - val_loss: 2.7683 - val_accuracy: 0.3155\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.1241 - accuracy: 0.4843 - val_loss: 2.7104 - val_accuracy: 0.3195\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.0216 - accuracy: 0.5057 - val_loss: 2.6620 - val_accuracy: 0.3319\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.9262 - accuracy: 0.5209 - val_loss: 2.6095 - val_accuracy: 0.3429\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.8393 - accuracy: 0.5384 - val_loss: 2.5680 - val_accuracy: 0.3464\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.7443 - accuracy: 0.5590 - val_loss: 2.5250 - val_accuracy: 0.3476\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.6629 - accuracy: 0.5774 - val_loss: 2.5001 - val_accuracy: 0.3542\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.5783 - accuracy: 0.5952 - val_loss: 2.4672 - val_accuracy: 0.3607\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.5217 - accuracy: 0.6093 - val_loss: 2.4402 - val_accuracy: 0.3717\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.4459 - accuracy: 0.6260 - val_loss: 2.4010 - val_accuracy: 0.3740\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.3822 - accuracy: 0.6426 - val_loss: 2.3866 - val_accuracy: 0.3821\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.3260 - accuracy: 0.6554 - val_loss: 2.3618 - val_accuracy: 0.3890\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.2691 - accuracy: 0.6702 - val_loss: 2.3420 - val_accuracy: 0.3916\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.2208 - accuracy: 0.6794 - val_loss: 2.3381 - val_accuracy: 0.3956\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.1673 - accuracy: 0.6944 - val_loss: 2.3225 - val_accuracy: 0.3944\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.1274 - accuracy: 0.7054 - val_loss: 2.3110 - val_accuracy: 0.3953\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.0855 - accuracy: 0.7176 - val_loss: 2.2998 - val_accuracy: 0.3938\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2793 - accuracy: 0.3945\n",
            "Model N. 1   Accuracy =  0.39453125 Loss =  2.2792747020721436 parameters =  [34.7191435   0.62033407  0.21264131  0.24985126  0.09773406  0.11329705\n",
            "  0.37522165  0.16078744] \n",
            "\n",
            "45.05515570898315 0.6419271590683453 0.14392307030206453 0.09262478943167604 0.39233687921766486 0.14924712745072832 0.26949747900763876\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f39f10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e0ee3d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.6317 - accuracy: 0.0394 - val_loss: 4.0129 - val_accuracy: 0.1454\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.6635 - accuracy: 0.1983 - val_loss: 3.4159 - val_accuracy: 0.2317\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.9284 - accuracy: 0.3380 - val_loss: 2.9270 - val_accuracy: 0.3032\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.3531 - accuracy: 0.4385 - val_loss: 2.5653 - val_accuracy: 0.3723\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.8962 - accuracy: 0.5281 - val_loss: 2.3299 - val_accuracy: 0.4029\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.5489 - accuracy: 0.5881 - val_loss: 2.2002 - val_accuracy: 0.4192\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.3091 - accuracy: 0.6491 - val_loss: 2.1419 - val_accuracy: 0.4325\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.1118 - accuracy: 0.7015 - val_loss: 2.0871 - val_accuracy: 0.4377\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9650 - accuracy: 0.7362 - val_loss: 2.0566 - val_accuracy: 0.4490\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8277 - accuracy: 0.7779 - val_loss: 2.0442 - val_accuracy: 0.4651\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7338 - accuracy: 0.8058 - val_loss: 2.0293 - val_accuracy: 0.4638\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6398 - accuracy: 0.8325 - val_loss: 2.0159 - val_accuracy: 0.4726\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5763 - accuracy: 0.8493 - val_loss: 2.0233 - val_accuracy: 0.4787\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5084 - accuracy: 0.8687 - val_loss: 2.0295 - val_accuracy: 0.4872\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4346 - accuracy: 0.8903 - val_loss: 2.0261 - val_accuracy: 0.4852\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3966 - accuracy: 0.9013 - val_loss: 2.0448 - val_accuracy: 0.4834\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3553 - accuracy: 0.9117 - val_loss: 2.0384 - val_accuracy: 0.4882\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3089 - accuracy: 0.9275 - val_loss: 2.0503 - val_accuracy: 0.4840\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2720 - accuracy: 0.9381 - val_loss: 2.0448 - val_accuracy: 0.4812\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2487 - accuracy: 0.9429 - val_loss: 2.0664 - val_accuracy: 0.4830\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2297 - accuracy: 0.9473 - val_loss: 2.0470 - val_accuracy: 0.4915\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2082 - accuracy: 0.9524 - val_loss: 2.0657 - val_accuracy: 0.4900\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1922 - accuracy: 0.9586 - val_loss: 2.0806 - val_accuracy: 0.4864\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1716 - accuracy: 0.9625 - val_loss: 2.0946 - val_accuracy: 0.4907\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1653 - accuracy: 0.9629 - val_loss: 2.0975 - val_accuracy: 0.4947\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1498 - accuracy: 0.9685 - val_loss: 2.1291 - val_accuracy: 0.5015\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1374 - accuracy: 0.9711 - val_loss: 2.1557 - val_accuracy: 0.4887\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1210 - accuracy: 0.9747 - val_loss: 2.1579 - val_accuracy: 0.4930\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1212 - accuracy: 0.9755 - val_loss: 2.1863 - val_accuracy: 0.5005\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1091 - accuracy: 0.9785 - val_loss: 2.1823 - val_accuracy: 0.4950\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1590 - accuracy: 0.4991\n",
            "Model N. 2   Accuracy =  0.4991455078125 Loss =  2.1589901447296143 parameters =  [4.50551557e+01 6.41927159e-01 1.43923070e-01 9.26247894e-02\n",
            " 3.92336879e-01 1.49247127e-01 2.69497479e-01 4.01068986e-02] \n",
            "\n",
            "24.12991578769365 0.6236954072437758 0.7224380673225406 0.268486397154376 0.29954056143734353 0.048765214224910765 0.18260432965038287\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9a4fb203d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9a201890d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99ce083290> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979971b710> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 12s 54ms/step - loss: 5.2287 - accuracy: 0.0198 - val_loss: 4.6662 - val_accuracy: 0.0176\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 5.0675 - accuracy: 0.0194 - val_loss: 4.6693 - val_accuracy: 0.0168\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.9396 - accuracy: 0.0198 - val_loss: 4.6819 - val_accuracy: 0.0259\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.8097 - accuracy: 0.0229 - val_loss: 4.6871 - val_accuracy: 0.0215\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.7044 - accuracy: 0.0246 - val_loss: 4.6678 - val_accuracy: 0.0269\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.6380 - accuracy: 0.0276 - val_loss: 4.6289 - val_accuracy: 0.0308\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.5867 - accuracy: 0.0282 - val_loss: 4.5918 - val_accuracy: 0.0311\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.5482 - accuracy: 0.0308 - val_loss: 4.5605 - val_accuracy: 0.0342\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.5298 - accuracy: 0.0327 - val_loss: 4.5432 - val_accuracy: 0.0376\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.5025 - accuracy: 0.0329 - val_loss: 4.5195 - val_accuracy: 0.0426\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.4621 - accuracy: 0.0366 - val_loss: 4.5023 - val_accuracy: 0.0464\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.4484 - accuracy: 0.0397 - val_loss: 4.4865 - val_accuracy: 0.0496\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.4197 - accuracy: 0.0441 - val_loss: 4.4683 - val_accuracy: 0.0469\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.4026 - accuracy: 0.0478 - val_loss: 4.4490 - val_accuracy: 0.0490\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 5s 42ms/step - loss: 4.3712 - accuracy: 0.0488 - val_loss: 4.4293 - val_accuracy: 0.0531\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.3524 - accuracy: 0.0523 - val_loss: 4.4109 - val_accuracy: 0.0522\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.3159 - accuracy: 0.0571 - val_loss: 4.3937 - val_accuracy: 0.0566\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.2877 - accuracy: 0.0617 - val_loss: 4.3718 - val_accuracy: 0.0565\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.2653 - accuracy: 0.0652 - val_loss: 4.3563 - val_accuracy: 0.0601\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.2392 - accuracy: 0.0687 - val_loss: 4.3375 - val_accuracy: 0.0666\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.2019 - accuracy: 0.0744 - val_loss: 4.3180 - val_accuracy: 0.0708\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.1782 - accuracy: 0.0775 - val_loss: 4.3028 - val_accuracy: 0.0711\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.1371 - accuracy: 0.0825 - val_loss: 4.2839 - val_accuracy: 0.0729\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.1186 - accuracy: 0.0850 - val_loss: 4.2608 - val_accuracy: 0.0723\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.0860 - accuracy: 0.0920 - val_loss: 4.2410 - val_accuracy: 0.0700\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.0568 - accuracy: 0.0933 - val_loss: 4.2211 - val_accuracy: 0.0728\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.0163 - accuracy: 0.0983 - val_loss: 4.2043 - val_accuracy: 0.0776\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 5s 42ms/step - loss: 3.9742 - accuracy: 0.1057 - val_loss: 4.1829 - val_accuracy: 0.0778\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 3.9570 - accuracy: 0.1087 - val_loss: 4.1696 - val_accuracy: 0.0783\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 3.9227 - accuracy: 0.1138 - val_loss: 4.1482 - val_accuracy: 0.0819\n",
            "32/32 [==============================] - 2s 31ms/step - loss: 4.1314 - accuracy: 0.0878\n",
            "9.581149124417399 0.5202323652303815 1.808988456804158 0.35488392489750753 0.5482906407146811 0.10915726532863186 0.5718265524004978\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97990bdbd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978efaf350> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978efbcd50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f6880d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978efbead0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978efbe190> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 10s 48ms/step - loss: 4.1213 - accuracy: 0.0840 - val_loss: 3.2822 - val_accuracy: 0.2568\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 2.3508 - accuracy: 0.3196 - val_loss: 2.3637 - val_accuracy: 0.3564\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 6s 42ms/step - loss: 1.6178 - accuracy: 0.5065 - val_loss: 2.0601 - val_accuracy: 0.3979\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 1.0555 - accuracy: 0.6744 - val_loss: 2.1426 - val_accuracy: 0.3870\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 0.6226 - accuracy: 0.8135 - val_loss: 2.3600 - val_accuracy: 0.4069\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.3491 - accuracy: 0.9007 - val_loss: 2.5991 - val_accuracy: 0.4089\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.1876 - accuracy: 0.9504 - val_loss: 2.7821 - val_accuracy: 0.3968\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.1074 - accuracy: 0.9746 - val_loss: 2.9771 - val_accuracy: 0.4009\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0664 - accuracy: 0.9854 - val_loss: 3.1492 - val_accuracy: 0.4041\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0447 - accuracy: 0.9903 - val_loss: 3.2792 - val_accuracy: 0.4022\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 3.4313 - accuracy: 0.3994\n",
            "45.99191703484342 0.4687673645242516 2.280218623254144 0.31056702151259763 0.6052653799555472 0.03739217876707755 0.9837269873216066\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f4b3610> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978d9a9390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97925a8790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97929f7490> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791666cd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d57ffd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 12s 55ms/step - loss: 4.4880 - accuracy: 0.0456 - val_loss: 3.5450 - val_accuracy: 0.1781\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 2.9259 - accuracy: 0.1982 - val_loss: 2.5315 - val_accuracy: 0.3154\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 2.1299 - accuracy: 0.3702 - val_loss: 2.0346 - val_accuracy: 0.4062\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.4879 - accuracy: 0.5499 - val_loss: 1.8917 - val_accuracy: 0.4518\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9912 - accuracy: 0.6932 - val_loss: 1.9103 - val_accuracy: 0.4671\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.6235 - accuracy: 0.8083 - val_loss: 1.9992 - val_accuracy: 0.4598\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.3718 - accuracy: 0.8882 - val_loss: 2.1377 - val_accuracy: 0.4676\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.2308 - accuracy: 0.9317 - val_loss: 2.2706 - val_accuracy: 0.4626\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.1362 - accuracy: 0.9623 - val_loss: 2.3227 - val_accuracy: 0.4658\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.0826 - accuracy: 0.9785 - val_loss: 2.4109 - val_accuracy: 0.4744\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 2.5535 - val_accuracy: 0.4767\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.0451 - accuracy: 0.9879 - val_loss: 2.6556 - val_accuracy: 0.4771\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 2.7320 - val_accuracy: 0.4738\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 0.0271 - accuracy: 0.9934 - val_loss: 2.7271 - val_accuracy: 0.4806\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 2.7775 - val_accuracy: 0.4826\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 2.8738 - val_accuracy: 0.4759\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 2.9052 - val_accuracy: 0.4850\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 2.9229 - val_accuracy: 0.4959\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 2.9916 - val_accuracy: 0.4914\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 3.1152 - val_accuracy: 0.4844\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 3.1674 - val_accuracy: 0.4821\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.0210 - accuracy: 0.9950 - val_loss: 3.1881 - val_accuracy: 0.4873\n",
            "32/32 [==============================] - 2s 30ms/step - loss: 3.1842 - accuracy: 0.4810\n",
            "13.151637549303203 0.3167769371682848 2.9867658969597697 0.5345822157944082 0.5753434962212229 0.12293569223555148 0.7628890570539153\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978ce04ed0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978d047050> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dd6c850> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e103dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e0ed910> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e101f90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e0ed050> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798f91950> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 13s 35ms/step - loss: 4.1709 - accuracy: 0.0596 - val_loss: 2.8631 - val_accuracy: 0.2680\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 2.7207 - accuracy: 0.1971 - val_loss: 2.2508 - val_accuracy: 0.3215\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 8s 30ms/step - loss: 2.1287 - accuracy: 0.3328 - val_loss: 2.0930 - val_accuracy: 0.3712\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 1.6102 - accuracy: 0.4737 - val_loss: 2.1336 - val_accuracy: 0.3958\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 1.1279 - accuracy: 0.6242 - val_loss: 2.4259 - val_accuracy: 0.4018\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 8s 30ms/step - loss: 0.7153 - accuracy: 0.7596 - val_loss: 2.8778 - val_accuracy: 0.4064\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 0.4203 - accuracy: 0.8632 - val_loss: 3.3134 - val_accuracy: 0.3956\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 0.2607 - accuracy: 0.9183 - val_loss: 3.6229 - val_accuracy: 0.3941\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 0.1715 - accuracy: 0.9471 - val_loss: 3.9263 - val_accuracy: 0.3797\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 8s 30ms/step - loss: 0.1193 - accuracy: 0.9634 - val_loss: 4.0805 - val_accuracy: 0.3823\n",
            "64/64 [==============================] - 2s 20ms/step - loss: 3.9739 - accuracy: 0.3947\n",
            "5.079778341925333 0.7957395540632755 0.8146463608491029 0.46866598646771634 0.01533511223644995 0.04722616093922525 0.8727122337641209\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978cfa71d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d100590> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d100e50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799cc9e10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 16s 22ms/step - loss: 3.8934 - accuracy: 0.1436 - val_loss: 2.3367 - val_accuracy: 0.3401\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 2.0644 - accuracy: 0.4077 - val_loss: 2.0611 - val_accuracy: 0.4019\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 1.5505 - accuracy: 0.5358 - val_loss: 1.9789 - val_accuracy: 0.4205\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 1.2205 - accuracy: 0.6355 - val_loss: 1.9334 - val_accuracy: 0.4372\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.9729 - accuracy: 0.7154 - val_loss: 1.9383 - val_accuracy: 0.4480\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.7698 - accuracy: 0.7774 - val_loss: 1.9679 - val_accuracy: 0.4574\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.6085 - accuracy: 0.8304 - val_loss: 2.0144 - val_accuracy: 0.4490\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.4743 - accuracy: 0.8745 - val_loss: 2.0932 - val_accuracy: 0.4332\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.3728 - accuracy: 0.9058 - val_loss: 2.1388 - val_accuracy: 0.4573\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 11s 21ms/step - loss: 0.2866 - accuracy: 0.9338 - val_loss: 2.2581 - val_accuracy: 0.4456\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.1939 - accuracy: 0.4617\n",
            "2.552138068845491 0.06211508328964732 0.6396450414381187 0.49118061650982325 0.4491699288655913 0.18748540986527826 0.38557920452500827\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97916e3e10> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978efbfcd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97992b6910> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f6be690> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 12s 29ms/step - loss: 5.3359 - accuracy: 0.0207 - val_loss: 3.9906 - val_accuracy: 0.1021\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 4.1258 - accuracy: 0.0896 - val_loss: 3.4102 - val_accuracy: 0.1705\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 3.6627 - accuracy: 0.1374 - val_loss: 3.1465 - val_accuracy: 0.2181\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 3.3900 - accuracy: 0.1695 - val_loss: 2.9804 - val_accuracy: 0.2410\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 3.1877 - accuracy: 0.1995 - val_loss: 2.8581 - val_accuracy: 0.2563\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 3.0392 - accuracy: 0.2179 - val_loss: 2.7658 - val_accuracy: 0.2746\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.9250 - accuracy: 0.2362 - val_loss: 2.6966 - val_accuracy: 0.2904\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.8260 - accuracy: 0.2553 - val_loss: 2.6360 - val_accuracy: 0.3044\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.7531 - accuracy: 0.2630 - val_loss: 2.5849 - val_accuracy: 0.3112\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.6670 - accuracy: 0.2808 - val_loss: 2.5445 - val_accuracy: 0.3246\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.5980 - accuracy: 0.2928 - val_loss: 2.5042 - val_accuracy: 0.3334\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.5402 - accuracy: 0.2985 - val_loss: 2.4701 - val_accuracy: 0.3378\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.4732 - accuracy: 0.3155 - val_loss: 2.4403 - val_accuracy: 0.3428\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.4402 - accuracy: 0.3232 - val_loss: 2.4128 - val_accuracy: 0.3466\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.3850 - accuracy: 0.3322 - val_loss: 2.3879 - val_accuracy: 0.3492\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.3499 - accuracy: 0.3379 - val_loss: 2.3640 - val_accuracy: 0.3517\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.3067 - accuracy: 0.3504 - val_loss: 2.3430 - val_accuracy: 0.3514\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.2663 - accuracy: 0.3564 - val_loss: 2.3249 - val_accuracy: 0.3547\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.2314 - accuracy: 0.3609 - val_loss: 2.3058 - val_accuracy: 0.3561\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.2082 - accuracy: 0.3663 - val_loss: 2.2876 - val_accuracy: 0.3549\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.1785 - accuracy: 0.3792 - val_loss: 2.2720 - val_accuracy: 0.3575\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.1292 - accuracy: 0.3868 - val_loss: 2.2592 - val_accuracy: 0.3634\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.1196 - accuracy: 0.3906 - val_loss: 2.2445 - val_accuracy: 0.3695\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.0829 - accuracy: 0.3949 - val_loss: 2.2313 - val_accuracy: 0.3700\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.0604 - accuracy: 0.4070 - val_loss: 2.2152 - val_accuracy: 0.3672\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 2.0317 - accuracy: 0.4100 - val_loss: 2.2058 - val_accuracy: 0.3730\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 2.0188 - accuracy: 0.4110 - val_loss: 2.1949 - val_accuracy: 0.3772\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 1.9901 - accuracy: 0.4240 - val_loss: 2.1883 - val_accuracy: 0.3773\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 7s 25ms/step - loss: 1.9750 - accuracy: 0.4188 - val_loss: 2.1772 - val_accuracy: 0.3797\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 7s 26ms/step - loss: 1.9531 - accuracy: 0.4315 - val_loss: 2.1695 - val_accuracy: 0.3795\n",
            "64/64 [==============================] - 2s 19ms/step - loss: 2.1568 - accuracy: 0.3915\n",
            "27.84293768298978 0.659821208894719 2.9503383202857876 0.5148630392214589 0.28458983627919354 0.18259890671278978 0.10754455070510471\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d761e10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f7c3310> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ceed090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bfa51e90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799755290> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9793ac6050> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ceedf90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dec1dd0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 13s 35ms/step - loss: 4.7527 - accuracy: 0.0221 - val_loss: 4.4147 - val_accuracy: 0.0565\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 9s 32ms/step - loss: 4.1253 - accuracy: 0.0514 - val_loss: 3.7556 - val_accuracy: 0.0800\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 3.6098 - accuracy: 0.0695 - val_loss: 3.2806 - val_accuracy: 0.1225\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 3.3332 - accuracy: 0.0870 - val_loss: 2.9897 - val_accuracy: 0.1787\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 3.1215 - accuracy: 0.1159 - val_loss: 2.7853 - val_accuracy: 0.2380\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 2.9376 - accuracy: 0.1461 - val_loss: 2.6511 - val_accuracy: 0.2626\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 2.7981 - accuracy: 0.1792 - val_loss: 2.5635 - val_accuracy: 0.2812\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 2.6693 - accuracy: 0.2111 - val_loss: 2.4438 - val_accuracy: 0.2965\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 2.5302 - accuracy: 0.2379 - val_loss: 2.3513 - val_accuracy: 0.3193\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 2.3993 - accuracy: 0.2729 - val_loss: 2.2817 - val_accuracy: 0.3314\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 2.2612 - accuracy: 0.3084 - val_loss: 2.1988 - val_accuracy: 0.3489\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 2.1507 - accuracy: 0.3442 - val_loss: 2.1426 - val_accuracy: 0.3632\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 2.0183 - accuracy: 0.3807 - val_loss: 2.1138 - val_accuracy: 0.3640\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 1.9046 - accuracy: 0.4119 - val_loss: 2.0831 - val_accuracy: 0.3763\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 1.8035 - accuracy: 0.4346 - val_loss: 2.0567 - val_accuracy: 0.4029\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.6683 - accuracy: 0.4762 - val_loss: 2.0591 - val_accuracy: 0.4048\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.5632 - accuracy: 0.5041 - val_loss: 2.0211 - val_accuracy: 0.4054\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.4706 - accuracy: 0.5317 - val_loss: 2.0542 - val_accuracy: 0.4059\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.3663 - accuracy: 0.5626 - val_loss: 2.0471 - val_accuracy: 0.4199\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.2450 - accuracy: 0.5982 - val_loss: 2.0774 - val_accuracy: 0.4272\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 9s 34ms/step - loss: 1.1488 - accuracy: 0.6282 - val_loss: 2.1041 - val_accuracy: 0.4295\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 1.0521 - accuracy: 0.6651 - val_loss: 2.1446 - val_accuracy: 0.4417\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.9816 - accuracy: 0.6844 - val_loss: 2.1863 - val_accuracy: 0.4358\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 9s 32ms/step - loss: 0.8889 - accuracy: 0.7161 - val_loss: 2.2044 - val_accuracy: 0.4435\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.8010 - accuracy: 0.7398 - val_loss: 2.2722 - val_accuracy: 0.4468\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.7249 - accuracy: 0.7707 - val_loss: 2.3410 - val_accuracy: 0.4403\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.6534 - accuracy: 0.7921 - val_loss: 2.3420 - val_accuracy: 0.4481\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.5784 - accuracy: 0.8189 - val_loss: 2.4344 - val_accuracy: 0.4516\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.5128 - accuracy: 0.8393 - val_loss: 2.4800 - val_accuracy: 0.4503\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 9s 33ms/step - loss: 0.4525 - accuracy: 0.8609 - val_loss: 2.5127 - val_accuracy: 0.4516\n",
            "64/64 [==============================] - 2s 20ms/step - loss: 2.4077 - accuracy: 0.4529\n",
            "15.550840662430685 0.8057169405665658 2.025213016820224 0.3442356227920552 0.5223982234850568 0.1258754917197224 0.3675951925847968\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d669b50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e2f9e10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b84e950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b85c090> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b84ecd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d662bd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 11s 51ms/step - loss: 5.2719 - accuracy: 0.0134 - val_loss: 4.5452 - val_accuracy: 0.0329\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.6174 - accuracy: 0.0290 - val_loss: 4.4502 - val_accuracy: 0.0594\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.4605 - accuracy: 0.0404 - val_loss: 4.3107 - val_accuracy: 0.0962\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.3372 - accuracy: 0.0544 - val_loss: 4.1367 - val_accuracy: 0.1133\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 4.1959 - accuracy: 0.0713 - val_loss: 3.9634 - val_accuracy: 0.1261\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 4.0651 - accuracy: 0.0837 - val_loss: 3.8123 - val_accuracy: 0.1398\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 3.9410 - accuracy: 0.0941 - val_loss: 3.6738 - val_accuracy: 0.1493\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 3.8184 - accuracy: 0.1041 - val_loss: 3.5443 - val_accuracy: 0.1637\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 3.6895 - accuracy: 0.1122 - val_loss: 3.4248 - val_accuracy: 0.1701\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 3.5848 - accuracy: 0.1221 - val_loss: 3.3048 - val_accuracy: 0.1812\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 3.4479 - accuracy: 0.1371 - val_loss: 3.2020 - val_accuracy: 0.1938\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 3.3548 - accuracy: 0.1462 - val_loss: 3.0980 - val_accuracy: 0.2087\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 3.2586 - accuracy: 0.1574 - val_loss: 3.0104 - val_accuracy: 0.2184\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 3.1522 - accuracy: 0.1718 - val_loss: 2.9281 - val_accuracy: 0.2373\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 3.0626 - accuracy: 0.1837 - val_loss: 2.8520 - val_accuracy: 0.2459\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 2.9912 - accuracy: 0.1945 - val_loss: 2.7889 - val_accuracy: 0.2520\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 2.9082 - accuracy: 0.2037 - val_loss: 2.7387 - val_accuracy: 0.2601\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 2.8519 - accuracy: 0.2149 - val_loss: 2.6926 - val_accuracy: 0.2625\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.7822 - accuracy: 0.2252 - val_loss: 2.6479 - val_accuracy: 0.2681\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.7242 - accuracy: 0.2363 - val_loss: 2.6059 - val_accuracy: 0.2780\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.6618 - accuracy: 0.2445 - val_loss: 2.5780 - val_accuracy: 0.2790\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.6131 - accuracy: 0.2521 - val_loss: 2.5450 - val_accuracy: 0.2812\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 2.5801 - accuracy: 0.2615 - val_loss: 2.5189 - val_accuracy: 0.2899\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.5234 - accuracy: 0.2725 - val_loss: 2.4917 - val_accuracy: 0.2933\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.4935 - accuracy: 0.2796 - val_loss: 2.4675 - val_accuracy: 0.2943\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 2.4205 - accuracy: 0.2982 - val_loss: 2.4463 - val_accuracy: 0.2930\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.3848 - accuracy: 0.3022 - val_loss: 2.4261 - val_accuracy: 0.2998\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.3601 - accuracy: 0.3080 - val_loss: 2.4105 - val_accuracy: 0.3005\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.3121 - accuracy: 0.3261 - val_loss: 2.3940 - val_accuracy: 0.3049\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 2.2795 - accuracy: 0.3297 - val_loss: 2.3730 - val_accuracy: 0.3101\n",
            "32/32 [==============================] - 2s 31ms/step - loss: 2.4024 - accuracy: 0.2966\n",
            "38.709263884078254 0.6372874622311722 0.0 0.22659040125627483 0.1622796448542807 0.17476871121715026 0.5805181502928658\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799953ad0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b6ce610> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 2.2254 - accuracy: 0.4124 - val_loss: 1.7399 - val_accuracy: 0.5382\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2649 - accuracy: 0.9216 - val_loss: 2.0534 - val_accuracy: 0.5357\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1035 - accuracy: 0.9708 - val_loss: 2.2203 - val_accuracy: 0.5459\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0998 - accuracy: 0.9720 - val_loss: 2.4211 - val_accuracy: 0.5374\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0875 - accuracy: 0.9729 - val_loss: 2.2689 - val_accuracy: 0.5613\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 2.4073 - val_accuracy: 0.5642\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0750 - accuracy: 0.9776 - val_loss: 3.0666 - val_accuracy: 0.5469\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1299 - accuracy: 0.9697 - val_loss: 2.3149 - val_accuracy: 0.5557\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0241 - accuracy: 0.9940 - val_loss: 2.4185 - val_accuracy: 0.5667\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 2.8537 - val_accuracy: 0.5484\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0918 - accuracy: 0.9737 - val_loss: 3.3460 - val_accuracy: 0.5317\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1591 - accuracy: 0.9730 - val_loss: 4.8042 - val_accuracy: 0.5332\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0636 - accuracy: 0.9887 - val_loss: 2.4217 - val_accuracy: 0.5550\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.4941 - accuracy: 0.5464\n",
            "Model N. 3   Accuracy =  0.54638671875 Loss =  2.494129180908203 parameters =  [38.70926388  0.63728746  0.          0.2265904   0.16227964  0.17476871\n",
            "  0.58051815  0.        ] \n",
            "\n",
            "49.0 0.26362059415302636 0.0 0.08948846722056425 0.2762458550768334 0.19742618052415997 0.04983020084042722\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b53b9d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97990a6590> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 33ms/step - loss: 4.4576 - accuracy: 0.0635 - val_loss: 3.5506 - val_accuracy: 0.2666\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.1025 - accuracy: 0.3210 - val_loss: 2.6056 - val_accuracy: 0.3873\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0785 - accuracy: 0.4864 - val_loss: 2.1350 - val_accuracy: 0.4330\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4947 - accuracy: 0.5897 - val_loss: 1.9292 - val_accuracy: 0.4673\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1309 - accuracy: 0.6874 - val_loss: 1.8439 - val_accuracy: 0.4985\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8960 - accuracy: 0.7507 - val_loss: 1.8000 - val_accuracy: 0.5033\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6953 - accuracy: 0.8124 - val_loss: 1.7854 - val_accuracy: 0.5060\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5753 - accuracy: 0.8436 - val_loss: 1.8108 - val_accuracy: 0.5168\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4579 - accuracy: 0.8805 - val_loss: 1.8295 - val_accuracy: 0.5120\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3725 - accuracy: 0.9039 - val_loss: 1.8402 - val_accuracy: 0.5234\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3198 - accuracy: 0.9166 - val_loss: 1.8601 - val_accuracy: 0.5246\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2574 - accuracy: 0.9353 - val_loss: 1.8884 - val_accuracy: 0.5316\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2287 - accuracy: 0.9449 - val_loss: 1.9159 - val_accuracy: 0.5359\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2017 - accuracy: 0.9513 - val_loss: 1.9117 - val_accuracy: 0.5401\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1698 - accuracy: 0.9581 - val_loss: 1.9497 - val_accuracy: 0.5381\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1509 - accuracy: 0.9649 - val_loss: 1.9437 - val_accuracy: 0.5421\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1351 - accuracy: 0.9680 - val_loss: 1.9772 - val_accuracy: 0.5444\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1235 - accuracy: 0.9710 - val_loss: 1.9871 - val_accuracy: 0.5381\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0987 - accuracy: 0.9778 - val_loss: 1.9927 - val_accuracy: 0.5482\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0963 - accuracy: 0.9779 - val_loss: 2.0058 - val_accuracy: 0.5499\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0886 - accuracy: 0.9803 - val_loss: 2.0174 - val_accuracy: 0.5577\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0820 - accuracy: 0.9814 - val_loss: 2.0445 - val_accuracy: 0.5497\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0693 - accuracy: 0.9850 - val_loss: 2.0578 - val_accuracy: 0.5542\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0702 - accuracy: 0.9833 - val_loss: 2.0780 - val_accuracy: 0.5532\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0631 - accuracy: 0.9848 - val_loss: 2.0754 - val_accuracy: 0.5600\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0595 - accuracy: 0.9857 - val_loss: 2.0558 - val_accuracy: 0.5570\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0541 - accuracy: 0.9892 - val_loss: 2.0782 - val_accuracy: 0.5603\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0483 - accuracy: 0.9896 - val_loss: 2.0943 - val_accuracy: 0.5602\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0495 - accuracy: 0.9890 - val_loss: 2.0606 - val_accuracy: 0.5550\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0493 - accuracy: 0.9880 - val_loss: 2.0820 - val_accuracy: 0.5578\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2539 - accuracy: 0.5363\n",
            "20.080766352732795 0.7307415408104263 0.0 0.2062274439694802 0.32124118070430724 0.008971307920613306 0.5542692614944635\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791ae08d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798f91590> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 19s 27ms/step - loss: 5.0186 - accuracy: 0.0228 - val_loss: 4.3782 - val_accuracy: 0.0791\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 4.1195 - accuracy: 0.0943 - val_loss: 3.9468 - val_accuracy: 0.1383\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 3.5914 - accuracy: 0.1742 - val_loss: 3.6414 - val_accuracy: 0.1760\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 3.1761 - accuracy: 0.2423 - val_loss: 3.3944 - val_accuracy: 0.2041\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.8404 - accuracy: 0.3001 - val_loss: 3.1950 - val_accuracy: 0.2312\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 2.5491 - accuracy: 0.3496 - val_loss: 3.0287 - val_accuracy: 0.2507\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 2.2956 - accuracy: 0.3995 - val_loss: 2.8783 - val_accuracy: 0.2718\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.0989 - accuracy: 0.4373 - val_loss: 2.7793 - val_accuracy: 0.2789\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.9040 - accuracy: 0.4746 - val_loss: 2.6752 - val_accuracy: 0.2939\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.7458 - accuracy: 0.5146 - val_loss: 2.6134 - val_accuracy: 0.2931\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.6066 - accuracy: 0.5468 - val_loss: 2.5552 - val_accuracy: 0.3103\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.5185 - accuracy: 0.5725 - val_loss: 2.5136 - val_accuracy: 0.3142\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.4001 - accuracy: 0.6047 - val_loss: 2.4812 - val_accuracy: 0.3205\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.2877 - accuracy: 0.6397 - val_loss: 2.4597 - val_accuracy: 0.3248\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.1992 - accuracy: 0.6640 - val_loss: 2.4383 - val_accuracy: 0.3268\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.1274 - accuracy: 0.6854 - val_loss: 2.4178 - val_accuracy: 0.3349\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.0416 - accuracy: 0.7147 - val_loss: 2.4045 - val_accuracy: 0.3305\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.9749 - accuracy: 0.7351 - val_loss: 2.4000 - val_accuracy: 0.3447\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.9074 - accuracy: 0.7565 - val_loss: 2.3881 - val_accuracy: 0.3426\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.8500 - accuracy: 0.7801 - val_loss: 2.3922 - val_accuracy: 0.3457\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 0.7862 - accuracy: 0.7945 - val_loss: 2.3829 - val_accuracy: 0.3501\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.7467 - accuracy: 0.8101 - val_loss: 2.3824 - val_accuracy: 0.3514\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.6812 - accuracy: 0.8323 - val_loss: 2.3858 - val_accuracy: 0.3477\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.6461 - accuracy: 0.8421 - val_loss: 2.3859 - val_accuracy: 0.3559\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.6054 - accuracy: 0.8544 - val_loss: 2.4034 - val_accuracy: 0.3472\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.5488 - accuracy: 0.8716 - val_loss: 2.3870 - val_accuracy: 0.3527\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 0.5283 - accuracy: 0.8779 - val_loss: 2.4030 - val_accuracy: 0.3556\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 0.4762 - accuracy: 0.8941 - val_loss: 2.4062 - val_accuracy: 0.3630\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.4532 - accuracy: 0.9013 - val_loss: 2.4125 - val_accuracy: 0.3549\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.4256 - accuracy: 0.9067 - val_loss: 2.4222 - val_accuracy: 0.3664\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3656 - accuracy: 0.3750\n",
            "28.33596933722375 0.36641772304763937 1.3649104747323604 0.0 0.6381819251092166 0.13450992379322058 0.4784633439991021\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dbe1410> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9799999290> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf71f250> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce492950> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 20s 29ms/step - loss: 4.5031 - accuracy: 0.0499 - val_loss: 3.6923 - val_accuracy: 0.1511\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.1769 - accuracy: 0.2382 - val_loss: 2.9342 - val_accuracy: 0.2532\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 2.3739 - accuracy: 0.3834 - val_loss: 2.5482 - val_accuracy: 0.3221\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.8579 - accuracy: 0.4929 - val_loss: 2.3467 - val_accuracy: 0.3624\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.5417 - accuracy: 0.5700 - val_loss: 2.2171 - val_accuracy: 0.3855\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.2977 - accuracy: 0.6384 - val_loss: 2.1737 - val_accuracy: 0.3989\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.1017 - accuracy: 0.6960 - val_loss: 2.1334 - val_accuracy: 0.4154\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.9501 - accuracy: 0.7417 - val_loss: 2.1174 - val_accuracy: 0.4119\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.8141 - accuracy: 0.7838 - val_loss: 2.1085 - val_accuracy: 0.4279\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.7056 - accuracy: 0.8160 - val_loss: 2.1319 - val_accuracy: 0.4342\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.6164 - accuracy: 0.8468 - val_loss: 2.1424 - val_accuracy: 0.4388\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.5199 - accuracy: 0.8764 - val_loss: 2.1377 - val_accuracy: 0.4433\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.4611 - accuracy: 0.8932 - val_loss: 2.1593 - val_accuracy: 0.4427\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.4036 - accuracy: 0.9089 - val_loss: 2.1544 - val_accuracy: 0.4473\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.3501 - accuracy: 0.9222 - val_loss: 2.1787 - val_accuracy: 0.4503\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.3078 - accuracy: 0.9364 - val_loss: 2.1950 - val_accuracy: 0.4535\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.2754 - accuracy: 0.9431 - val_loss: 2.2211 - val_accuracy: 0.4541\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.2332 - accuracy: 0.9543 - val_loss: 2.2428 - val_accuracy: 0.4574\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.2198 - accuracy: 0.9551 - val_loss: 2.2283 - val_accuracy: 0.4588\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.1927 - accuracy: 0.9635 - val_loss: 2.2778 - val_accuracy: 0.4574\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.1759 - accuracy: 0.9665 - val_loss: 2.2518 - val_accuracy: 0.4563\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1544 - accuracy: 0.9730 - val_loss: 2.2656 - val_accuracy: 0.4586\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1431 - accuracy: 0.9743 - val_loss: 2.2632 - val_accuracy: 0.4656\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.1317 - accuracy: 0.9763 - val_loss: 2.3203 - val_accuracy: 0.4641\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1152 - accuracy: 0.9808 - val_loss: 2.3184 - val_accuracy: 0.4691\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1096 - accuracy: 0.9812 - val_loss: 2.3410 - val_accuracy: 0.4598\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.0972 - accuracy: 0.9839 - val_loss: 2.3701 - val_accuracy: 0.4515\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.0926 - accuracy: 0.9839 - val_loss: 2.3791 - val_accuracy: 0.4543\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.0873 - accuracy: 0.9862 - val_loss: 2.3499 - val_accuracy: 0.4676\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3606 - accuracy: 0.4453\n",
            "49.0 0.6375901727545576 0.7262749450242341 0.3678806822776756 0.23377966785194326 0.1666887098511981 0.4693449275718913\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d7d60d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f183190> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f035c90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e0cfc10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.8147 - accuracy: 0.0125 - val_loss: 4.5172 - val_accuracy: 0.0334\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 4.3902 - accuracy: 0.0458 - val_loss: 4.1368 - val_accuracy: 0.1019\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.9471 - accuracy: 0.1200 - val_loss: 3.6141 - val_accuracy: 0.1727\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.3836 - accuracy: 0.2032 - val_loss: 3.0511 - val_accuracy: 0.2485\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.8700 - accuracy: 0.2851 - val_loss: 2.5983 - val_accuracy: 0.3168\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4086 - accuracy: 0.3622 - val_loss: 2.2745 - val_accuracy: 0.3629\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0624 - accuracy: 0.4299 - val_loss: 2.0602 - val_accuracy: 0.3961\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.8101 - accuracy: 0.4870 - val_loss: 1.9174 - val_accuracy: 0.4285\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.5999 - accuracy: 0.5330 - val_loss: 1.8239 - val_accuracy: 0.4651\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.4429 - accuracy: 0.5727 - val_loss: 1.7650 - val_accuracy: 0.4782\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.3223 - accuracy: 0.6078 - val_loss: 1.7294 - val_accuracy: 0.4947\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1901 - accuracy: 0.6486 - val_loss: 1.6965 - val_accuracy: 0.5060\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0776 - accuracy: 0.6764 - val_loss: 1.6653 - val_accuracy: 0.5193\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9942 - accuracy: 0.7024 - val_loss: 1.6552 - val_accuracy: 0.5211\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8892 - accuracy: 0.7352 - val_loss: 1.6682 - val_accuracy: 0.5216\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8017 - accuracy: 0.7615 - val_loss: 1.6525 - val_accuracy: 0.5266\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7172 - accuracy: 0.7879 - val_loss: 1.6580 - val_accuracy: 0.5377\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6707 - accuracy: 0.7990 - val_loss: 1.6786 - val_accuracy: 0.5352\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6050 - accuracy: 0.8204 - val_loss: 1.6843 - val_accuracy: 0.5357\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5463 - accuracy: 0.8448 - val_loss: 1.6936 - val_accuracy: 0.5402\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4993 - accuracy: 0.8572 - val_loss: 1.6993 - val_accuracy: 0.5450\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4624 - accuracy: 0.8665 - val_loss: 1.7182 - val_accuracy: 0.5384\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4255 - accuracy: 0.8775 - val_loss: 1.7393 - val_accuracy: 0.5356\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3795 - accuracy: 0.8957 - val_loss: 1.7525 - val_accuracy: 0.5419\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3568 - accuracy: 0.8996 - val_loss: 1.7515 - val_accuracy: 0.5440\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.8663 - accuracy: 0.5143\n",
            "17.177799787842943 0.4053302138484424 2.5118360258252697 0.5895811700415643 0.2984744508594441 0.2 0.3053190321261797\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791c8f4d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97929e7f50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799215350> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce368810> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf73be90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97999997d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ef15e10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791903090> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 19s 27ms/step - loss: 4.6146 - accuracy: 0.0316 - val_loss: 3.6103 - val_accuracy: 0.1004\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 3.5772 - accuracy: 0.0623 - val_loss: 3.0980 - val_accuracy: 0.1669\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 3.2675 - accuracy: 0.0806 - val_loss: 2.8913 - val_accuracy: 0.2018\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 3.0874 - accuracy: 0.1103 - val_loss: 2.7280 - val_accuracy: 0.2236\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.9499 - accuracy: 0.1314 - val_loss: 2.6087 - val_accuracy: 0.2483\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.8187 - accuracy: 0.1603 - val_loss: 2.5162 - val_accuracy: 0.2550\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.6933 - accuracy: 0.1872 - val_loss: 2.4467 - val_accuracy: 0.2708\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.5962 - accuracy: 0.2113 - val_loss: 2.3902 - val_accuracy: 0.2827\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 2.4796 - accuracy: 0.2356 - val_loss: 2.3281 - val_accuracy: 0.2967\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 2.3936 - accuracy: 0.2596 - val_loss: 2.2766 - val_accuracy: 0.3107\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 2.3073 - accuracy: 0.2774 - val_loss: 2.2365 - val_accuracy: 0.3263\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 2.2010 - accuracy: 0.3048 - val_loss: 2.1917 - val_accuracy: 0.3348\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 2.1279 - accuracy: 0.3194 - val_loss: 2.1678 - val_accuracy: 0.3361\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 2.0319 - accuracy: 0.3483 - val_loss: 2.1523 - val_accuracy: 0.3449\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.9498 - accuracy: 0.3673 - val_loss: 2.1474 - val_accuracy: 0.3534\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.8636 - accuracy: 0.3918 - val_loss: 2.1448 - val_accuracy: 0.3642\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.7936 - accuracy: 0.4118 - val_loss: 2.1408 - val_accuracy: 0.3674\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.7067 - accuracy: 0.4356 - val_loss: 2.1537 - val_accuracy: 0.3684\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.6269 - accuracy: 0.4577 - val_loss: 2.1719 - val_accuracy: 0.3732\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.5719 - accuracy: 0.4780 - val_loss: 2.1785 - val_accuracy: 0.3868\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.4734 - accuracy: 0.4996 - val_loss: 2.2226 - val_accuracy: 0.3888\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.4110 - accuracy: 0.5211 - val_loss: 2.2509 - val_accuracy: 0.3905\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.3401 - accuracy: 0.5449 - val_loss: 2.2680 - val_accuracy: 0.3880\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.2859 - accuracy: 0.5628 - val_loss: 2.3164 - val_accuracy: 0.3954\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.2087 - accuracy: 0.5839 - val_loss: 2.3512 - val_accuracy: 0.3948\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 1.1480 - accuracy: 0.6074 - val_loss: 2.3692 - val_accuracy: 0.4013\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 1.0875 - accuracy: 0.6284 - val_loss: 2.4076 - val_accuracy: 0.4014\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 1.0160 - accuracy: 0.6500 - val_loss: 2.4760 - val_accuracy: 0.3973\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.9606 - accuracy: 0.6724 - val_loss: 2.4990 - val_accuracy: 0.3981\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 14s 25ms/step - loss: 0.8966 - accuracy: 0.6978 - val_loss: 2.5524 - val_accuracy: 0.3911\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.4657 - accuracy: 0.3933\n",
            "27.063695763769573 0.9764594439084463 1.8086715688832031 0.425558894290977 0.20510955175902418 0.18597508751635075 0.39036142514670646\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d084310> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99592386d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791974750> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d04fa50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ef15b10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b3d6210> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 20s 29ms/step - loss: 4.4793 - accuracy: 0.0361 - val_loss: 3.1733 - val_accuracy: 0.1805\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 3.0409 - accuracy: 0.1735 - val_loss: 2.4788 - val_accuracy: 0.2857\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 2.4479 - accuracy: 0.2845 - val_loss: 2.1964 - val_accuracy: 0.3433\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 15s 27ms/step - loss: 2.0776 - accuracy: 0.3749 - val_loss: 2.0540 - val_accuracy: 0.3682\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.7833 - accuracy: 0.4507 - val_loss: 1.9729 - val_accuracy: 0.4121\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.5587 - accuracy: 0.5221 - val_loss: 1.9052 - val_accuracy: 0.4430\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.3522 - accuracy: 0.5772 - val_loss: 1.8715 - val_accuracy: 0.4485\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.1847 - accuracy: 0.6283 - val_loss: 1.8975 - val_accuracy: 0.4586\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.0247 - accuracy: 0.6809 - val_loss: 1.9144 - val_accuracy: 0.4706\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.8722 - accuracy: 0.7295 - val_loss: 1.9888 - val_accuracy: 0.4673\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.7418 - accuracy: 0.7687 - val_loss: 2.0211 - val_accuracy: 0.4746\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.6269 - accuracy: 0.8089 - val_loss: 2.0931 - val_accuracy: 0.4751\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.5296 - accuracy: 0.8401 - val_loss: 2.2061 - val_accuracy: 0.4741\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.4639 - accuracy: 0.8609 - val_loss: 2.2109 - val_accuracy: 0.4744\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.3873 - accuracy: 0.8879 - val_loss: 2.2522 - val_accuracy: 0.4804\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.3280 - accuracy: 0.9035 - val_loss: 2.2682 - val_accuracy: 0.4882\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.2814 - accuracy: 0.9164 - val_loss: 2.3361 - val_accuracy: 0.4900\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.2496 - accuracy: 0.9276 - val_loss: 2.3786 - val_accuracy: 0.4834\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.2244 - accuracy: 0.9353 - val_loss: 2.4352 - val_accuracy: 0.4865\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1918 - accuracy: 0.9452 - val_loss: 2.5067 - val_accuracy: 0.4756\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1627 - accuracy: 0.9565 - val_loss: 2.5700 - val_accuracy: 0.4741\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.5577 - accuracy: 0.4753\n",
            "9.450907063326328 0.5788997420522334 0.7134274670091081 0.4684664341845606 0.01320905866266131 0.15458264096603616 0.5406562684582891\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791bc4810> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791ba8e90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f719a50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bfbdf610> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 17s 24ms/step - loss: 2.6067 - accuracy: 0.3013 - val_loss: 2.1199 - val_accuracy: 0.3920\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 12s 22ms/step - loss: 0.9655 - accuracy: 0.6909 - val_loss: 2.8912 - val_accuracy: 0.3803\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.4097 - accuracy: 0.8685 - val_loss: 3.4468 - val_accuracy: 0.3748\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.2367 - accuracy: 0.9249 - val_loss: 3.7821 - val_accuracy: 0.3841\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1805 - accuracy: 0.9423 - val_loss: 3.9731 - val_accuracy: 0.3951\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1181 - accuracy: 0.9616 - val_loss: 4.1828 - val_accuracy: 0.4013\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1254 - accuracy: 0.9609 - val_loss: 4.3841 - val_accuracy: 0.3835\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 12s 22ms/step - loss: 0.1017 - accuracy: 0.9679 - val_loss: 4.6073 - val_accuracy: 0.3891\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.0950 - accuracy: 0.9706 - val_loss: 4.7541 - val_accuracy: 0.3843\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1061 - accuracy: 0.9664 - val_loss: 4.7209 - val_accuracy: 0.3916\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 4.6702 - accuracy: 0.3960\n",
            "13.513136444502052 0.607832648270362 1.2991119705737173 0.584122442505783 0.36913742914509595 0.07925100899817941 0.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791c9f350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d870f90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b514150> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bbf2a90> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 13s 32ms/step - loss: 5.7936 - accuracy: 0.0127 - val_loss: 4.7006 - val_accuracy: 0.0199\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 8s 30ms/step - loss: 5.0323 - accuracy: 0.0153 - val_loss: 4.6384 - val_accuracy: 0.0239\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.7899 - accuracy: 0.0194 - val_loss: 4.5473 - val_accuracy: 0.0322\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.6562 - accuracy: 0.0246 - val_loss: 4.4832 - val_accuracy: 0.0352\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.5840 - accuracy: 0.0280 - val_loss: 4.4289 - val_accuracy: 0.0399\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.5228 - accuracy: 0.0331 - val_loss: 4.3795 - val_accuracy: 0.0469\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.4692 - accuracy: 0.0383 - val_loss: 4.3309 - val_accuracy: 0.0512\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.4265 - accuracy: 0.0433 - val_loss: 4.2797 - val_accuracy: 0.0633\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.3753 - accuracy: 0.0512 - val_loss: 4.2274 - val_accuracy: 0.0785\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.3268 - accuracy: 0.0591 - val_loss: 4.1783 - val_accuracy: 0.0889\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.2761 - accuracy: 0.0669 - val_loss: 4.1232 - val_accuracy: 0.1036\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.2245 - accuracy: 0.0755 - val_loss: 4.0696 - val_accuracy: 0.1155\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 4.1963 - accuracy: 0.0774 - val_loss: 4.0213 - val_accuracy: 0.1203\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.1309 - accuracy: 0.0857 - val_loss: 3.9733 - val_accuracy: 0.1338\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.0845 - accuracy: 0.0942 - val_loss: 3.9273 - val_accuracy: 0.1413\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.0500 - accuracy: 0.0966 - val_loss: 3.8807 - val_accuracy: 0.1478\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 4.0078 - accuracy: 0.1083 - val_loss: 3.8319 - val_accuracy: 0.1544\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.9522 - accuracy: 0.1131 - val_loss: 3.7854 - val_accuracy: 0.1584\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.9035 - accuracy: 0.1194 - val_loss: 3.7465 - val_accuracy: 0.1606\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.8575 - accuracy: 0.1282 - val_loss: 3.6988 - val_accuracy: 0.1682\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.8164 - accuracy: 0.1294 - val_loss: 3.6565 - val_accuracy: 0.1740\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.7665 - accuracy: 0.1331 - val_loss: 3.6148 - val_accuracy: 0.1795\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.7276 - accuracy: 0.1442 - val_loss: 3.5723 - val_accuracy: 0.1840\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.6618 - accuracy: 0.1522 - val_loss: 3.5301 - val_accuracy: 0.1868\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.6402 - accuracy: 0.1545 - val_loss: 3.4917 - val_accuracy: 0.1908\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.5765 - accuracy: 0.1615 - val_loss: 3.4507 - val_accuracy: 0.1956\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.5460 - accuracy: 0.1696 - val_loss: 3.4122 - val_accuracy: 0.2043\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.4925 - accuracy: 0.1767 - val_loss: 3.3723 - val_accuracy: 0.2018\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 3.4564 - accuracy: 0.1809 - val_loss: 3.3353 - val_accuracy: 0.2050\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.4002 - accuracy: 0.1845 - val_loss: 3.2963 - val_accuracy: 0.2118\n",
            "64/64 [==============================] - 2s 21ms/step - loss: 3.3609 - accuracy: 0.2034\n",
            "12.490224878738315 1.0 0.0 0.2865665622083554 0.3943726120790082 0.2 0.356742795544314\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97999b4cd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798fe6bd0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 12s 31ms/step - loss: 4.5262 - accuracy: 0.0585 - val_loss: 3.8456 - val_accuracy: 0.1526\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 3.1702 - accuracy: 0.2898 - val_loss: 3.1664 - val_accuracy: 0.2728\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 2.3602 - accuracy: 0.4621 - val_loss: 2.8271 - val_accuracy: 0.3165\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 1.7752 - accuracy: 0.5952 - val_loss: 2.6371 - val_accuracy: 0.3393\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 1.3489 - accuracy: 0.6975 - val_loss: 2.4969 - val_accuracy: 0.3602\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 1.0594 - accuracy: 0.7710 - val_loss: 2.4382 - val_accuracy: 0.3627\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.8307 - accuracy: 0.8377 - val_loss: 2.3963 - val_accuracy: 0.3717\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.6593 - accuracy: 0.8854 - val_loss: 2.3730 - val_accuracy: 0.3828\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.5271 - accuracy: 0.9236 - val_loss: 2.3566 - val_accuracy: 0.3770\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.4274 - accuracy: 0.9454 - val_loss: 2.3488 - val_accuracy: 0.3810\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.3646 - accuracy: 0.9603 - val_loss: 2.3447 - val_accuracy: 0.3858\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.2908 - accuracy: 0.9762 - val_loss: 2.3520 - val_accuracy: 0.3871\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.2425 - accuracy: 0.9835 - val_loss: 2.3565 - val_accuracy: 0.3848\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.2109 - accuracy: 0.9896 - val_loss: 2.3498 - val_accuracy: 0.3848\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1803 - accuracy: 0.9924 - val_loss: 2.3566 - val_accuracy: 0.3870\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1586 - accuracy: 0.9937 - val_loss: 2.3668 - val_accuracy: 0.3885\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1375 - accuracy: 0.9961 - val_loss: 2.3658 - val_accuracy: 0.3893\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1211 - accuracy: 0.9972 - val_loss: 2.3691 - val_accuracy: 0.3885\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1128 - accuracy: 0.9979 - val_loss: 2.3667 - val_accuracy: 0.3896\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.1010 - accuracy: 0.9981 - val_loss: 2.3836 - val_accuracy: 0.3918\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.0912 - accuracy: 0.9991 - val_loss: 2.3912 - val_accuracy: 0.3943\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.0841 - accuracy: 0.9993 - val_loss: 2.3939 - val_accuracy: 0.3956\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.0773 - accuracy: 0.9991 - val_loss: 2.3962 - val_accuracy: 0.3959\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.0703 - accuracy: 0.9994 - val_loss: 2.3956 - val_accuracy: 0.3983\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.0650 - accuracy: 0.9996 - val_loss: 2.4059 - val_accuracy: 0.3946\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 0.0598 - accuracy: 0.9997 - val_loss: 2.4149 - val_accuracy: 0.3943\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 8s 29ms/step - loss: 0.0563 - accuracy: 0.9996 - val_loss: 2.4167 - val_accuracy: 0.4006\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 7s 28ms/step - loss: 0.0540 - accuracy: 0.9998 - val_loss: 2.4235 - val_accuracy: 0.3991\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.0504 - accuracy: 0.9998 - val_loss: 2.4264 - val_accuracy: 0.4023\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 7s 27ms/step - loss: 0.0471 - accuracy: 0.9999 - val_loss: 2.4300 - val_accuracy: 0.3954\n",
            "64/64 [==============================] - 2s 19ms/step - loss: 2.4347 - accuracy: 0.4148\n",
            "40.704324077053826 0.6457641579244077 0.0 0.21495997296222644 0.1945524350790892 0.2 0.6831664005892976\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97927c96d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979278b390> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 2.1425 - accuracy: 0.4264 - val_loss: 2.8292 - val_accuracy: 0.4983\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5526 - accuracy: 0.8284 - val_loss: 2.0368 - val_accuracy: 0.5507\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1821 - accuracy: 0.9414 - val_loss: 2.4549 - val_accuracy: 0.5324\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1369 - accuracy: 0.9586 - val_loss: 2.5543 - val_accuracy: 0.5322\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1219 - accuracy: 0.9604 - val_loss: 2.6333 - val_accuracy: 0.5386\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0885 - accuracy: 0.9730 - val_loss: 3.3278 - val_accuracy: 0.5209\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 3.2271 - accuracy: 0.5366\n",
            "49.0 0.07847125308415859 0.0 0.17541517072081703 0.1918950143242833 0.2 0.14518094015360386\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97927a8f90> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9799327410> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.4682 - accuracy: 0.0579 - val_loss: 3.5436 - val_accuracy: 0.2344\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9801 - accuracy: 0.3203 - val_loss: 2.5202 - val_accuracy: 0.3792\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9475 - accuracy: 0.5081 - val_loss: 2.0571 - val_accuracy: 0.4523\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.3779 - accuracy: 0.6213 - val_loss: 1.9081 - val_accuracy: 0.4855\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0398 - accuracy: 0.7077 - val_loss: 1.8415 - val_accuracy: 0.4988\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8036 - accuracy: 0.7761 - val_loss: 1.8386 - val_accuracy: 0.5028\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6397 - accuracy: 0.8244 - val_loss: 1.8108 - val_accuracy: 0.5176\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5139 - accuracy: 0.8623 - val_loss: 1.8645 - val_accuracy: 0.5090\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4183 - accuracy: 0.8914 - val_loss: 1.9026 - val_accuracy: 0.5110\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3304 - accuracy: 0.9188 - val_loss: 1.9206 - val_accuracy: 0.5221\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2850 - accuracy: 0.9306 - val_loss: 1.9274 - val_accuracy: 0.5183\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2364 - accuracy: 0.9421 - val_loss: 1.9516 - val_accuracy: 0.5268\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2092 - accuracy: 0.9487 - val_loss: 1.9693 - val_accuracy: 0.5301\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1771 - accuracy: 0.9574 - val_loss: 2.0064 - val_accuracy: 0.5244\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1607 - accuracy: 0.9606 - val_loss: 1.9837 - val_accuracy: 0.5291\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1342 - accuracy: 0.9699 - val_loss: 2.0051 - val_accuracy: 0.5342\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1230 - accuracy: 0.9727 - val_loss: 2.0219 - val_accuracy: 0.5332\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1059 - accuracy: 0.9767 - val_loss: 2.0568 - val_accuracy: 0.5288\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0947 - accuracy: 0.9791 - val_loss: 2.0564 - val_accuracy: 0.5331\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0877 - accuracy: 0.9797 - val_loss: 2.0783 - val_accuracy: 0.5251\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0860 - accuracy: 0.5355\n",
            "34.40967927514115 0.6951312836235748 0.0 0.18650503939875893 0.2023485069390969 0.12509808289852375 0.7476162541161413\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d8baad0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d8b27d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 2.3252 - accuracy: 0.3773 - val_loss: 2.0593 - val_accuracy: 0.4958\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.3942 - accuracy: 0.8813 - val_loss: 2.0719 - val_accuracy: 0.5317\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1015 - accuracy: 0.9739 - val_loss: 2.2122 - val_accuracy: 0.5303\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.0966 - accuracy: 0.9717 - val_loss: 2.3938 - val_accuracy: 0.5372\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.0705 - accuracy: 0.9801 - val_loss: 2.5293 - val_accuracy: 0.5228\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0805 - accuracy: 0.9774 - val_loss: 2.5534 - val_accuracy: 0.5143\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0643 - accuracy: 0.9823 - val_loss: 2.5624 - val_accuracy: 0.5296\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 2.6736 - val_accuracy: 0.5203\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.7018 - accuracy: 0.5238\n",
            "43.74511806692861 0.36664277605038553 0.8326619772893582 0.01101201086569012 0.65 0.1719987494068088 0.4841531571302553\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d8b2650> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9798e0ee10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798e39f10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798e39e10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.6067 - accuracy: 0.0355 - val_loss: 3.7073 - val_accuracy: 0.1474\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.2975 - accuracy: 0.2079 - val_loss: 2.9472 - val_accuracy: 0.2530\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.4873 - accuracy: 0.3553 - val_loss: 2.5191 - val_accuracy: 0.3153\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9836 - accuracy: 0.4635 - val_loss: 2.2965 - val_accuracy: 0.3582\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6545 - accuracy: 0.5347 - val_loss: 2.1311 - val_accuracy: 0.3898\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3895 - accuracy: 0.6043 - val_loss: 2.0610 - val_accuracy: 0.4199\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.1970 - accuracy: 0.6623 - val_loss: 1.9710 - val_accuracy: 0.4446\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0398 - accuracy: 0.7117 - val_loss: 1.9434 - val_accuracy: 0.4297\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9215 - accuracy: 0.7447 - val_loss: 1.9321 - val_accuracy: 0.4476\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8014 - accuracy: 0.7828 - val_loss: 1.8941 - val_accuracy: 0.4483\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7049 - accuracy: 0.8135 - val_loss: 1.8612 - val_accuracy: 0.4676\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6258 - accuracy: 0.8354 - val_loss: 1.8628 - val_accuracy: 0.4737\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5580 - accuracy: 0.8567 - val_loss: 1.8486 - val_accuracy: 0.4747\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4966 - accuracy: 0.8750 - val_loss: 1.8555 - val_accuracy: 0.4724\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4380 - accuracy: 0.8933 - val_loss: 1.8620 - val_accuracy: 0.4691\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3823 - accuracy: 0.9079 - val_loss: 1.8759 - val_accuracy: 0.4875\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3548 - accuracy: 0.9154 - val_loss: 1.8783 - val_accuracy: 0.4875\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3103 - accuracy: 0.9319 - val_loss: 1.8837 - val_accuracy: 0.4910\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2760 - accuracy: 0.9388 - val_loss: 1.8921 - val_accuracy: 0.4772\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.2541 - accuracy: 0.9444 - val_loss: 1.9001 - val_accuracy: 0.4877\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2253 - accuracy: 0.9524 - val_loss: 1.9123 - val_accuracy: 0.4844\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2069 - accuracy: 0.9565 - val_loss: 1.9005 - val_accuracy: 0.4962\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1961 - accuracy: 0.9587 - val_loss: 1.9149 - val_accuracy: 0.5028\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1720 - accuracy: 0.9650 - val_loss: 1.9182 - val_accuracy: 0.4950\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1517 - accuracy: 0.9708 - val_loss: 1.9401 - val_accuracy: 0.4947\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1434 - accuracy: 0.9728 - val_loss: 1.9324 - val_accuracy: 0.5007\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1310 - accuracy: 0.9752 - val_loss: 1.9494 - val_accuracy: 0.5043\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1207 - accuracy: 0.9781 - val_loss: 1.9532 - val_accuracy: 0.4978\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1168 - accuracy: 0.9781 - val_loss: 1.9569 - val_accuracy: 0.4958\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1075 - accuracy: 0.9795 - val_loss: 1.9540 - val_accuracy: 0.5075\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9838 - accuracy: 0.5023\n",
            "48.313195820891266 0.7217158918048574 0.0 0.3523166866069807 0.03177772114281946 0.2 0.2992057542926656\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dc97810> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798f80910> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.4858 - accuracy: 0.0589 - val_loss: 3.5929 - val_accuracy: 0.2296\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.0680 - accuracy: 0.3090 - val_loss: 2.4990 - val_accuracy: 0.4021\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0154 - accuracy: 0.4901 - val_loss: 2.0409 - val_accuracy: 0.4589\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4357 - accuracy: 0.6054 - val_loss: 1.8653 - val_accuracy: 0.4827\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0967 - accuracy: 0.6877 - val_loss: 1.7960 - val_accuracy: 0.5088\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8802 - accuracy: 0.7486 - val_loss: 1.7948 - val_accuracy: 0.5103\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6986 - accuracy: 0.8045 - val_loss: 1.7585 - val_accuracy: 0.5236\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5564 - accuracy: 0.8498 - val_loss: 1.8039 - val_accuracy: 0.5311\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4633 - accuracy: 0.8743 - val_loss: 1.8054 - val_accuracy: 0.5259\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3844 - accuracy: 0.8995 - val_loss: 1.7982 - val_accuracy: 0.5402\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3204 - accuracy: 0.9184 - val_loss: 1.8307 - val_accuracy: 0.5281\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2729 - accuracy: 0.9311 - val_loss: 1.8117 - val_accuracy: 0.5346\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2334 - accuracy: 0.9446 - val_loss: 1.8397 - val_accuracy: 0.5414\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2022 - accuracy: 0.9509 - val_loss: 1.8618 - val_accuracy: 0.5454\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1745 - accuracy: 0.9588 - val_loss: 1.8664 - val_accuracy: 0.5580\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1502 - accuracy: 0.9651 - val_loss: 1.8917 - val_accuracy: 0.5557\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1335 - accuracy: 0.9683 - val_loss: 1.9284 - val_accuracy: 0.5524\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1202 - accuracy: 0.9720 - val_loss: 1.9469 - val_accuracy: 0.5560\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1131 - accuracy: 0.9742 - val_loss: 1.9658 - val_accuracy: 0.5567\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.1380 - accuracy: 0.5206\n",
            "20.3514396941497 0.4867707307091179 0.8025411589030371 0.585461432366777 0.164426467477 0.19412097519920504 0.4008529426946379\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97916f3a50> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e0eeb50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798e0ed90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4e8f50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 19s 27ms/step - loss: 4.7321 - accuracy: 0.0378 - val_loss: 3.7273 - val_accuracy: 0.1702\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 3.6686 - accuracy: 0.1485 - val_loss: 2.9503 - val_accuracy: 0.2540\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.9868 - accuracy: 0.2378 - val_loss: 2.5856 - val_accuracy: 0.2871\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.5440 - accuracy: 0.2965 - val_loss: 2.3290 - val_accuracy: 0.3388\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.2576 - accuracy: 0.3467 - val_loss: 2.1976 - val_accuracy: 0.3565\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.0178 - accuracy: 0.4079 - val_loss: 2.1263 - val_accuracy: 0.3675\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.8319 - accuracy: 0.4532 - val_loss: 2.1000 - val_accuracy: 0.3815\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.6585 - accuracy: 0.4980 - val_loss: 2.0577 - val_accuracy: 0.3951\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.5064 - accuracy: 0.5447 - val_loss: 2.0509 - val_accuracy: 0.4077\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.3785 - accuracy: 0.5814 - val_loss: 2.0740 - val_accuracy: 0.4142\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.2453 - accuracy: 0.6188 - val_loss: 2.0860 - val_accuracy: 0.4157\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.1155 - accuracy: 0.6580 - val_loss: 2.1003 - val_accuracy: 0.4157\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.0200 - accuracy: 0.6875 - val_loss: 2.1343 - val_accuracy: 0.4152\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 0.8968 - accuracy: 0.7285 - val_loss: 2.1494 - val_accuracy: 0.4094\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 0.8171 - accuracy: 0.7548 - val_loss: 2.1969 - val_accuracy: 0.4137\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2583 - accuracy: 0.4062\n",
            "46.78697523766833 0.8596023011421835 1.680825507538573 0.27284768815468485 0.27197383874945535 0.2 0.24578926835419226\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9793a8e810> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798e0d910> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f594f50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97914b0ad0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979155b890> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792a01b10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.4538 - accuracy: 0.0359 - val_loss: 3.3739 - val_accuracy: 0.1232\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.1667 - accuracy: 0.1347 - val_loss: 2.5238 - val_accuracy: 0.2681\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.4736 - accuracy: 0.2707 - val_loss: 2.0883 - val_accuracy: 0.3713\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9894 - accuracy: 0.3992 - val_loss: 1.8287 - val_accuracy: 0.4403\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6744 - accuracy: 0.4842 - val_loss: 1.6843 - val_accuracy: 0.4849\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4129 - accuracy: 0.5610 - val_loss: 1.6344 - val_accuracy: 0.5098\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2069 - accuracy: 0.6247 - val_loss: 1.5909 - val_accuracy: 0.5224\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0261 - accuracy: 0.6774 - val_loss: 1.5995 - val_accuracy: 0.5341\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8914 - accuracy: 0.7266 - val_loss: 1.6251 - val_accuracy: 0.5407\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7662 - accuracy: 0.7642 - val_loss: 1.6221 - val_accuracy: 0.5455\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6236 - accuracy: 0.8089 - val_loss: 1.6549 - val_accuracy: 0.5592\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5476 - accuracy: 0.8334 - val_loss: 1.7182 - val_accuracy: 0.5597\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4563 - accuracy: 0.8616 - val_loss: 1.7381 - val_accuracy: 0.5628\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3804 - accuracy: 0.8878 - val_loss: 1.7865 - val_accuracy: 0.5622\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3371 - accuracy: 0.9008 - val_loss: 1.8392 - val_accuracy: 0.5643\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2861 - accuracy: 0.9164 - val_loss: 1.8640 - val_accuracy: 0.5602\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2421 - accuracy: 0.9291 - val_loss: 1.8957 - val_accuracy: 0.5635\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2022 - accuracy: 0.9443 - val_loss: 1.9331 - val_accuracy: 0.5623\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1878 - accuracy: 0.9477 - val_loss: 1.9893 - val_accuracy: 0.5740\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1680 - accuracy: 0.9518 - val_loss: 2.0415 - val_accuracy: 0.5786\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1435 - accuracy: 0.9592 - val_loss: 2.0378 - val_accuracy: 0.5750\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1305 - accuracy: 0.9626 - val_loss: 2.0429 - val_accuracy: 0.5828\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1203 - accuracy: 0.9664 - val_loss: 2.0463 - val_accuracy: 0.5844\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1056 - accuracy: 0.9705 - val_loss: 2.1040 - val_accuracy: 0.5800\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0915 - accuracy: 0.9753 - val_loss: 2.1021 - val_accuracy: 0.5728\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0867 - accuracy: 0.9770 - val_loss: 2.1575 - val_accuracy: 0.5705\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0783 - accuracy: 0.9787 - val_loss: 2.1583 - val_accuracy: 0.5806\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.2103 - accuracy: 0.5514\n",
            "Model N. 4   Accuracy =  0.5513916015625 Loss =  2.2103261947631836 parameters =  [46.78697524  0.8596023   1.68082551  0.27284769  0.27197384  0.2\n",
            "  0.24578927  0.        ] \n",
            "\n",
            "31.482065142589498 1.0 1.0599566847063644 0.4491445922136479 0.0 0.18134196234887243 0.4770439608255117\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792c8d1d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bc47050> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978de11210> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b6127d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 20s 30ms/step - loss: 4.6817 - accuracy: 0.0295 - val_loss: 3.7629 - val_accuracy: 0.1692\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 3.4281 - accuracy: 0.1907 - val_loss: 2.6709 - val_accuracy: 0.2788\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 2.4998 - accuracy: 0.3202 - val_loss: 2.2667 - val_accuracy: 0.3602\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 2.0037 - accuracy: 0.4142 - val_loss: 2.0683 - val_accuracy: 0.3808\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.6746 - accuracy: 0.4981 - val_loss: 2.0003 - val_accuracy: 0.4092\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.4330 - accuracy: 0.5625 - val_loss: 1.9826 - val_accuracy: 0.4380\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.2222 - accuracy: 0.6224 - val_loss: 1.9456 - val_accuracy: 0.4506\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 1.0583 - accuracy: 0.6805 - val_loss: 1.9236 - val_accuracy: 0.4525\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.8825 - accuracy: 0.7315 - val_loss: 2.0126 - val_accuracy: 0.4571\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.7515 - accuracy: 0.7726 - val_loss: 2.0135 - val_accuracy: 0.4621\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.6638 - accuracy: 0.7984 - val_loss: 2.0514 - val_accuracy: 0.4664\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.5620 - accuracy: 0.8305 - val_loss: 2.0798 - val_accuracy: 0.4588\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.4713 - accuracy: 0.8608 - val_loss: 2.0928 - val_accuracy: 0.4653\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.4100 - accuracy: 0.8780 - val_loss: 2.1504 - val_accuracy: 0.4722\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.3547 - accuracy: 0.8964 - val_loss: 2.1801 - val_accuracy: 0.4697\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.3040 - accuracy: 0.9128 - val_loss: 2.2588 - val_accuracy: 0.4724\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 0.2688 - accuracy: 0.9245 - val_loss: 2.3318 - val_accuracy: 0.4631\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.2232 - accuracy: 0.9381 - val_loss: 2.3008 - val_accuracy: 0.4629\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1981 - accuracy: 0.9436 - val_loss: 2.4471 - val_accuracy: 0.4731\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1829 - accuracy: 0.9485 - val_loss: 2.3843 - val_accuracy: 0.4801\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1629 - accuracy: 0.9540 - val_loss: 2.4801 - val_accuracy: 0.4707\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1527 - accuracy: 0.9571 - val_loss: 2.4949 - val_accuracy: 0.4603\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1334 - accuracy: 0.9639 - val_loss: 2.5497 - val_accuracy: 0.4702\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 0.1180 - accuracy: 0.9684 - val_loss: 2.4961 - val_accuracy: 0.4731\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.4553 - accuracy: 0.4869\n",
            "25.893028401973503 0.8420338120866538 1.260547887074099 0.3257920011585216 0.38024139182142214 0.06346353282930206 0.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978de35250> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b52a8d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978cee4f50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bfbc77d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 20s 28ms/step - loss: 5.4062 - accuracy: 0.0062 - val_loss: 4.8570 - val_accuracy: 0.0126\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.8469 - accuracy: 0.0106 - val_loss: 4.6751 - val_accuracy: 0.0100\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.6720 - accuracy: 0.0142 - val_loss: 4.6133 - val_accuracy: 0.0206\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.6235 - accuracy: 0.0172 - val_loss: 4.5763 - val_accuracy: 0.0246\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.5855 - accuracy: 0.0213 - val_loss: 4.5484 - val_accuracy: 0.0294\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.5551 - accuracy: 0.0246 - val_loss: 4.5197 - val_accuracy: 0.0386\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.5219 - accuracy: 0.0291 - val_loss: 4.4906 - val_accuracy: 0.0432\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.4889 - accuracy: 0.0357 - val_loss: 4.4590 - val_accuracy: 0.0535\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.4528 - accuracy: 0.0434 - val_loss: 4.4248 - val_accuracy: 0.0633\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.4159 - accuracy: 0.0468 - val_loss: 4.3894 - val_accuracy: 0.0700\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.3795 - accuracy: 0.0549 - val_loss: 4.3469 - val_accuracy: 0.0761\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.3333 - accuracy: 0.0623 - val_loss: 4.3008 - val_accuracy: 0.0813\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.2836 - accuracy: 0.0680 - val_loss: 4.2515 - val_accuracy: 0.0904\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.2278 - accuracy: 0.0764 - val_loss: 4.1970 - val_accuracy: 0.1031\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.1664 - accuracy: 0.0854 - val_loss: 4.1356 - val_accuracy: 0.1095\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 4.1116 - accuracy: 0.0943 - val_loss: 4.0689 - val_accuracy: 0.1125\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 4.0411 - accuracy: 0.1030 - val_loss: 3.9983 - val_accuracy: 0.1188\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.9892 - accuracy: 0.1105 - val_loss: 3.9262 - val_accuracy: 0.1386\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.9154 - accuracy: 0.1246 - val_loss: 3.8632 - val_accuracy: 0.1438\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.8328 - accuracy: 0.1366 - val_loss: 3.7869 - val_accuracy: 0.1662\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.7647 - accuracy: 0.1448 - val_loss: 3.7192 - val_accuracy: 0.1722\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.6841 - accuracy: 0.1608 - val_loss: 3.6515 - val_accuracy: 0.1792\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.6078 - accuracy: 0.1746 - val_loss: 3.5784 - val_accuracy: 0.1838\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.5261 - accuracy: 0.1844 - val_loss: 3.5101 - val_accuracy: 0.1878\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.4499 - accuracy: 0.1974 - val_loss: 3.4426 - val_accuracy: 0.2013\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.3907 - accuracy: 0.2034 - val_loss: 3.3894 - val_accuracy: 0.2010\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.3166 - accuracy: 0.2138 - val_loss: 3.3315 - val_accuracy: 0.2126\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.2524 - accuracy: 0.2251 - val_loss: 3.2788 - val_accuracy: 0.2202\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.1725 - accuracy: 0.2358 - val_loss: 3.2287 - val_accuracy: 0.2201\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.1300 - accuracy: 0.2399 - val_loss: 3.1776 - val_accuracy: 0.2296\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 3.1974 - accuracy: 0.2426\n",
            "12.314360729993844 1.0 0.0 0.2488927243240339 0.32136942265801627 0.2 0.32969107170875545\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9a201ec290> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f3c2d50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 18s 26ms/step - loss: 4.2150 - accuracy: 0.1009 - val_loss: 3.1554 - val_accuracy: 0.2721\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 2.4504 - accuracy: 0.4213 - val_loss: 2.6266 - val_accuracy: 0.3414\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 1.6273 - accuracy: 0.5872 - val_loss: 2.4006 - val_accuracy: 0.3677\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 1.1291 - accuracy: 0.7223 - val_loss: 2.3264 - val_accuracy: 0.3675\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 13s 24ms/step - loss: 0.7946 - accuracy: 0.8258 - val_loss: 2.2953 - val_accuracy: 0.3866\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.5951 - accuracy: 0.8846 - val_loss: 2.2692 - val_accuracy: 0.3943\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.4517 - accuracy: 0.9242 - val_loss: 2.2917 - val_accuracy: 0.3890\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.3331 - accuracy: 0.9549 - val_loss: 2.2957 - val_accuracy: 0.3875\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.2678 - accuracy: 0.9703 - val_loss: 2.2997 - val_accuracy: 0.3923\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.2134 - accuracy: 0.9798 - val_loss: 2.3261 - val_accuracy: 0.3973\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1726 - accuracy: 0.9865 - val_loss: 2.3394 - val_accuracy: 0.4009\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1482 - accuracy: 0.9902 - val_loss: 2.3311 - val_accuracy: 0.4087\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1224 - accuracy: 0.9933 - val_loss: 2.3553 - val_accuracy: 0.4071\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.1063 - accuracy: 0.9951 - val_loss: 2.3701 - val_accuracy: 0.4023\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.0933 - accuracy: 0.9963 - val_loss: 2.3767 - val_accuracy: 0.4033\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 12s 23ms/step - loss: 0.0807 - accuracy: 0.9976 - val_loss: 2.4059 - val_accuracy: 0.4053\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3776 - accuracy: 0.4231\n",
            "42.81527854485985 0.8191052907550231 1.3436818559614574 0.22943984998580047 0.2464634269684764 0.2 0.47695015036693567\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978ce489d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99ce0df510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791466e50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792c53450> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 4.4144 - accuracy: 0.0648 - val_loss: 3.1313 - val_accuracy: 0.2435\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.7365 - accuracy: 0.2936 - val_loss: 2.2975 - val_accuracy: 0.3577\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.8808 - accuracy: 0.4610 - val_loss: 1.9942 - val_accuracy: 0.4171\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.4404 - accuracy: 0.5729 - val_loss: 1.8563 - val_accuracy: 0.4619\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.1448 - accuracy: 0.6571 - val_loss: 1.7854 - val_accuracy: 0.4852\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9191 - accuracy: 0.7189 - val_loss: 1.7859 - val_accuracy: 0.4864\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7366 - accuracy: 0.7828 - val_loss: 1.7648 - val_accuracy: 0.4942\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6218 - accuracy: 0.8163 - val_loss: 1.8000 - val_accuracy: 0.4905\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5007 - accuracy: 0.8555 - val_loss: 1.8298 - val_accuracy: 0.5068\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4135 - accuracy: 0.8843 - val_loss: 1.8367 - val_accuracy: 0.5148\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3482 - accuracy: 0.9025 - val_loss: 1.8802 - val_accuracy: 0.5050\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2945 - accuracy: 0.9222 - val_loss: 1.8882 - val_accuracy: 0.5181\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2346 - accuracy: 0.9404 - val_loss: 1.9205 - val_accuracy: 0.5088\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2170 - accuracy: 0.9426 - val_loss: 1.9313 - val_accuracy: 0.5253\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1888 - accuracy: 0.9516 - val_loss: 1.9483 - val_accuracy: 0.5203\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1600 - accuracy: 0.9589 - val_loss: 1.9893 - val_accuracy: 0.5223\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1445 - accuracy: 0.9655 - val_loss: 2.0163 - val_accuracy: 0.5181\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1308 - accuracy: 0.9669 - val_loss: 2.0366 - val_accuracy: 0.5141\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9887 - accuracy: 0.5017\n",
            "48.86316557410454 0.519420390425466 1.1928376869356785 0.24633526051522403 0.16598779413623574 0.2 0.16066212184115067\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791664f90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792ab0410> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dc9c1d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dc92f50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.4774 - accuracy: 0.0482 - val_loss: 3.6852 - val_accuracy: 0.1504\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.1909 - accuracy: 0.2125 - val_loss: 2.4631 - val_accuracy: 0.3216\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1339 - accuracy: 0.4023 - val_loss: 1.9953 - val_accuracy: 0.4274\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6099 - accuracy: 0.5188 - val_loss: 1.8159 - val_accuracy: 0.4584\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2974 - accuracy: 0.6088 - val_loss: 1.7445 - val_accuracy: 0.4864\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0608 - accuracy: 0.6747 - val_loss: 1.7064 - val_accuracy: 0.5108\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8749 - accuracy: 0.7359 - val_loss: 1.6884 - val_accuracy: 0.5221\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7174 - accuracy: 0.7863 - val_loss: 1.6937 - val_accuracy: 0.5201\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5870 - accuracy: 0.8230 - val_loss: 1.7159 - val_accuracy: 0.5450\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5090 - accuracy: 0.8478 - val_loss: 1.7079 - val_accuracy: 0.5416\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4177 - accuracy: 0.8797 - val_loss: 1.7564 - val_accuracy: 0.5352\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3572 - accuracy: 0.8960 - val_loss: 1.7843 - val_accuracy: 0.5349\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2976 - accuracy: 0.9169 - val_loss: 1.8005 - val_accuracy: 0.5419\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 1.8486 - accuracy: 0.5314\n",
            "49.0 0.7859733070743266 0.0 0.2030378350973284 0.17628025880345308 0.1977850274475957 0.4319699119753742\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978db01510> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bfa470d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.4495 - accuracy: 0.0652 - val_loss: 3.5003 - val_accuracy: 0.2613\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9079 - accuracy: 0.3328 - val_loss: 2.5026 - val_accuracy: 0.3815\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9149 - accuracy: 0.5110 - val_loss: 2.0489 - val_accuracy: 0.4461\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3593 - accuracy: 0.6240 - val_loss: 1.8890 - val_accuracy: 0.4862\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0288 - accuracy: 0.7121 - val_loss: 1.7910 - val_accuracy: 0.4915\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8048 - accuracy: 0.7756 - val_loss: 1.7730 - val_accuracy: 0.5032\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6253 - accuracy: 0.8302 - val_loss: 1.8006 - val_accuracy: 0.5093\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5070 - accuracy: 0.8668 - val_loss: 1.7799 - val_accuracy: 0.5101\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4142 - accuracy: 0.8956 - val_loss: 1.7896 - val_accuracy: 0.5163\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3358 - accuracy: 0.9161 - val_loss: 1.8011 - val_accuracy: 0.5238\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2777 - accuracy: 0.9345 - val_loss: 1.8401 - val_accuracy: 0.5317\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2341 - accuracy: 0.9464 - val_loss: 1.8651 - val_accuracy: 0.5361\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1966 - accuracy: 0.9551 - val_loss: 1.8463 - val_accuracy: 0.5332\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1719 - accuracy: 0.9617 - val_loss: 1.8687 - val_accuracy: 0.5346\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1538 - accuracy: 0.9653 - val_loss: 1.8735 - val_accuracy: 0.5404\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1296 - accuracy: 0.9724 - val_loss: 1.8870 - val_accuracy: 0.5429\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1146 - accuracy: 0.9742 - val_loss: 1.9277 - val_accuracy: 0.5449\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1043 - accuracy: 0.9786 - val_loss: 1.9601 - val_accuracy: 0.5412\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0946 - accuracy: 0.9788 - val_loss: 1.9224 - val_accuracy: 0.5421\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0883 - accuracy: 0.9819 - val_loss: 1.9380 - val_accuracy: 0.5431\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0781 - accuracy: 0.9837 - val_loss: 1.9327 - val_accuracy: 0.5447\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1022 - accuracy: 0.5225\n",
            "49.0 0.4757643224662772 0.8611097470617634 0.27806433764808525 0.43395139752244904 0.2 0.26173839671106797\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d5123d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978d9b8890> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf686790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bc6f090> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 33ms/step - loss: 4.5968 - accuracy: 0.0324 - val_loss: 3.8752 - val_accuracy: 0.1672\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.4614 - accuracy: 0.1967 - val_loss: 2.7444 - val_accuracy: 0.3044\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.4323 - accuracy: 0.3547 - val_loss: 2.1512 - val_accuracy: 0.3963\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.7981 - accuracy: 0.4817 - val_loss: 1.9028 - val_accuracy: 0.4501\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4433 - accuracy: 0.5717 - val_loss: 1.8032 - val_accuracy: 0.4679\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1833 - accuracy: 0.6431 - val_loss: 1.7566 - val_accuracy: 0.4759\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.9878 - accuracy: 0.7012 - val_loss: 1.7416 - val_accuracy: 0.4932\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8101 - accuracy: 0.7587 - val_loss: 1.7476 - val_accuracy: 0.5020\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6877 - accuracy: 0.7970 - val_loss: 1.7817 - val_accuracy: 0.5065\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5766 - accuracy: 0.8327 - val_loss: 1.7998 - val_accuracy: 0.5057\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4822 - accuracy: 0.8602 - val_loss: 1.8100 - val_accuracy: 0.5081\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4182 - accuracy: 0.8787 - val_loss: 1.8487 - val_accuracy: 0.5203\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3506 - accuracy: 0.9003 - val_loss: 1.8626 - val_accuracy: 0.5171\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2962 - accuracy: 0.9180 - val_loss: 1.8950 - val_accuracy: 0.5193\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2519 - accuracy: 0.9318 - val_loss: 1.9222 - val_accuracy: 0.5229\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2262 - accuracy: 0.9396 - val_loss: 1.9337 - val_accuracy: 0.5266\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1912 - accuracy: 0.9478 - val_loss: 1.9683 - val_accuracy: 0.5308\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1700 - accuracy: 0.9546 - val_loss: 1.9737 - val_accuracy: 0.5331\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1690 - accuracy: 0.9522 - val_loss: 2.0157 - val_accuracy: 0.5213\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1383 - accuracy: 0.9628 - val_loss: 2.0198 - val_accuracy: 0.5283\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1250 - accuracy: 0.9687 - val_loss: 2.0457 - val_accuracy: 0.5248\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1242 - accuracy: 0.9678 - val_loss: 2.0750 - val_accuracy: 0.5166\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0882 - accuracy: 0.5371\n",
            "46.96550507656838 0.8941457665766012 0.5171656920885132 0.29824753890399586 0.05186455775848259 0.2 0.18910009773121617\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978bc5be10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97927a9910> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b63ae90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978df20290> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.5767 - accuracy: 0.0395 - val_loss: 3.7337 - val_accuracy: 0.1664\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.3589 - accuracy: 0.2017 - val_loss: 2.5523 - val_accuracy: 0.3285\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.2425 - accuracy: 0.3843 - val_loss: 2.0070 - val_accuracy: 0.4210\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6584 - accuracy: 0.5113 - val_loss: 1.7961 - val_accuracy: 0.4686\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.3069 - accuracy: 0.6073 - val_loss: 1.7149 - val_accuracy: 0.4894\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0473 - accuracy: 0.6803 - val_loss: 1.7216 - val_accuracy: 0.4977\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8492 - accuracy: 0.7424 - val_loss: 1.7073 - val_accuracy: 0.5106\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6859 - accuracy: 0.7949 - val_loss: 1.7174 - val_accuracy: 0.5194\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5672 - accuracy: 0.8282 - val_loss: 1.7300 - val_accuracy: 0.5273\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4612 - accuracy: 0.8633 - val_loss: 1.7566 - val_accuracy: 0.5256\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3818 - accuracy: 0.8910 - val_loss: 1.7655 - val_accuracy: 0.5289\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3275 - accuracy: 0.9074 - val_loss: 1.8012 - val_accuracy: 0.5336\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2720 - accuracy: 0.9243 - val_loss: 1.8412 - val_accuracy: 0.5445\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2379 - accuracy: 0.9356 - val_loss: 1.8819 - val_accuracy: 0.5351\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1970 - accuracy: 0.9472 - val_loss: 1.8864 - val_accuracy: 0.5460\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1758 - accuracy: 0.9534 - val_loss: 1.9389 - val_accuracy: 0.5421\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1547 - accuracy: 0.9578 - val_loss: 1.9678 - val_accuracy: 0.5392\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1340 - accuracy: 0.9664 - val_loss: 2.0020 - val_accuracy: 0.5389\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1205 - accuracy: 0.9690 - val_loss: 1.9947 - val_accuracy: 0.5432\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0713 - accuracy: 0.5269\n",
            "35.238225129180655 0.7622428253817837 0.0 0.29291034665128346 0.16006256199991176 0.19310056840360107 0.4325424015631759\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792d81cd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978ef96b50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 4.3235 - accuracy: 0.0903 - val_loss: 3.1749 - val_accuracy: 0.2766\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 2.4855 - accuracy: 0.3970 - val_loss: 2.4717 - val_accuracy: 0.3491\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 1.6187 - accuracy: 0.5621 - val_loss: 2.1956 - val_accuracy: 0.4079\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.1676 - accuracy: 0.6757 - val_loss: 2.1092 - val_accuracy: 0.4232\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.8686 - accuracy: 0.7625 - val_loss: 2.0661 - val_accuracy: 0.4535\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.6721 - accuracy: 0.8208 - val_loss: 2.0842 - val_accuracy: 0.4500\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.5166 - accuracy: 0.8665 - val_loss: 2.0512 - val_accuracy: 0.4574\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.4100 - accuracy: 0.8981 - val_loss: 2.0827 - val_accuracy: 0.4688\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.3268 - accuracy: 0.9252 - val_loss: 2.1037 - val_accuracy: 0.4762\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.2571 - accuracy: 0.9423 - val_loss: 2.1226 - val_accuracy: 0.4651\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.2403 - accuracy: 0.9444 - val_loss: 2.1804 - val_accuracy: 0.4626\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.1781 - accuracy: 0.9655 - val_loss: 2.1751 - val_accuracy: 0.4782\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.1563 - accuracy: 0.9690 - val_loss: 2.1729 - val_accuracy: 0.4797\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.1366 - accuracy: 0.9735 - val_loss: 2.2353 - val_accuracy: 0.4656\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.1122 - accuracy: 0.9802 - val_loss: 2.2079 - val_accuracy: 0.4766\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.1060 - accuracy: 0.9807 - val_loss: 2.2740 - val_accuracy: 0.4806\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.0912 - accuracy: 0.9831 - val_loss: 2.2613 - val_accuracy: 0.4709\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.0801 - accuracy: 0.9861 - val_loss: 2.2833 - val_accuracy: 0.4684\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.0769 - accuracy: 0.9850 - val_loss: 2.2979 - val_accuracy: 0.4786\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.0629 - accuracy: 0.9894 - val_loss: 2.3162 - val_accuracy: 0.4704\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3355 - accuracy: 0.4736\n",
            "49.0 0.8011737297590521 1.6169024768662579 0.19649208508653876 0.30540598224467097 0.2 0.17350318995793518\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799cfe350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d88ce90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d892810> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d88c190> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d873990> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d892610> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.4940 - accuracy: 0.0330 - val_loss: 3.3476 - val_accuracy: 0.1386\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.1603 - accuracy: 0.1527 - val_loss: 2.4729 - val_accuracy: 0.2906\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4427 - accuracy: 0.2856 - val_loss: 2.0744 - val_accuracy: 0.3913\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0042 - accuracy: 0.3958 - val_loss: 1.8653 - val_accuracy: 0.4443\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6746 - accuracy: 0.4848 - val_loss: 1.7373 - val_accuracy: 0.4736\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4317 - accuracy: 0.5547 - val_loss: 1.6812 - val_accuracy: 0.4894\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2342 - accuracy: 0.6156 - val_loss: 1.6422 - val_accuracy: 0.5057\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0679 - accuracy: 0.6685 - val_loss: 1.6174 - val_accuracy: 0.5155\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8985 - accuracy: 0.7223 - val_loss: 1.6197 - val_accuracy: 0.5231\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7670 - accuracy: 0.7627 - val_loss: 1.6375 - val_accuracy: 0.5392\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6611 - accuracy: 0.7994 - val_loss: 1.6589 - val_accuracy: 0.5356\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5639 - accuracy: 0.8264 - val_loss: 1.6922 - val_accuracy: 0.5406\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4876 - accuracy: 0.8552 - val_loss: 1.7095 - val_accuracy: 0.5364\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4051 - accuracy: 0.8817 - val_loss: 1.7801 - val_accuracy: 0.5367\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3425 - accuracy: 0.9001 - val_loss: 1.8229 - val_accuracy: 0.5457\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2933 - accuracy: 0.9149 - val_loss: 1.8063 - val_accuracy: 0.5445\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2483 - accuracy: 0.9300 - val_loss: 1.8601 - val_accuracy: 0.5359\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2214 - accuracy: 0.9361 - val_loss: 1.8972 - val_accuracy: 0.5436\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1953 - accuracy: 0.9464 - val_loss: 1.9469 - val_accuracy: 0.5394\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9693 - accuracy: 0.5411\n",
            "49.0 1.0 1.4864388186053983 0.3604119168078801 0.0 0.2 0.3839614887940124\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978cd65bd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97993665d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9793ac9e10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792ac22d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.7173 - accuracy: 0.0231 - val_loss: 4.1853 - val_accuracy: 0.1152\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.9325 - accuracy: 0.1331 - val_loss: 3.1813 - val_accuracy: 0.2623\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.9485 - accuracy: 0.2750 - val_loss: 2.3922 - val_accuracy: 0.3690\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1585 - accuracy: 0.4013 - val_loss: 1.9615 - val_accuracy: 0.4239\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6812 - accuracy: 0.5104 - val_loss: 1.8223 - val_accuracy: 0.4599\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.3820 - accuracy: 0.5881 - val_loss: 1.7356 - val_accuracy: 0.4937\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1489 - accuracy: 0.6541 - val_loss: 1.7351 - val_accuracy: 0.4952\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9479 - accuracy: 0.7136 - val_loss: 1.7341 - val_accuracy: 0.4988\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8153 - accuracy: 0.7571 - val_loss: 1.7500 - val_accuracy: 0.5185\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6872 - accuracy: 0.7994 - val_loss: 1.7673 - val_accuracy: 0.5268\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5832 - accuracy: 0.8290 - val_loss: 1.7960 - val_accuracy: 0.5243\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.4999 - accuracy: 0.8546 - val_loss: 1.8138 - val_accuracy: 0.5344\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4187 - accuracy: 0.8782 - val_loss: 1.8360 - val_accuracy: 0.5364\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3541 - accuracy: 0.8985 - val_loss: 1.8852 - val_accuracy: 0.5319\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3115 - accuracy: 0.9130 - val_loss: 1.8689 - val_accuracy: 0.5475\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2724 - accuracy: 0.9235 - val_loss: 1.9074 - val_accuracy: 0.5495\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2338 - accuracy: 0.9392 - val_loss: 1.9146 - val_accuracy: 0.5597\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2034 - accuracy: 0.9448 - val_loss: 1.9838 - val_accuracy: 0.5434\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1809 - accuracy: 0.9517 - val_loss: 1.9697 - val_accuracy: 0.5502\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1700 - accuracy: 0.9534 - val_loss: 1.9872 - val_accuracy: 0.5445\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1557 - accuracy: 0.9588 - val_loss: 2.0237 - val_accuracy: 0.5470\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.0861 - accuracy: 0.5381\n",
            "47.11285778163936 0.9063774120510851 2.224964570388103 0.18326599881250247 0.31113347260422186 0.10034065829143313 0.18471113451916998\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791bdb990> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e0d6b90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792d5ead0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792791c50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bc010d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97927bad10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.8905 - accuracy: 0.0146 - val_loss: 4.5101 - val_accuracy: 0.0276\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 4.5207 - accuracy: 0.0241 - val_loss: 4.4075 - val_accuracy: 0.0432\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 4.3950 - accuracy: 0.0406 - val_loss: 4.2658 - val_accuracy: 0.0555\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 4.2577 - accuracy: 0.0504 - val_loss: 4.0852 - val_accuracy: 0.0627\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 4.0912 - accuracy: 0.0635 - val_loss: 3.9006 - val_accuracy: 0.0771\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.9227 - accuracy: 0.0746 - val_loss: 3.7248 - val_accuracy: 0.0946\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.7567 - accuracy: 0.0849 - val_loss: 3.5627 - val_accuracy: 0.1105\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.5978 - accuracy: 0.1045 - val_loss: 3.3979 - val_accuracy: 0.1285\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.4443 - accuracy: 0.1227 - val_loss: 3.2563 - val_accuracy: 0.1544\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.3288 - accuracy: 0.1339 - val_loss: 3.1508 - val_accuracy: 0.1621\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.2133 - accuracy: 0.1508 - val_loss: 3.0416 - val_accuracy: 0.1867\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.0824 - accuracy: 0.1723 - val_loss: 2.9460 - val_accuracy: 0.1938\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9830 - accuracy: 0.1893 - val_loss: 2.8624 - val_accuracy: 0.2126\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.8910 - accuracy: 0.2056 - val_loss: 2.7799 - val_accuracy: 0.2226\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.7888 - accuracy: 0.2209 - val_loss: 2.7136 - val_accuracy: 0.2334\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.7051 - accuracy: 0.2389 - val_loss: 2.6488 - val_accuracy: 0.2560\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.6294 - accuracy: 0.2547 - val_loss: 2.5828 - val_accuracy: 0.2678\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.5626 - accuracy: 0.2674 - val_loss: 2.5305 - val_accuracy: 0.2864\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4839 - accuracy: 0.2891 - val_loss: 2.4783 - val_accuracy: 0.2891\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4128 - accuracy: 0.3034 - val_loss: 2.4319 - val_accuracy: 0.3024\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.3501 - accuracy: 0.3180 - val_loss: 2.3778 - val_accuracy: 0.3175\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.2969 - accuracy: 0.3315 - val_loss: 2.3299 - val_accuracy: 0.3336\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.2317 - accuracy: 0.3476 - val_loss: 2.2818 - val_accuracy: 0.3418\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1847 - accuracy: 0.3586 - val_loss: 2.2501 - val_accuracy: 0.3466\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1325 - accuracy: 0.3714 - val_loss: 2.2153 - val_accuracy: 0.3514\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0712 - accuracy: 0.3850 - val_loss: 2.1742 - val_accuracy: 0.3589\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0230 - accuracy: 0.4025 - val_loss: 2.1445 - val_accuracy: 0.3679\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.9594 - accuracy: 0.4161 - val_loss: 2.1092 - val_accuracy: 0.3753\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.9252 - accuracy: 0.4269 - val_loss: 2.0786 - val_accuracy: 0.3782\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.8731 - accuracy: 0.4423 - val_loss: 2.0571 - val_accuracy: 0.3856\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0388 - accuracy: 0.3922\n",
            "30.73523297401495 0.9432025279827452 0.6678317439032428 0.2535802293547708 0.27066884368579996 0.2 0.27206081857097253\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b7fac50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791b94750> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9a3453b950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791860690> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 30ms/step - loss: 4.5968 - accuracy: 0.0289 - val_loss: 3.6338 - val_accuracy: 0.1770\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 3.2600 - accuracy: 0.2084 - val_loss: 2.6162 - val_accuracy: 0.3090\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 2.2975 - accuracy: 0.3633 - val_loss: 2.2272 - val_accuracy: 0.3722\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.7808 - accuracy: 0.4737 - val_loss: 2.0669 - val_accuracy: 0.4061\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.4597 - accuracy: 0.5607 - val_loss: 1.9797 - val_accuracy: 0.4189\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.2119 - accuracy: 0.6326 - val_loss: 1.9510 - val_accuracy: 0.4387\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 1.0211 - accuracy: 0.6916 - val_loss: 1.9688 - val_accuracy: 0.4503\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.8455 - accuracy: 0.7431 - val_loss: 1.9485 - val_accuracy: 0.4609\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.7186 - accuracy: 0.7835 - val_loss: 1.9727 - val_accuracy: 0.4576\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.6026 - accuracy: 0.8264 - val_loss: 2.0015 - val_accuracy: 0.4759\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.4899 - accuracy: 0.8585 - val_loss: 2.0245 - val_accuracy: 0.4747\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 15s 27ms/step - loss: 0.4230 - accuracy: 0.8822 - val_loss: 2.0778 - val_accuracy: 0.4573\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.3639 - accuracy: 0.8983 - val_loss: 2.1368 - val_accuracy: 0.4656\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 0.2984 - accuracy: 0.9191 - val_loss: 2.1939 - val_accuracy: 0.4653\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1924 - accuracy: 0.4534\n",
            "44.52526272262587 0.8382479013308074 2.126285277669923 0.26090513186960235 0.25914111144983065 0.2 0.250969490632568\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e4c5b90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97991bda10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978cf40550> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978cd77d90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978cf43790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9a3453b310> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 33ms/step - loss: 4.4495 - accuracy: 0.0393 - val_loss: 3.2311 - val_accuracy: 0.1641\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.0465 - accuracy: 0.1716 - val_loss: 2.4339 - val_accuracy: 0.3133\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.3770 - accuracy: 0.2988 - val_loss: 2.0993 - val_accuracy: 0.3765\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.9687 - accuracy: 0.4067 - val_loss: 1.9057 - val_accuracy: 0.4156\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6589 - accuracy: 0.4914 - val_loss: 1.8128 - val_accuracy: 0.4372\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4044 - accuracy: 0.5631 - val_loss: 1.7601 - val_accuracy: 0.4673\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2127 - accuracy: 0.6267 - val_loss: 1.7339 - val_accuracy: 0.4834\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0357 - accuracy: 0.6821 - val_loss: 1.7155 - val_accuracy: 0.4929\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8940 - accuracy: 0.7260 - val_loss: 1.7208 - val_accuracy: 0.5105\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7657 - accuracy: 0.7641 - val_loss: 1.7491 - val_accuracy: 0.5118\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6428 - accuracy: 0.8030 - val_loss: 1.7812 - val_accuracy: 0.5165\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5605 - accuracy: 0.8298 - val_loss: 1.8234 - val_accuracy: 0.5093\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4633 - accuracy: 0.8582 - val_loss: 1.8638 - val_accuracy: 0.5118\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4074 - accuracy: 0.8780 - val_loss: 1.9285 - val_accuracy: 0.5163\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3343 - accuracy: 0.9019 - val_loss: 1.9755 - val_accuracy: 0.5146\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9063 - accuracy: 0.5270\n",
            "47.41114176968574 0.9464141500670452 1.814030768561363 0.2223411290746712 0.20379641819921163 0.2 0.16586554181150054\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e49d550> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798f6e110> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9793ba5090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9a201b7210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99e80f2dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978efa9050> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.3367 - accuracy: 0.0503 - val_loss: 2.9543 - val_accuracy: 0.1991\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.8376 - accuracy: 0.2056 - val_loss: 2.3108 - val_accuracy: 0.3236\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.2145 - accuracy: 0.3342 - val_loss: 1.9742 - val_accuracy: 0.3989\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.8187 - accuracy: 0.4473 - val_loss: 1.7976 - val_accuracy: 0.4541\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.5182 - accuracy: 0.5323 - val_loss: 1.7160 - val_accuracy: 0.4927\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2856 - accuracy: 0.5946 - val_loss: 1.6585 - val_accuracy: 0.5121\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.1093 - accuracy: 0.6516 - val_loss: 1.6434 - val_accuracy: 0.5108\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9270 - accuracy: 0.7087 - val_loss: 1.6302 - val_accuracy: 0.5286\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7986 - accuracy: 0.7519 - val_loss: 1.6372 - val_accuracy: 0.5344\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6696 - accuracy: 0.7939 - val_loss: 1.6756 - val_accuracy: 0.5334\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5630 - accuracy: 0.8295 - val_loss: 1.6917 - val_accuracy: 0.5417\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4753 - accuracy: 0.8559 - val_loss: 1.7094 - val_accuracy: 0.5359\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3925 - accuracy: 0.8820 - val_loss: 1.7432 - val_accuracy: 0.5444\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3422 - accuracy: 0.8984 - val_loss: 1.8205 - val_accuracy: 0.5384\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2838 - accuracy: 0.9164 - val_loss: 1.8490 - val_accuracy: 0.5427\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2396 - accuracy: 0.9337 - val_loss: 1.8908 - val_accuracy: 0.5489\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2059 - accuracy: 0.9425 - val_loss: 1.9297 - val_accuracy: 0.5555\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1752 - accuracy: 0.9514 - val_loss: 1.9660 - val_accuracy: 0.5540\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1481 - accuracy: 0.9599 - val_loss: 1.9899 - val_accuracy: 0.5492\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1358 - accuracy: 0.9620 - val_loss: 2.0092 - val_accuracy: 0.5495\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1191 - accuracy: 0.9664 - val_loss: 2.0505 - val_accuracy: 0.5554\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.1227 - accuracy: 0.5442\n",
            "49.0 0.888334213725325 0.44589365809535964 0.21163123952207238 0.24571799531481162 0.2 0.22022629432785396\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792b67b50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d082410> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.3342 - accuracy: 0.0828 - val_loss: 3.3034 - val_accuracy: 0.2781\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.6079 - accuracy: 0.3831 - val_loss: 2.2881 - val_accuracy: 0.4117\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6750 - accuracy: 0.5522 - val_loss: 1.9787 - val_accuracy: 0.4488\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2097 - accuracy: 0.6614 - val_loss: 1.8407 - val_accuracy: 0.4787\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9235 - accuracy: 0.7443 - val_loss: 1.8129 - val_accuracy: 0.4968\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7306 - accuracy: 0.7990 - val_loss: 1.7796 - val_accuracy: 0.5170\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5661 - accuracy: 0.8478 - val_loss: 1.7820 - val_accuracy: 0.5150\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4476 - accuracy: 0.8857 - val_loss: 1.8148 - val_accuracy: 0.5126\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3600 - accuracy: 0.9096 - val_loss: 1.8461 - val_accuracy: 0.5273\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3038 - accuracy: 0.9255 - val_loss: 1.8238 - val_accuracy: 0.5263\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2557 - accuracy: 0.9373 - val_loss: 1.8332 - val_accuracy: 0.5336\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2168 - accuracy: 0.9488 - val_loss: 1.8455 - val_accuracy: 0.5404\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1784 - accuracy: 0.9612 - val_loss: 1.8712 - val_accuracy: 0.5309\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1600 - accuracy: 0.9636 - val_loss: 1.8811 - val_accuracy: 0.5484\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1358 - accuracy: 0.9686 - val_loss: 1.8859 - val_accuracy: 0.5480\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1275 - accuracy: 0.9717 - val_loss: 1.8720 - val_accuracy: 0.5440\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1052 - accuracy: 0.9768 - val_loss: 1.8764 - val_accuracy: 0.5542\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0917 - accuracy: 0.9804 - val_loss: 1.8961 - val_accuracy: 0.5524\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0862 - accuracy: 0.9823 - val_loss: 1.9030 - val_accuracy: 0.5504\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0834 - accuracy: 0.9826 - val_loss: 1.9285 - val_accuracy: 0.5554\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0696 - accuracy: 0.9856 - val_loss: 1.9149 - val_accuracy: 0.5595\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0677 - accuracy: 0.9868 - val_loss: 1.9401 - val_accuracy: 0.5575\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0618 - accuracy: 0.9872 - val_loss: 1.9381 - val_accuracy: 0.5585\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0599 - accuracy: 0.9879 - val_loss: 1.9536 - val_accuracy: 0.5487\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0552 - accuracy: 0.9885 - val_loss: 1.9824 - val_accuracy: 0.5554\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0560 - accuracy: 0.5403\n",
            "49.0 0.8626832994332734 1.1607455836365836 0.41072528268035546 0.25201638190567005 0.2 0.1492830709862858\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b7ebb90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978db5f150> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798faa0d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4525d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.5708 - accuracy: 0.0349 - val_loss: 3.7059 - val_accuracy: 0.1843\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.3744 - accuracy: 0.2010 - val_loss: 2.6323 - val_accuracy: 0.3231\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4034 - accuracy: 0.3544 - val_loss: 2.0826 - val_accuracy: 0.4026\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.8224 - accuracy: 0.4706 - val_loss: 1.8515 - val_accuracy: 0.4521\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4829 - accuracy: 0.5587 - val_loss: 1.7357 - val_accuracy: 0.4731\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2416 - accuracy: 0.6264 - val_loss: 1.6902 - val_accuracy: 0.4960\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0338 - accuracy: 0.6848 - val_loss: 1.7043 - val_accuracy: 0.5017\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8642 - accuracy: 0.7380 - val_loss: 1.6655 - val_accuracy: 0.5173\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.7320 - accuracy: 0.7821 - val_loss: 1.6766 - val_accuracy: 0.5236\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6159 - accuracy: 0.8170 - val_loss: 1.6808 - val_accuracy: 0.5294\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5224 - accuracy: 0.8444 - val_loss: 1.7169 - val_accuracy: 0.5268\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4475 - accuracy: 0.8683 - val_loss: 1.7474 - val_accuracy: 0.5374\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3859 - accuracy: 0.8875 - val_loss: 1.7448 - val_accuracy: 0.5431\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3291 - accuracy: 0.9055 - val_loss: 1.7641 - val_accuracy: 0.5457\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.2915 - accuracy: 0.9157 - val_loss: 1.8613 - val_accuracy: 0.5465\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2339 - accuracy: 0.9345 - val_loss: 1.8529 - val_accuracy: 0.5475\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2228 - accuracy: 0.9369 - val_loss: 1.8969 - val_accuracy: 0.5520\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1879 - accuracy: 0.9495 - val_loss: 1.9329 - val_accuracy: 0.5525\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1761 - accuracy: 0.9510 - val_loss: 1.9631 - val_accuracy: 0.5565\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1503 - accuracy: 0.9588 - val_loss: 1.9574 - val_accuracy: 0.5505\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1394 - accuracy: 0.9628 - val_loss: 1.9882 - val_accuracy: 0.5577\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1306 - accuracy: 0.9634 - val_loss: 2.0087 - val_accuracy: 0.5424\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1183 - accuracy: 0.9680 - val_loss: 2.0407 - val_accuracy: 0.5572\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1074 - accuracy: 0.9706 - val_loss: 2.0486 - val_accuracy: 0.5602\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0971 - accuracy: 0.9731 - val_loss: 2.0456 - val_accuracy: 0.5497\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0972 - accuracy: 0.9733 - val_loss: 2.0988 - val_accuracy: 0.5554\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0856 - accuracy: 0.9777 - val_loss: 2.1246 - val_accuracy: 0.5535\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0778 - accuracy: 0.9796 - val_loss: 2.0987 - val_accuracy: 0.5485\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2342 - accuracy: 0.5336\n",
            "46.271514877474345 0.9717459889045076 1.5207815900050723 0.26525403200236664 0.17170724342598112 0.2 0.17774158855451724\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d01e550> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e1ed910> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e1ca490> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d019d90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d317fd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d317050> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 33ms/step - loss: 4.4874 - accuracy: 0.0315 - val_loss: 3.2242 - val_accuracy: 0.1715\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.9979 - accuracy: 0.1813 - val_loss: 2.4001 - val_accuracy: 0.3049\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.2921 - accuracy: 0.3223 - val_loss: 2.0273 - val_accuracy: 0.3863\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.8446 - accuracy: 0.4394 - val_loss: 1.8415 - val_accuracy: 0.4400\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.5485 - accuracy: 0.5197 - val_loss: 1.7347 - val_accuracy: 0.4644\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2911 - accuracy: 0.5999 - val_loss: 1.6950 - val_accuracy: 0.4874\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1147 - accuracy: 0.6528 - val_loss: 1.6494 - val_accuracy: 0.5053\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9397 - accuracy: 0.7098 - val_loss: 1.6541 - val_accuracy: 0.5115\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8098 - accuracy: 0.7475 - val_loss: 1.6952 - val_accuracy: 0.5123\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6690 - accuracy: 0.7937 - val_loss: 1.7138 - val_accuracy: 0.5369\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5564 - accuracy: 0.8300 - val_loss: 1.7674 - val_accuracy: 0.5399\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4627 - accuracy: 0.8621 - val_loss: 1.8047 - val_accuracy: 0.5346\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3892 - accuracy: 0.8849 - val_loss: 1.8329 - val_accuracy: 0.5387\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3205 - accuracy: 0.9081 - val_loss: 1.8963 - val_accuracy: 0.5314\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2736 - accuracy: 0.9223 - val_loss: 1.9235 - val_accuracy: 0.5351\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.0043 - accuracy: 0.5168\n",
            "49.0 0.9534802045655347 0.0 0.13354172087571364 0.2583703597293549 0.1992227623390699 0.3453846048984238\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d018990> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bf73bad0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.4449 - accuracy: 0.0627 - val_loss: 3.5827 - val_accuracy: 0.2387\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.0236 - accuracy: 0.3283 - val_loss: 2.5603 - val_accuracy: 0.3851\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0557 - accuracy: 0.4890 - val_loss: 2.0727 - val_accuracy: 0.4596\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4854 - accuracy: 0.5945 - val_loss: 1.9055 - val_accuracy: 0.4774\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1303 - accuracy: 0.6813 - val_loss: 1.8084 - val_accuracy: 0.5038\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9125 - accuracy: 0.7440 - val_loss: 1.7762 - val_accuracy: 0.5183\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7537 - accuracy: 0.7946 - val_loss: 1.7768 - val_accuracy: 0.5155\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5853 - accuracy: 0.8420 - val_loss: 1.8025 - val_accuracy: 0.5214\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4991 - accuracy: 0.8657 - val_loss: 1.7957 - val_accuracy: 0.5165\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4025 - accuracy: 0.8936 - val_loss: 1.7997 - val_accuracy: 0.5266\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3453 - accuracy: 0.9136 - val_loss: 1.8598 - val_accuracy: 0.5309\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2999 - accuracy: 0.9248 - val_loss: 1.8693 - val_accuracy: 0.5294\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2551 - accuracy: 0.9392 - val_loss: 1.9025 - val_accuracy: 0.5331\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2193 - accuracy: 0.9481 - val_loss: 1.9050 - val_accuracy: 0.5364\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1981 - accuracy: 0.9512 - val_loss: 1.9243 - val_accuracy: 0.5485\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1817 - accuracy: 0.9561 - val_loss: 1.9712 - val_accuracy: 0.5397\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1571 - accuracy: 0.9627 - val_loss: 1.9186 - val_accuracy: 0.5537\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1374 - accuracy: 0.9686 - val_loss: 1.9485 - val_accuracy: 0.5482\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1295 - accuracy: 0.9690 - val_loss: 1.9551 - val_accuracy: 0.5509\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1113 - accuracy: 0.9733 - val_loss: 2.0040 - val_accuracy: 0.5422\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1099 - accuracy: 0.9731 - val_loss: 1.9617 - val_accuracy: 0.5515\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.0335 - accuracy: 0.5430\n",
            "49.0 0.8074953705570229 1.6501776396105299 0.21016515573072933 0.2957978094015317 0.2 0.19240559299046792\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f462dd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97914ad1d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfa62590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97914adb50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792794450> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97990f9950> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 34ms/step - loss: 4.5349 - accuracy: 0.0321 - val_loss: 3.5128 - val_accuracy: 0.1516\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.2680 - accuracy: 0.1395 - val_loss: 2.5070 - val_accuracy: 0.2774\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.5165 - accuracy: 0.2683 - val_loss: 2.1324 - val_accuracy: 0.3684\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.0769 - accuracy: 0.3810 - val_loss: 1.8956 - val_accuracy: 0.4428\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.7326 - accuracy: 0.4754 - val_loss: 1.7880 - val_accuracy: 0.4671\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.4868 - accuracy: 0.5422 - val_loss: 1.7225 - val_accuracy: 0.4782\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.2803 - accuracy: 0.6074 - val_loss: 1.6768 - val_accuracy: 0.4963\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1145 - accuracy: 0.6517 - val_loss: 1.6734 - val_accuracy: 0.5106\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.9428 - accuracy: 0.7095 - val_loss: 1.6662 - val_accuracy: 0.5165\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.8112 - accuracy: 0.7504 - val_loss: 1.6661 - val_accuracy: 0.5198\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6946 - accuracy: 0.7900 - val_loss: 1.6672 - val_accuracy: 0.5419\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.5961 - accuracy: 0.8171 - val_loss: 1.7222 - val_accuracy: 0.5334\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.5010 - accuracy: 0.8480 - val_loss: 1.7839 - val_accuracy: 0.5421\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.4309 - accuracy: 0.8704 - val_loss: 1.8114 - val_accuracy: 0.5465\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.3648 - accuracy: 0.8901 - val_loss: 1.8352 - val_accuracy: 0.5482\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.3181 - accuracy: 0.9067 - val_loss: 1.8855 - val_accuracy: 0.5469\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2716 - accuracy: 0.9199 - val_loss: 1.9094 - val_accuracy: 0.5505\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.2259 - accuracy: 0.9345 - val_loss: 1.9582 - val_accuracy: 0.5492\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.2133 - accuracy: 0.9387 - val_loss: 1.9612 - val_accuracy: 0.5620\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1811 - accuracy: 0.9499 - val_loss: 1.9932 - val_accuracy: 0.5593\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.1571 - accuracy: 0.9567 - val_loss: 2.0180 - val_accuracy: 0.5588\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.1438 - accuracy: 0.9605 - val_loss: 2.0245 - val_accuracy: 0.5642\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.1280 - accuracy: 0.9640 - val_loss: 2.0699 - val_accuracy: 0.5587\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1145 - accuracy: 0.9681 - val_loss: 2.1223 - val_accuracy: 0.5568\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.1057 - accuracy: 0.9699 - val_loss: 2.1425 - val_accuracy: 0.5672\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.0970 - accuracy: 0.9742 - val_loss: 2.1536 - val_accuracy: 0.5620\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.0825 - accuracy: 0.9766 - val_loss: 2.1606 - val_accuracy: 0.5618\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.0814 - accuracy: 0.9786 - val_loss: 2.1833 - val_accuracy: 0.5583\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.0741 - accuracy: 0.9789 - val_loss: 2.2023 - val_accuracy: 0.5532\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.2895 - accuracy: 0.5498\n",
            "49.0 1.0 1.8430603368871163 0.27013460824988744 0.19601352498293512 0.2 0.23809677746161995\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97915dafd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97916f97d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979914de10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798e5b110> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798f39d50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979914b910> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.3097 - accuracy: 0.0459 - val_loss: 3.0925 - val_accuracy: 0.1908\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.9555 - accuracy: 0.1762 - val_loss: 2.3758 - val_accuracy: 0.3062\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.3146 - accuracy: 0.3187 - val_loss: 2.0175 - val_accuracy: 0.3881\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9009 - accuracy: 0.4243 - val_loss: 1.8240 - val_accuracy: 0.4453\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.5969 - accuracy: 0.5070 - val_loss: 1.7190 - val_accuracy: 0.4751\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.3591 - accuracy: 0.5761 - val_loss: 1.6543 - val_accuracy: 0.5030\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1460 - accuracy: 0.6416 - val_loss: 1.6435 - val_accuracy: 0.5221\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9893 - accuracy: 0.6903 - val_loss: 1.6341 - val_accuracy: 0.5321\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.8452 - accuracy: 0.7382 - val_loss: 1.6438 - val_accuracy: 0.5293\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7126 - accuracy: 0.7805 - val_loss: 1.6718 - val_accuracy: 0.5344\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6040 - accuracy: 0.8164 - val_loss: 1.7066 - val_accuracy: 0.5381\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5124 - accuracy: 0.8453 - val_loss: 1.7324 - val_accuracy: 0.5376\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4289 - accuracy: 0.8714 - val_loss: 1.7809 - val_accuracy: 0.5337\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3682 - accuracy: 0.8923 - val_loss: 1.8121 - val_accuracy: 0.5464\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3154 - accuracy: 0.9056 - val_loss: 1.8678 - val_accuracy: 0.5505\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2724 - accuracy: 0.9196 - val_loss: 1.9356 - val_accuracy: 0.5504\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2292 - accuracy: 0.9360 - val_loss: 1.9698 - val_accuracy: 0.5499\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2138 - accuracy: 0.9400 - val_loss: 1.9763 - val_accuracy: 0.5532\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1757 - accuracy: 0.9510 - val_loss: 2.0287 - val_accuracy: 0.5512\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 2.0434 - val_accuracy: 0.5470\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1377 - accuracy: 0.9626 - val_loss: 2.0650 - val_accuracy: 0.5615\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1342 - accuracy: 0.9613 - val_loss: 2.1134 - val_accuracy: 0.5502\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1124 - accuracy: 0.9685 - val_loss: 2.0845 - val_accuracy: 0.5544\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0992 - accuracy: 0.9745 - val_loss: 2.1312 - val_accuracy: 0.5515\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 2.1109 - val_accuracy: 0.5613\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.1909 - accuracy: 0.5464\n",
            "49.0 0.7844276851416818 2.9587712228646414 0.34868002681683924 0.2456903160501979 0.14276851805052998 0.29936394526470295\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b505690> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b5051d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791021150> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e3fb410> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d3648d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97910216d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e0f2ed0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf7f1990> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 34ms/step - loss: 4.6315 - accuracy: 0.0263 - val_loss: 4.0342 - val_accuracy: 0.0540\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.8493 - accuracy: 0.0542 - val_loss: 3.3363 - val_accuracy: 0.1044\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.4087 - accuracy: 0.0694 - val_loss: 3.0752 - val_accuracy: 0.1519\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.1943 - accuracy: 0.0913 - val_loss: 2.8600 - val_accuracy: 0.1920\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 3.0113 - accuracy: 0.1257 - val_loss: 2.6660 - val_accuracy: 0.2447\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.8467 - accuracy: 0.1650 - val_loss: 2.5099 - val_accuracy: 0.2937\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.6900 - accuracy: 0.1993 - val_loss: 2.3781 - val_accuracy: 0.3155\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.5303 - accuracy: 0.2378 - val_loss: 2.2648 - val_accuracy: 0.3452\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.3975 - accuracy: 0.2645 - val_loss: 2.1566 - val_accuracy: 0.3717\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.2716 - accuracy: 0.3013 - val_loss: 2.0624 - val_accuracy: 0.3873\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.1307 - accuracy: 0.3378 - val_loss: 1.9686 - val_accuracy: 0.4066\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 2.0268 - accuracy: 0.3645 - val_loss: 1.8859 - val_accuracy: 0.4257\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.9027 - accuracy: 0.4015 - val_loss: 1.8204 - val_accuracy: 0.4325\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.8059 - accuracy: 0.4247 - val_loss: 1.7715 - val_accuracy: 0.4408\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.6865 - accuracy: 0.4563 - val_loss: 1.7278 - val_accuracy: 0.4633\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.6046 - accuracy: 0.4823 - val_loss: 1.6923 - val_accuracy: 0.4732\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.5081 - accuracy: 0.5154 - val_loss: 1.6803 - val_accuracy: 0.4764\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.4214 - accuracy: 0.5404 - val_loss: 1.6666 - val_accuracy: 0.4973\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.3471 - accuracy: 0.5642 - val_loss: 1.6503 - val_accuracy: 0.5088\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.2686 - accuracy: 0.5941 - val_loss: 1.6518 - val_accuracy: 0.5131\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1945 - accuracy: 0.6189 - val_loss: 1.6635 - val_accuracy: 0.5185\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.1239 - accuracy: 0.6360 - val_loss: 1.6780 - val_accuracy: 0.5238\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0566 - accuracy: 0.6625 - val_loss: 1.6791 - val_accuracy: 0.5158\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.9740 - accuracy: 0.6896 - val_loss: 1.6969 - val_accuracy: 0.5108\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9030 - accuracy: 0.7106 - val_loss: 1.7139 - val_accuracy: 0.5298\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.8515 - accuracy: 0.7321 - val_loss: 1.7275 - val_accuracy: 0.5332\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.7885 - accuracy: 0.7483 - val_loss: 1.7565 - val_accuracy: 0.5332\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7353 - accuracy: 0.7731 - val_loss: 1.7785 - val_accuracy: 0.5436\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6636 - accuracy: 0.7901 - val_loss: 1.8195 - val_accuracy: 0.5407\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6193 - accuracy: 0.8066 - val_loss: 1.8622 - val_accuracy: 0.5396\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.8239 - accuracy: 0.5409\n",
            "41.718105584247226 0.8582195069826014 1.7190344154203958 0.2629262936101528 0.24597489141369222 0.2 0.23019494504199545\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f83dd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792d13bd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979154f590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791026090> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9793b53fd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e45cc10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.3982 - accuracy: 0.0454 - val_loss: 3.0303 - val_accuracy: 0.1938\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9109 - accuracy: 0.1991 - val_loss: 2.3693 - val_accuracy: 0.3145\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.3140 - accuracy: 0.3120 - val_loss: 2.0240 - val_accuracy: 0.3983\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9120 - accuracy: 0.4166 - val_loss: 1.8284 - val_accuracy: 0.4410\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6176 - accuracy: 0.5002 - val_loss: 1.7462 - val_accuracy: 0.4646\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3754 - accuracy: 0.5709 - val_loss: 1.6741 - val_accuracy: 0.4905\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.1661 - accuracy: 0.6324 - val_loss: 1.6515 - val_accuracy: 0.4952\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0078 - accuracy: 0.6851 - val_loss: 1.6588 - val_accuracy: 0.5183\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8691 - accuracy: 0.7303 - val_loss: 1.6626 - val_accuracy: 0.5060\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7410 - accuracy: 0.7711 - val_loss: 1.6973 - val_accuracy: 0.5209\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6394 - accuracy: 0.8028 - val_loss: 1.7237 - val_accuracy: 0.5186\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5453 - accuracy: 0.8318 - val_loss: 1.7667 - val_accuracy: 0.5354\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4578 - accuracy: 0.8637 - val_loss: 1.7789 - val_accuracy: 0.5344\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3993 - accuracy: 0.8810 - val_loss: 1.8452 - val_accuracy: 0.5406\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3386 - accuracy: 0.8992 - val_loss: 1.8560 - val_accuracy: 0.5409\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2901 - accuracy: 0.9172 - val_loss: 1.8979 - val_accuracy: 0.5384\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2478 - accuracy: 0.9294 - val_loss: 1.9426 - val_accuracy: 0.5359\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2239 - accuracy: 0.9355 - val_loss: 1.9849 - val_accuracy: 0.5427\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1793 - accuracy: 0.9504 - val_loss: 2.0346 - val_accuracy: 0.5429\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1634 - accuracy: 0.9546 - val_loss: 2.0937 - val_accuracy: 0.5384\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1472 - accuracy: 0.9587 - val_loss: 2.1143 - val_accuracy: 0.5412\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1321 - accuracy: 0.9628 - val_loss: 2.1684 - val_accuracy: 0.5342\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1191 - accuracy: 0.9672 - val_loss: 2.1880 - val_accuracy: 0.5389\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.2087 - accuracy: 0.5342\n",
            "44.86680197187455 0.7649625900606626 1.9174364449654786 0.2847191898485157 0.24941089120673568 0.1941715675489714 0.2176349155301328\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978ef15950> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e32b4d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979146f990> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791a6d490> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978db15590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799cc7f90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.3814 - accuracy: 0.0448 - val_loss: 3.1483 - val_accuracy: 0.1651\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.0212 - accuracy: 0.1736 - val_loss: 2.4712 - val_accuracy: 0.2901\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4302 - accuracy: 0.2868 - val_loss: 2.1455 - val_accuracy: 0.3632\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0033 - accuracy: 0.3953 - val_loss: 1.9476 - val_accuracy: 0.4074\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6888 - accuracy: 0.4834 - val_loss: 1.8162 - val_accuracy: 0.4535\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.4557 - accuracy: 0.5509 - val_loss: 1.7472 - val_accuracy: 0.4759\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2500 - accuracy: 0.6089 - val_loss: 1.7207 - val_accuracy: 0.4874\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0801 - accuracy: 0.6592 - val_loss: 1.7170 - val_accuracy: 0.4920\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9162 - accuracy: 0.7136 - val_loss: 1.7270 - val_accuracy: 0.4914\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7924 - accuracy: 0.7517 - val_loss: 1.7645 - val_accuracy: 0.4973\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6726 - accuracy: 0.7947 - val_loss: 1.8083 - val_accuracy: 0.5022\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5921 - accuracy: 0.8194 - val_loss: 1.8362 - val_accuracy: 0.5071\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4948 - accuracy: 0.8494 - val_loss: 1.8972 - val_accuracy: 0.5110\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4198 - accuracy: 0.8746 - val_loss: 1.9712 - val_accuracy: 0.5093\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3515 - accuracy: 0.8959 - val_loss: 2.0141 - val_accuracy: 0.5168\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3060 - accuracy: 0.9113 - val_loss: 2.0614 - val_accuracy: 0.5163\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2561 - accuracy: 0.9240 - val_loss: 2.1047 - val_accuracy: 0.5111\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2264 - accuracy: 0.9367 - val_loss: 2.1538 - val_accuracy: 0.5181\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1905 - accuracy: 0.9459 - val_loss: 2.1774 - val_accuracy: 0.5268\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1724 - accuracy: 0.9509 - val_loss: 2.1883 - val_accuracy: 0.5203\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1445 - accuracy: 0.9587 - val_loss: 2.2109 - val_accuracy: 0.5286\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1287 - accuracy: 0.9634 - val_loss: 2.2844 - val_accuracy: 0.5206\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1192 - accuracy: 0.9672 - val_loss: 2.3062 - val_accuracy: 0.5221\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1073 - accuracy: 0.9699 - val_loss: 2.3106 - val_accuracy: 0.5183\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1008 - accuracy: 0.9721 - val_loss: 2.3318 - val_accuracy: 0.5243\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.2974 - accuracy: 0.5216\n",
            "46.397626335313475 1.0 2.1220997061312326 0.21769728763686594 0.2880786960131033 0.2 0.2065729977977402\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97916a95d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9799645c10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798e02bd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979168ab90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798e1de10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799645910> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 34ms/step - loss: 4.5868 - accuracy: 0.0294 - val_loss: 3.3997 - val_accuracy: 0.1705\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.1904 - accuracy: 0.1623 - val_loss: 2.4594 - val_accuracy: 0.3015\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.4183 - accuracy: 0.2936 - val_loss: 2.0661 - val_accuracy: 0.3742\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9468 - accuracy: 0.4143 - val_loss: 1.8387 - val_accuracy: 0.4382\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6256 - accuracy: 0.5025 - val_loss: 1.7379 - val_accuracy: 0.4671\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3717 - accuracy: 0.5787 - val_loss: 1.6909 - val_accuracy: 0.5015\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.1661 - accuracy: 0.6390 - val_loss: 1.6598 - val_accuracy: 0.5131\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9796 - accuracy: 0.6947 - val_loss: 1.6393 - val_accuracy: 0.5196\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8499 - accuracy: 0.7362 - val_loss: 1.6425 - val_accuracy: 0.5261\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7053 - accuracy: 0.7803 - val_loss: 1.6847 - val_accuracy: 0.5317\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6038 - accuracy: 0.8135 - val_loss: 1.7052 - val_accuracy: 0.5455\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4964 - accuracy: 0.8495 - val_loss: 1.7582 - val_accuracy: 0.5406\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4280 - accuracy: 0.8701 - val_loss: 1.8050 - val_accuracy: 0.5489\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3640 - accuracy: 0.8945 - val_loss: 1.8311 - val_accuracy: 0.5484\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3079 - accuracy: 0.9098 - val_loss: 1.8480 - val_accuracy: 0.5470\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2630 - accuracy: 0.9243 - val_loss: 1.8885 - val_accuracy: 0.5588\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2270 - accuracy: 0.9345 - val_loss: 1.9510 - val_accuracy: 0.5376\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1985 - accuracy: 0.9428 - val_loss: 1.9967 - val_accuracy: 0.5455\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1602 - accuracy: 0.9562 - val_loss: 2.0263 - val_accuracy: 0.5507\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1461 - accuracy: 0.9585 - val_loss: 2.0426 - val_accuracy: 0.5559\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.0801 - accuracy: 0.5514\n",
            "48.16091211994802 0.9187436347249895 0.9699125236539603 0.24141895883159972 0.29794564296529746 0.2 0.1395566076214644\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97916a7090> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792ae5f50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791878d90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e3421d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.5947 - accuracy: 0.0429 - val_loss: 3.7406 - val_accuracy: 0.1539\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.2584 - accuracy: 0.2160 - val_loss: 2.5568 - val_accuracy: 0.3163\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.1865 - accuracy: 0.3961 - val_loss: 2.0411 - val_accuracy: 0.4054\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6446 - accuracy: 0.5118 - val_loss: 1.8667 - val_accuracy: 0.4367\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3142 - accuracy: 0.6050 - val_loss: 1.8087 - val_accuracy: 0.4689\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0663 - accuracy: 0.6792 - val_loss: 1.7709 - val_accuracy: 0.4747\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8765 - accuracy: 0.7351 - val_loss: 1.7445 - val_accuracy: 0.4935\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7177 - accuracy: 0.7861 - val_loss: 1.7600 - val_accuracy: 0.5065\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6043 - accuracy: 0.8243 - val_loss: 1.8033 - val_accuracy: 0.4970\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4995 - accuracy: 0.8544 - val_loss: 1.8112 - val_accuracy: 0.5130\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4255 - accuracy: 0.8779 - val_loss: 1.8385 - val_accuracy: 0.5153\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3591 - accuracy: 0.8981 - val_loss: 1.8563 - val_accuracy: 0.5191\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3008 - accuracy: 0.9155 - val_loss: 1.8749 - val_accuracy: 0.5283\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2516 - accuracy: 0.9326 - val_loss: 1.8860 - val_accuracy: 0.5312\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2198 - accuracy: 0.9402 - val_loss: 1.9279 - val_accuracy: 0.5216\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1950 - accuracy: 0.9490 - val_loss: 1.9676 - val_accuracy: 0.5289\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1679 - accuracy: 0.9558 - val_loss: 1.9828 - val_accuracy: 0.5389\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1395 - accuracy: 0.9653 - val_loss: 2.0115 - val_accuracy: 0.5332\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1309 - accuracy: 0.9673 - val_loss: 2.0026 - val_accuracy: 0.5347\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1212 - accuracy: 0.9694 - val_loss: 2.0258 - val_accuracy: 0.5329\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1051 - accuracy: 0.9736 - val_loss: 2.0673 - val_accuracy: 0.5324\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.0367 - accuracy: 0.5316\n",
            "49.0 1.0 1.6670845692288647 0.3009968195295343 0.1893907496453142 0.2 0.1502192922191995\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791ae0f90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b7c7e10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf6b7d90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf6b7790> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791cb4590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d0741d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.5168 - accuracy: 0.0328 - val_loss: 3.3617 - val_accuracy: 0.1353\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.1315 - accuracy: 0.1496 - val_loss: 2.5129 - val_accuracy: 0.2774\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.4155 - accuracy: 0.2819 - val_loss: 2.1006 - val_accuracy: 0.3640\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9554 - accuracy: 0.3959 - val_loss: 1.8914 - val_accuracy: 0.4214\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6455 - accuracy: 0.4877 - val_loss: 1.7728 - val_accuracy: 0.4538\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.3987 - accuracy: 0.5633 - val_loss: 1.7185 - val_accuracy: 0.4757\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.2122 - accuracy: 0.6195 - val_loss: 1.6828 - val_accuracy: 0.4899\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0343 - accuracy: 0.6717 - val_loss: 1.6630 - val_accuracy: 0.5040\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8943 - accuracy: 0.7204 - val_loss: 1.6669 - val_accuracy: 0.5155\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7572 - accuracy: 0.7651 - val_loss: 1.6854 - val_accuracy: 0.5176\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6569 - accuracy: 0.7962 - val_loss: 1.7159 - val_accuracy: 0.5266\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5469 - accuracy: 0.8300 - val_loss: 1.7365 - val_accuracy: 0.5394\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4668 - accuracy: 0.8582 - val_loss: 1.7659 - val_accuracy: 0.5376\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4073 - accuracy: 0.8749 - val_loss: 1.8145 - val_accuracy: 0.5406\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3316 - accuracy: 0.9018 - val_loss: 1.8309 - val_accuracy: 0.5467\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2789 - accuracy: 0.9180 - val_loss: 1.8818 - val_accuracy: 0.5524\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2436 - accuracy: 0.9298 - val_loss: 1.8933 - val_accuracy: 0.5535\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2158 - accuracy: 0.9383 - val_loss: 1.9931 - val_accuracy: 0.5539\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1875 - accuracy: 0.9497 - val_loss: 1.9951 - val_accuracy: 0.5560\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1627 - accuracy: 0.9541 - val_loss: 2.0419 - val_accuracy: 0.5502\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1400 - accuracy: 0.9617 - val_loss: 2.0573 - val_accuracy: 0.5545\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1258 - accuracy: 0.9646 - val_loss: 2.0791 - val_accuracy: 0.5520\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1173 - accuracy: 0.9671 - val_loss: 2.1152 - val_accuracy: 0.5557\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.1742 - accuracy: 0.5336\n",
            "46.13017498751144 0.9027211880744291 2.1057924357092395 0.25473700391796267 0.20712346585748379 0.2 0.179750796388943\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99ce131250> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791813510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfca04d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f7ec950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d100750> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d437810> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 4.5035 - accuracy: 0.0372 - val_loss: 3.3011 - val_accuracy: 0.1850\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.0679 - accuracy: 0.1768 - val_loss: 2.3738 - val_accuracy: 0.3220\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.3044 - accuracy: 0.3210 - val_loss: 2.0171 - val_accuracy: 0.4029\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.8499 - accuracy: 0.4376 - val_loss: 1.8388 - val_accuracy: 0.4398\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.5231 - accuracy: 0.5274 - val_loss: 1.7403 - val_accuracy: 0.4792\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.2928 - accuracy: 0.5983 - val_loss: 1.7086 - val_accuracy: 0.5030\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0917 - accuracy: 0.6590 - val_loss: 1.6775 - val_accuracy: 0.5151\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9180 - accuracy: 0.7132 - val_loss: 1.7025 - val_accuracy: 0.5166\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7824 - accuracy: 0.7574 - val_loss: 1.7139 - val_accuracy: 0.5185\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6630 - accuracy: 0.7937 - val_loss: 1.7452 - val_accuracy: 0.5369\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5569 - accuracy: 0.8315 - val_loss: 1.7855 - val_accuracy: 0.5404\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4813 - accuracy: 0.8570 - val_loss: 1.8244 - val_accuracy: 0.5409\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4005 - accuracy: 0.8779 - val_loss: 1.9043 - val_accuracy: 0.5324\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3451 - accuracy: 0.8988 - val_loss: 1.9489 - val_accuracy: 0.5354\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.2897 - accuracy: 0.9129 - val_loss: 1.9958 - val_accuracy: 0.5369\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2482 - accuracy: 0.9280 - val_loss: 2.0242 - val_accuracy: 0.5362\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9610 - accuracy: 0.5399\n",
            "49.0 0.9614513752838593 0.5330066790571719 0.1589162453679419 0.31841866480024394 0.2 0.2039595602705921\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99bf3f68d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97914c7510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf80af90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf80b150> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 4.5869 - accuracy: 0.0344 - val_loss: 3.8662 - val_accuracy: 0.1491\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 3.3136 - accuracy: 0.2076 - val_loss: 2.6294 - val_accuracy: 0.3017\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.1493 - accuracy: 0.4088 - val_loss: 2.1212 - val_accuracy: 0.3941\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.5857 - accuracy: 0.5366 - val_loss: 1.9064 - val_accuracy: 0.4551\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.2529 - accuracy: 0.6272 - val_loss: 1.8168 - val_accuracy: 0.4614\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0009 - accuracy: 0.7023 - val_loss: 1.7923 - val_accuracy: 0.4912\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8138 - accuracy: 0.7570 - val_loss: 1.7824 - val_accuracy: 0.4934\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6688 - accuracy: 0.8051 - val_loss: 1.7828 - val_accuracy: 0.5071\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5515 - accuracy: 0.8426 - val_loss: 1.7722 - val_accuracy: 0.5125\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4624 - accuracy: 0.8696 - val_loss: 1.8038 - val_accuracy: 0.5140\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3761 - accuracy: 0.8964 - val_loss: 1.8498 - val_accuracy: 0.5148\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3186 - accuracy: 0.9141 - val_loss: 1.8654 - val_accuracy: 0.5120\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2710 - accuracy: 0.9295 - val_loss: 1.8762 - val_accuracy: 0.5133\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2305 - accuracy: 0.9389 - val_loss: 1.9073 - val_accuracy: 0.5244\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1978 - accuracy: 0.9480 - val_loss: 1.9602 - val_accuracy: 0.5189\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1721 - accuracy: 0.9570 - val_loss: 1.9637 - val_accuracy: 0.5196\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1517 - accuracy: 0.9609 - val_loss: 1.9625 - val_accuracy: 0.5216\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1336 - accuracy: 0.9666 - val_loss: 1.9884 - val_accuracy: 0.5273\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1237 - accuracy: 0.9688 - val_loss: 1.9917 - val_accuracy: 0.5309\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1103 - accuracy: 0.9729 - val_loss: 2.0062 - val_accuracy: 0.5371\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0935 - accuracy: 0.9766 - val_loss: 2.0258 - val_accuracy: 0.5477\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0859 - accuracy: 0.9795 - val_loss: 2.0315 - val_accuracy: 0.5336\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0802 - accuracy: 0.9806 - val_loss: 2.0389 - val_accuracy: 0.5362\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0765 - accuracy: 0.9816 - val_loss: 2.0435 - val_accuracy: 0.5288\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0630 - accuracy: 0.9854 - val_loss: 2.0505 - val_accuracy: 0.5416\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0771 - accuracy: 0.5372\n",
            "48.2735333305284 0.8454310806306757 1.6997273682341258 0.2538954249877903 0.2704161137340123 0.2 0.2535291945563508\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9a20126690> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792d13210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d42ddd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b475910> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799085750> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e0cc250> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.5298 - accuracy: 0.0254 - val_loss: 3.4680 - val_accuracy: 0.1393\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.2262 - accuracy: 0.1369 - val_loss: 2.5221 - val_accuracy: 0.2896\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.5212 - accuracy: 0.2647 - val_loss: 2.1364 - val_accuracy: 0.3742\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0790 - accuracy: 0.3739 - val_loss: 1.9087 - val_accuracy: 0.4370\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.7410 - accuracy: 0.4676 - val_loss: 1.7546 - val_accuracy: 0.4776\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.5001 - accuracy: 0.5366 - val_loss: 1.6934 - val_accuracy: 0.4953\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2760 - accuracy: 0.6090 - val_loss: 1.6281 - val_accuracy: 0.5254\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0959 - accuracy: 0.6597 - val_loss: 1.6317 - val_accuracy: 0.5291\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9579 - accuracy: 0.7025 - val_loss: 1.6084 - val_accuracy: 0.5495\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8127 - accuracy: 0.7472 - val_loss: 1.6189 - val_accuracy: 0.5409\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7083 - accuracy: 0.7824 - val_loss: 1.6593 - val_accuracy: 0.5477\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5975 - accuracy: 0.8168 - val_loss: 1.6577 - val_accuracy: 0.5477\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5001 - accuracy: 0.8520 - val_loss: 1.6918 - val_accuracy: 0.5645\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4387 - accuracy: 0.8691 - val_loss: 1.7377 - val_accuracy: 0.5652\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3787 - accuracy: 0.8904 - val_loss: 1.7756 - val_accuracy: 0.5583\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3263 - accuracy: 0.9029 - val_loss: 1.8218 - val_accuracy: 0.5602\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2676 - accuracy: 0.9201 - val_loss: 1.8656 - val_accuracy: 0.5622\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2370 - accuracy: 0.9336 - val_loss: 1.9125 - val_accuracy: 0.5677\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2145 - accuracy: 0.9379 - val_loss: 1.9311 - val_accuracy: 0.5605\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1888 - accuracy: 0.9474 - val_loss: 1.9897 - val_accuracy: 0.5517\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1550 - accuracy: 0.9572 - val_loss: 2.0182 - val_accuracy: 0.5627\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1432 - accuracy: 0.9599 - val_loss: 2.0453 - val_accuracy: 0.5559\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1140 - accuracy: 0.5394\n",
            "49.0 0.9608098748862257 1.9327401014071914 0.2251068883831662 0.30252553023890894 0.2 0.16570072269504507\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798faa350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97918a6a10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791891d50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792abd150> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97918c3f90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792aa7f90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.4761 - accuracy: 0.0368 - val_loss: 3.3469 - val_accuracy: 0.1543\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.1695 - accuracy: 0.1549 - val_loss: 2.4853 - val_accuracy: 0.2866\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.4322 - accuracy: 0.2939 - val_loss: 2.1063 - val_accuracy: 0.3951\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9998 - accuracy: 0.4027 - val_loss: 1.8925 - val_accuracy: 0.4284\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6788 - accuracy: 0.4892 - val_loss: 1.7619 - val_accuracy: 0.4732\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4182 - accuracy: 0.5633 - val_loss: 1.7076 - val_accuracy: 0.4897\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2307 - accuracy: 0.6261 - val_loss: 1.6732 - val_accuracy: 0.5158\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0417 - accuracy: 0.6800 - val_loss: 1.6450 - val_accuracy: 0.5349\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9080 - accuracy: 0.7204 - val_loss: 1.6668 - val_accuracy: 0.5362\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7588 - accuracy: 0.7681 - val_loss: 1.7073 - val_accuracy: 0.5341\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6636 - accuracy: 0.8000 - val_loss: 1.7244 - val_accuracy: 0.5386\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5487 - accuracy: 0.8378 - val_loss: 1.7280 - val_accuracy: 0.5505\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4794 - accuracy: 0.8555 - val_loss: 1.7733 - val_accuracy: 0.5502\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3992 - accuracy: 0.8826 - val_loss: 1.8321 - val_accuracy: 0.5467\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3464 - accuracy: 0.9004 - val_loss: 1.8700 - val_accuracy: 0.5520\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3057 - accuracy: 0.9107 - val_loss: 1.9208 - val_accuracy: 0.5480\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2627 - accuracy: 0.9236 - val_loss: 1.9622 - val_accuracy: 0.5597\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2259 - accuracy: 0.9333 - val_loss: 2.0116 - val_accuracy: 0.5535\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2014 - accuracy: 0.9422 - val_loss: 2.0458 - val_accuracy: 0.5437\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1724 - accuracy: 0.9506 - val_loss: 2.0643 - val_accuracy: 0.5485\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1531 - accuracy: 0.9564 - val_loss: 2.1254 - val_accuracy: 0.5452\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2306 - accuracy: 0.5419\n",
            "49.0 0.7449200564761299 2.507509449387954 0.39538787399839254 0.2231595802577997 0.2 0.30998279983333865\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792abc110> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b265250> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799306cd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d8be810> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b265a50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b2655d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798fbad10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799306fd0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.5472 - accuracy: 0.0328 - val_loss: 3.4618 - val_accuracy: 0.1039\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.4118 - accuracy: 0.0729 - val_loss: 2.8820 - val_accuracy: 0.1838\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.0351 - accuracy: 0.1240 - val_loss: 2.5589 - val_accuracy: 0.2638\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.7504 - accuracy: 0.1823 - val_loss: 2.3176 - val_accuracy: 0.3152\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.4959 - accuracy: 0.2428 - val_loss: 2.1231 - val_accuracy: 0.3755\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.2422 - accuracy: 0.3079 - val_loss: 1.9725 - val_accuracy: 0.3986\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0184 - accuracy: 0.3636 - val_loss: 1.8514 - val_accuracy: 0.4272\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.8357 - accuracy: 0.4183 - val_loss: 1.7529 - val_accuracy: 0.4623\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6683 - accuracy: 0.4633 - val_loss: 1.7142 - val_accuracy: 0.4764\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.5153 - accuracy: 0.5080 - val_loss: 1.6578 - val_accuracy: 0.4924\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.3802 - accuracy: 0.5541 - val_loss: 1.6726 - val_accuracy: 0.4943\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2354 - accuracy: 0.5988 - val_loss: 1.6720 - val_accuracy: 0.5224\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1265 - accuracy: 0.6347 - val_loss: 1.6895 - val_accuracy: 0.5145\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0130 - accuracy: 0.6771 - val_loss: 1.7040 - val_accuracy: 0.5319\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9029 - accuracy: 0.7120 - val_loss: 1.7327 - val_accuracy: 0.5303\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7944 - accuracy: 0.7469 - val_loss: 1.7698 - val_accuracy: 0.5374\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6914 - accuracy: 0.7804 - val_loss: 1.8018 - val_accuracy: 0.5535\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6002 - accuracy: 0.8134 - val_loss: 1.9248 - val_accuracy: 0.5371\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5301 - accuracy: 0.8346 - val_loss: 2.0065 - val_accuracy: 0.5352\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4655 - accuracy: 0.8604 - val_loss: 2.0437 - val_accuracy: 0.5439\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4152 - accuracy: 0.8755 - val_loss: 2.0974 - val_accuracy: 0.5337\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1292 - accuracy: 0.5203\n",
            "49.0 0.81677087318637 2.2243879409452623 0.27386684733944494 0.2336635188623132 0.2 0.2164783500175216\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e3fb0d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9a201522d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799129f90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97990ad150> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791b77c50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97990ad8d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.3491 - accuracy: 0.0490 - val_loss: 3.0474 - val_accuracy: 0.1842\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9333 - accuracy: 0.1894 - val_loss: 2.4156 - val_accuracy: 0.2884\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.3332 - accuracy: 0.3084 - val_loss: 2.0538 - val_accuracy: 0.3843\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9211 - accuracy: 0.4132 - val_loss: 1.8572 - val_accuracy: 0.4294\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.6216 - accuracy: 0.4966 - val_loss: 1.7526 - val_accuracy: 0.4812\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.3931 - accuracy: 0.5662 - val_loss: 1.6896 - val_accuracy: 0.4919\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2140 - accuracy: 0.6231 - val_loss: 1.6597 - val_accuracy: 0.5186\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0422 - accuracy: 0.6732 - val_loss: 1.6377 - val_accuracy: 0.5342\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8886 - accuracy: 0.7225 - val_loss: 1.6645 - val_accuracy: 0.5269\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7675 - accuracy: 0.7614 - val_loss: 1.6822 - val_accuracy: 0.5505\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6516 - accuracy: 0.7977 - val_loss: 1.7290 - val_accuracy: 0.5442\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5521 - accuracy: 0.8302 - val_loss: 1.7818 - val_accuracy: 0.5447\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4587 - accuracy: 0.8643 - val_loss: 1.8184 - val_accuracy: 0.5497\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3923 - accuracy: 0.8822 - val_loss: 1.8759 - val_accuracy: 0.5424\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9618 - accuracy: 0.5237\n",
            "44.517439279848766 0.7991906887778141 1.2040126911263886 0.28458364391196167 0.25476308213604126 0.185620375176553 0.2650014068325993\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e5dd550> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e5f9090> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792cbba90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791925550> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.7086 - accuracy: 0.0199 - val_loss: 4.2245 - val_accuracy: 0.1034\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.8092 - accuracy: 0.1458 - val_loss: 2.9848 - val_accuracy: 0.2666\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.6313 - accuracy: 0.3159 - val_loss: 2.2474 - val_accuracy: 0.3905\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9155 - accuracy: 0.4495 - val_loss: 1.9498 - val_accuracy: 0.4230\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.5050 - accuracy: 0.5477 - val_loss: 1.8140 - val_accuracy: 0.4536\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.2286 - accuracy: 0.6277 - val_loss: 1.7865 - val_accuracy: 0.4717\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0363 - accuracy: 0.6867 - val_loss: 1.7434 - val_accuracy: 0.4859\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8492 - accuracy: 0.7490 - val_loss: 1.7604 - val_accuracy: 0.4998\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7066 - accuracy: 0.7891 - val_loss: 1.7735 - val_accuracy: 0.5105\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6036 - accuracy: 0.8226 - val_loss: 1.7806 - val_accuracy: 0.5148\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4852 - accuracy: 0.8616 - val_loss: 1.7968 - val_accuracy: 0.5193\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4228 - accuracy: 0.8768 - val_loss: 1.8392 - val_accuracy: 0.5213\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3527 - accuracy: 0.8997 - val_loss: 1.8417 - val_accuracy: 0.5214\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3102 - accuracy: 0.9136 - val_loss: 1.9060 - val_accuracy: 0.5288\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2648 - accuracy: 0.9282 - val_loss: 1.9299 - val_accuracy: 0.5221\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2284 - accuracy: 0.9376 - val_loss: 1.9384 - val_accuracy: 0.5298\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1951 - accuracy: 0.9495 - val_loss: 1.9813 - val_accuracy: 0.5304\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1753 - accuracy: 0.9530 - val_loss: 2.0097 - val_accuracy: 0.5291\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1503 - accuracy: 0.9604 - val_loss: 2.0331 - val_accuracy: 0.5306\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1325 - accuracy: 0.9659 - val_loss: 2.0521 - val_accuracy: 0.5203\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1197 - accuracy: 0.9699 - val_loss: 2.0665 - val_accuracy: 0.5266\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1094 - accuracy: 0.9726 - val_loss: 2.1117 - val_accuracy: 0.5301\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1081 - accuracy: 0.9712 - val_loss: 2.1204 - val_accuracy: 0.5324\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0976 - accuracy: 0.9743 - val_loss: 2.1556 - val_accuracy: 0.5298\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0858 - accuracy: 0.9790 - val_loss: 2.1807 - val_accuracy: 0.5246\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0745 - accuracy: 0.9817 - val_loss: 2.1863 - val_accuracy: 0.5279\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 29ms/step - loss: 0.0689 - accuracy: 0.9827 - val_loss: 2.2223 - val_accuracy: 0.5165\n",
            "128/128 [==============================] - 3s 16ms/step - loss: 2.2882 - accuracy: 0.5272\n",
            "46.16743079766295 1.0 2.2735750078591073 0.2623141936472645 0.32500314632354654 0.2 0.24764445044578173\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979181a750> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e56e110> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ce7bad0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b55f550> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97937dacd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9793ac8c50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.5995 - accuracy: 0.0277 - val_loss: 3.4782 - val_accuracy: 0.1591\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 3.2451 - accuracy: 0.1538 - val_loss: 2.4827 - val_accuracy: 0.2884\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.5025 - accuracy: 0.2744 - val_loss: 2.0927 - val_accuracy: 0.3910\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.0532 - accuracy: 0.3840 - val_loss: 1.8598 - val_accuracy: 0.4373\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.7093 - accuracy: 0.4697 - val_loss: 1.7263 - val_accuracy: 0.4751\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.4615 - accuracy: 0.5473 - val_loss: 1.6712 - val_accuracy: 0.4920\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.2421 - accuracy: 0.6151 - val_loss: 1.6403 - val_accuracy: 0.5093\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.0633 - accuracy: 0.6703 - val_loss: 1.6343 - val_accuracy: 0.5175\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9146 - accuracy: 0.7134 - val_loss: 1.6359 - val_accuracy: 0.5329\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7570 - accuracy: 0.7658 - val_loss: 1.6505 - val_accuracy: 0.5304\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6565 - accuracy: 0.7995 - val_loss: 1.6687 - val_accuracy: 0.5479\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5540 - accuracy: 0.8299 - val_loss: 1.7516 - val_accuracy: 0.5417\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4729 - accuracy: 0.8602 - val_loss: 1.8074 - val_accuracy: 0.5427\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4000 - accuracy: 0.8804 - val_loss: 1.8400 - val_accuracy: 0.5454\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.3447 - accuracy: 0.8968 - val_loss: 1.9430 - val_accuracy: 0.5399\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.8852 - accuracy: 0.5408\n",
            "46.89119597688792 0.9190641434336614 1.114578289567562 0.2655384150281428 0.30094895323369225 0.2 0.16664546885022663\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d8aead0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f72ec10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4da5d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979974f890> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 31ms/step - loss: 4.5020 - accuracy: 0.0388 - val_loss: 3.3530 - val_accuracy: 0.2126\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.9346 - accuracy: 0.2661 - val_loss: 2.3509 - val_accuracy: 0.3516\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.9873 - accuracy: 0.4397 - val_loss: 2.0127 - val_accuracy: 0.4121\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.4896 - accuracy: 0.5593 - val_loss: 1.8558 - val_accuracy: 0.4501\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.1815 - accuracy: 0.6457 - val_loss: 1.7785 - val_accuracy: 0.4757\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9508 - accuracy: 0.7156 - val_loss: 1.7424 - val_accuracy: 0.4992\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.7664 - accuracy: 0.7700 - val_loss: 1.7824 - val_accuracy: 0.4865\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6231 - accuracy: 0.8165 - val_loss: 1.7623 - val_accuracy: 0.5196\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.5076 - accuracy: 0.8532 - val_loss: 1.8112 - val_accuracy: 0.5199\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4192 - accuracy: 0.8822 - val_loss: 1.8347 - val_accuracy: 0.5316\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 15s 29ms/step - loss: 0.3496 - accuracy: 0.9015 - val_loss: 1.8374 - val_accuracy: 0.5332\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2907 - accuracy: 0.9202 - val_loss: 1.8626 - val_accuracy: 0.5308\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2555 - accuracy: 0.9329 - val_loss: 1.8939 - val_accuracy: 0.5248\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2152 - accuracy: 0.9428 - val_loss: 1.8900 - val_accuracy: 0.5386\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1775 - accuracy: 0.9531 - val_loss: 1.9350 - val_accuracy: 0.5271\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1544 - accuracy: 0.9620 - val_loss: 1.9568 - val_accuracy: 0.5464\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1356 - accuracy: 0.9678 - val_loss: 1.9493 - val_accuracy: 0.5374\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1178 - accuracy: 0.9707 - val_loss: 2.0067 - val_accuracy: 0.5406\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1087 - accuracy: 0.9728 - val_loss: 2.0102 - val_accuracy: 0.5469\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0996 - accuracy: 0.9759 - val_loss: 2.0346 - val_accuracy: 0.5459\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0920 - accuracy: 0.9776 - val_loss: 2.0654 - val_accuracy: 0.5454\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0759 - accuracy: 0.9822 - val_loss: 2.0618 - val_accuracy: 0.5470\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0713 - accuracy: 0.9832 - val_loss: 2.0732 - val_accuracy: 0.5568\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0687 - accuracy: 0.9848 - val_loss: 2.1084 - val_accuracy: 0.5475\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0652 - accuracy: 0.9830 - val_loss: 2.1136 - val_accuracy: 0.5512\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0553 - accuracy: 0.9879 - val_loss: 2.1396 - val_accuracy: 0.5465\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0553 - accuracy: 0.9866 - val_loss: 2.1235 - val_accuracy: 0.5534\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1203 - accuracy: 0.5376\n",
            "48.619370210891084 1.0 1.5402610266598298 0.22835061084691982 0.2873304497204112 0.2 0.23037521607114175\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792cced90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792ccea90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97990f9a90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791adb290> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d888310> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792cce190> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.4240 - accuracy: 0.0458 - val_loss: 3.2078 - val_accuracy: 0.1828\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.0492 - accuracy: 0.1722 - val_loss: 2.4656 - val_accuracy: 0.3042\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.4090 - accuracy: 0.2950 - val_loss: 2.0899 - val_accuracy: 0.3790\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9945 - accuracy: 0.4018 - val_loss: 1.8738 - val_accuracy: 0.4272\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6742 - accuracy: 0.4888 - val_loss: 1.7714 - val_accuracy: 0.4611\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.4270 - accuracy: 0.5559 - val_loss: 1.7080 - val_accuracy: 0.4943\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2327 - accuracy: 0.6132 - val_loss: 1.6821 - val_accuracy: 0.4983\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.0603 - accuracy: 0.6730 - val_loss: 1.6659 - val_accuracy: 0.5105\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9074 - accuracy: 0.7184 - val_loss: 1.6766 - val_accuracy: 0.5224\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7645 - accuracy: 0.7634 - val_loss: 1.7097 - val_accuracy: 0.5296\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6624 - accuracy: 0.7950 - val_loss: 1.6928 - val_accuracy: 0.5359\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5614 - accuracy: 0.8292 - val_loss: 1.7598 - val_accuracy: 0.5312\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4741 - accuracy: 0.8569 - val_loss: 1.7876 - val_accuracy: 0.5422\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3957 - accuracy: 0.8811 - val_loss: 1.8259 - val_accuracy: 0.5432\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3526 - accuracy: 0.8953 - val_loss: 1.8658 - val_accuracy: 0.5480\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3006 - accuracy: 0.9128 - val_loss: 1.8829 - val_accuracy: 0.5549\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2547 - accuracy: 0.9252 - val_loss: 1.9375 - val_accuracy: 0.5499\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2175 - accuracy: 0.9394 - val_loss: 1.9324 - val_accuracy: 0.5570\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1939 - accuracy: 0.9431 - val_loss: 1.9834 - val_accuracy: 0.5539\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1681 - accuracy: 0.9522 - val_loss: 2.0140 - val_accuracy: 0.5600\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1445 - accuracy: 0.9606 - val_loss: 2.0298 - val_accuracy: 0.5670\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1450 - accuracy: 0.9578 - val_loss: 2.0522 - val_accuracy: 0.5633\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1221 - accuracy: 0.9644 - val_loss: 2.1055 - val_accuracy: 0.5570\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1052 - accuracy: 0.9719 - val_loss: 2.1073 - val_accuracy: 0.5648\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0963 - accuracy: 0.9734 - val_loss: 2.1273 - val_accuracy: 0.5637\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.2701 - accuracy: 0.5327\n",
            "46.57813391804109 0.8386039205872439 2.05751196694439 0.26121265729618326 0.2884795699764501 0.2 0.20317906921652484\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799085a10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9799b95950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799263490> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979924b510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d1119d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97991444d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.2885 - accuracy: 0.0486 - val_loss: 2.9868 - val_accuracy: 0.1948\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.9028 - accuracy: 0.1962 - val_loss: 2.3380 - val_accuracy: 0.3205\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 2.2656 - accuracy: 0.3365 - val_loss: 1.9894 - val_accuracy: 0.4026\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.8585 - accuracy: 0.4374 - val_loss: 1.8038 - val_accuracy: 0.4417\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.5672 - accuracy: 0.5158 - val_loss: 1.6946 - val_accuracy: 0.4709\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.3102 - accuracy: 0.5936 - val_loss: 1.6420 - val_accuracy: 0.4983\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.1360 - accuracy: 0.6478 - val_loss: 1.6299 - val_accuracy: 0.5188\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9793 - accuracy: 0.6967 - val_loss: 1.6634 - val_accuracy: 0.5156\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8287 - accuracy: 0.7432 - val_loss: 1.6716 - val_accuracy: 0.5214\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6910 - accuracy: 0.7869 - val_loss: 1.7063 - val_accuracy: 0.5283\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6002 - accuracy: 0.8172 - val_loss: 1.7164 - val_accuracy: 0.5329\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5053 - accuracy: 0.8473 - val_loss: 1.7457 - val_accuracy: 0.5374\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4153 - accuracy: 0.8771 - val_loss: 1.7974 - val_accuracy: 0.5407\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3554 - accuracy: 0.8954 - val_loss: 1.8508 - val_accuracy: 0.5431\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3211 - accuracy: 0.9048 - val_loss: 1.8871 - val_accuracy: 0.5469\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2625 - accuracy: 0.9219 - val_loss: 1.9277 - val_accuracy: 0.5539\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2279 - accuracy: 0.9328 - val_loss: 1.9492 - val_accuracy: 0.5510\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2028 - accuracy: 0.9416 - val_loss: 1.9850 - val_accuracy: 0.5577\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1750 - accuracy: 0.9505 - val_loss: 2.0406 - val_accuracy: 0.5618\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1512 - accuracy: 0.9566 - val_loss: 2.0762 - val_accuracy: 0.5529\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1321 - accuracy: 0.9634 - val_loss: 2.0926 - val_accuracy: 0.5643\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1197 - accuracy: 0.9664 - val_loss: 2.1375 - val_accuracy: 0.5549\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1087 - accuracy: 0.9704 - val_loss: 2.1855 - val_accuracy: 0.5583\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0914 - accuracy: 0.9751 - val_loss: 2.1894 - val_accuracy: 0.5602\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0890 - accuracy: 0.9767 - val_loss: 2.2387 - val_accuracy: 0.5534\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3504 - accuracy: 0.5435\n",
            "49.0 0.9004683498691084 1.5445981653083742 0.27016005841342117 0.2898227361365197 0.2 0.23379394360781558\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799141710> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9793abcdd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e602dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799f22690> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dcd9f10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979926b1d0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.4956 - accuracy: 0.0302 - val_loss: 3.3264 - val_accuracy: 0.1405\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.1120 - accuracy: 0.1573 - val_loss: 2.4705 - val_accuracy: 0.2906\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4471 - accuracy: 0.2819 - val_loss: 2.1216 - val_accuracy: 0.3767\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0185 - accuracy: 0.3936 - val_loss: 1.8773 - val_accuracy: 0.4357\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.7050 - accuracy: 0.4765 - val_loss: 1.7503 - val_accuracy: 0.4641\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4563 - accuracy: 0.5523 - val_loss: 1.6783 - val_accuracy: 0.4895\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2614 - accuracy: 0.6143 - val_loss: 1.6589 - val_accuracy: 0.5038\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0869 - accuracy: 0.6601 - val_loss: 1.6565 - val_accuracy: 0.5303\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.9372 - accuracy: 0.7044 - val_loss: 1.6577 - val_accuracy: 0.5346\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.8048 - accuracy: 0.7520 - val_loss: 1.6896 - val_accuracy: 0.5256\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6956 - accuracy: 0.7849 - val_loss: 1.7032 - val_accuracy: 0.5367\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5774 - accuracy: 0.8200 - val_loss: 1.7305 - val_accuracy: 0.5389\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4992 - accuracy: 0.8473 - val_loss: 1.7578 - val_accuracy: 0.5382\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4284 - accuracy: 0.8715 - val_loss: 1.8356 - val_accuracy: 0.5274\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3723 - accuracy: 0.8892 - val_loss: 1.8951 - val_accuracy: 0.5298\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3194 - accuracy: 0.9055 - val_loss: 1.9141 - val_accuracy: 0.5442\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2748 - accuracy: 0.9197 - val_loss: 1.9458 - val_accuracy: 0.5490\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2356 - accuracy: 0.9313 - val_loss: 1.9964 - val_accuracy: 0.5462\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.2027 - accuracy: 0.9430 - val_loss: 2.0122 - val_accuracy: 0.5447\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1841 - accuracy: 0.9476 - val_loss: 2.0710 - val_accuracy: 0.5462\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.1576 - accuracy: 0.9557 - val_loss: 2.1148 - val_accuracy: 0.5485\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1009 - accuracy: 0.5323\n",
            "46.935004853581695 0.8768135991737507 1.7071705860239004 0.2943791134194863 0.258883635918555 0.2 0.27964430014265823\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97937c85d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978cf1fb10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791676290> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dccc6d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97916761d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d0c5f90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 33ms/step - loss: 4.6195 - accuracy: 0.0342 - val_loss: 3.6428 - val_accuracy: 0.1592\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.3074 - accuracy: 0.1565 - val_loss: 2.5251 - val_accuracy: 0.2817\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4851 - accuracy: 0.2837 - val_loss: 2.0826 - val_accuracy: 0.3920\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.9976 - accuracy: 0.4015 - val_loss: 1.8827 - val_accuracy: 0.4445\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6576 - accuracy: 0.4936 - val_loss: 1.7534 - val_accuracy: 0.4804\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4097 - accuracy: 0.5634 - val_loss: 1.6864 - val_accuracy: 0.4953\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2203 - accuracy: 0.6242 - val_loss: 1.6537 - val_accuracy: 0.5185\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.0137 - accuracy: 0.6860 - val_loss: 1.6490 - val_accuracy: 0.5259\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8728 - accuracy: 0.7305 - val_loss: 1.6442 - val_accuracy: 0.5367\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7289 - accuracy: 0.7786 - val_loss: 1.6957 - val_accuracy: 0.5357\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6140 - accuracy: 0.8125 - val_loss: 1.7642 - val_accuracy: 0.5401\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5322 - accuracy: 0.8376 - val_loss: 1.7709 - val_accuracy: 0.5437\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4410 - accuracy: 0.8690 - val_loss: 1.8480 - val_accuracy: 0.5386\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3754 - accuracy: 0.8882 - val_loss: 1.8599 - val_accuracy: 0.5444\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3236 - accuracy: 0.9053 - val_loss: 1.8834 - val_accuracy: 0.5436\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2817 - accuracy: 0.9170 - val_loss: 1.9066 - val_accuracy: 0.5530\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2359 - accuracy: 0.9312 - val_loss: 1.9621 - val_accuracy: 0.5504\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2038 - accuracy: 0.9427 - val_loss: 2.0275 - val_accuracy: 0.5455\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1688 - accuracy: 0.9524 - val_loss: 2.0517 - val_accuracy: 0.5582\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1572 - accuracy: 0.9567 - val_loss: 2.0564 - val_accuracy: 0.5623\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1367 - accuracy: 0.9628 - val_loss: 2.0912 - val_accuracy: 0.5524\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1210 - accuracy: 0.9670 - val_loss: 2.1236 - val_accuracy: 0.5598\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1119 - accuracy: 0.9686 - val_loss: 2.1378 - val_accuracy: 0.5648\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0997 - accuracy: 0.9748 - val_loss: 2.1541 - val_accuracy: 0.5588\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0892 - accuracy: 0.9759 - val_loss: 2.1559 - val_accuracy: 0.5560\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0781 - accuracy: 0.9781 - val_loss: 2.2165 - val_accuracy: 0.5537\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.0690 - accuracy: 0.9803 - val_loss: 2.2070 - val_accuracy: 0.5590\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.3636 - accuracy: 0.5370\n",
            "49.0 0.9515952013891733 1.7741536736051529 0.23917801960866222 0.30217555878189106 0.2 0.16936171938018849\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f645d10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798eb05d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798ede550> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791047450> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f6b5050> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798ee6e50> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.6055 - accuracy: 0.0232 - val_loss: 3.7186 - val_accuracy: 0.1418\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.3644 - accuracy: 0.1438 - val_loss: 2.5553 - val_accuracy: 0.2698\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.5451 - accuracy: 0.2668 - val_loss: 2.1293 - val_accuracy: 0.3710\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.0820 - accuracy: 0.3761 - val_loss: 1.9130 - val_accuracy: 0.4177\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.7317 - accuracy: 0.4708 - val_loss: 1.7614 - val_accuracy: 0.4653\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4993 - accuracy: 0.5354 - val_loss: 1.6909 - val_accuracy: 0.4852\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2857 - accuracy: 0.5995 - val_loss: 1.6677 - val_accuracy: 0.5007\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1172 - accuracy: 0.6500 - val_loss: 1.6360 - val_accuracy: 0.5193\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9671 - accuracy: 0.7025 - val_loss: 1.6764 - val_accuracy: 0.5165\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8521 - accuracy: 0.7307 - val_loss: 1.7053 - val_accuracy: 0.5189\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.7109 - accuracy: 0.7802 - val_loss: 1.7232 - val_accuracy: 0.5359\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5918 - accuracy: 0.8199 - val_loss: 1.7279 - val_accuracy: 0.5467\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5167 - accuracy: 0.8416 - val_loss: 1.8198 - val_accuracy: 0.5294\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4343 - accuracy: 0.8724 - val_loss: 1.8339 - val_accuracy: 0.5326\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3742 - accuracy: 0.8900 - val_loss: 1.8788 - val_accuracy: 0.5426\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3236 - accuracy: 0.9042 - val_loss: 1.8914 - val_accuracy: 0.5465\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.8604 - accuracy: 0.5446\n",
            "48.01847214865312 0.792023699568904 2.131221322759927 0.30568337586512273 0.25268981810212315 0.2 0.2620974316371988\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979923d490> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d0a4850> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d9085d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798ec9b50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4fe210> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4fead0> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 33ms/step - loss: 4.6755 - accuracy: 0.0186 - val_loss: 3.9274 - val_accuracy: 0.1110\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.5298 - accuracy: 0.1180 - val_loss: 2.6368 - val_accuracy: 0.2635\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.6208 - accuracy: 0.2467 - val_loss: 2.1587 - val_accuracy: 0.3657\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.1261 - accuracy: 0.3613 - val_loss: 1.8853 - val_accuracy: 0.4342\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.7710 - accuracy: 0.4582 - val_loss: 1.7397 - val_accuracy: 0.4643\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.5083 - accuracy: 0.5270 - val_loss: 1.6637 - val_accuracy: 0.4975\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2905 - accuracy: 0.5975 - val_loss: 1.6042 - val_accuracy: 0.5150\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.1146 - accuracy: 0.6524 - val_loss: 1.6087 - val_accuracy: 0.5269\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.9659 - accuracy: 0.6950 - val_loss: 1.6026 - val_accuracy: 0.5391\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.8250 - accuracy: 0.7346 - val_loss: 1.6265 - val_accuracy: 0.5406\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7157 - accuracy: 0.7765 - val_loss: 1.6671 - val_accuracy: 0.5304\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6129 - accuracy: 0.8109 - val_loss: 1.6954 - val_accuracy: 0.5452\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.5159 - accuracy: 0.8396 - val_loss: 1.7345 - val_accuracy: 0.5422\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.4602 - accuracy: 0.8575 - val_loss: 1.7778 - val_accuracy: 0.5432\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.3890 - accuracy: 0.8810 - val_loss: 1.7707 - val_accuracy: 0.5567\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3329 - accuracy: 0.9019 - val_loss: 1.8079 - val_accuracy: 0.5512\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2842 - accuracy: 0.9162 - val_loss: 1.8452 - val_accuracy: 0.5557\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2452 - accuracy: 0.9300 - val_loss: 1.8749 - val_accuracy: 0.5554\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2199 - accuracy: 0.9355 - val_loss: 1.8942 - val_accuracy: 0.5675\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.2001 - accuracy: 0.9396 - val_loss: 1.9318 - val_accuracy: 0.5567\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1762 - accuracy: 0.9497 - val_loss: 1.9319 - val_accuracy: 0.5643\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1535 - accuracy: 0.9579 - val_loss: 1.9675 - val_accuracy: 0.5677\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1370 - accuracy: 0.9621 - val_loss: 1.9801 - val_accuracy: 0.5691\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1267 - accuracy: 0.9636 - val_loss: 2.0114 - val_accuracy: 0.5687\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.1166 - accuracy: 0.9666 - val_loss: 2.0145 - val_accuracy: 0.5698\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0997 - accuracy: 0.9723 - val_loss: 2.0829 - val_accuracy: 0.5720\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0936 - accuracy: 0.9745 - val_loss: 2.0669 - val_accuracy: 0.5716\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.0883 - accuracy: 0.9758 - val_loss: 2.0803 - val_accuracy: 0.5688\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0761 - accuracy: 0.9785 - val_loss: 2.1014 - val_accuracy: 0.5790\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.0760 - accuracy: 0.9792 - val_loss: 2.1253 - val_accuracy: 0.5785\n",
            "128/128 [==============================] - 3s 18ms/step - loss: 2.3291 - accuracy: 0.5397\n",
            "49.0 0.8188789060006422 2.13726795644256 0.2759404932694628 0.2564267960475479 0.2 0.2393679628954639\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978cf81a10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792c9b8d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bcfcf90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e2f1850> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f293610> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bcd5990> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 33ms/step - loss: 4.5034 - accuracy: 0.0319 - val_loss: 3.2882 - val_accuracy: 0.1651\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 3.1120 - accuracy: 0.1643 - val_loss: 2.4489 - val_accuracy: 0.2969\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 2.4344 - accuracy: 0.2883 - val_loss: 2.1047 - val_accuracy: 0.3800\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.9887 - accuracy: 0.3999 - val_loss: 1.8887 - val_accuracy: 0.4437\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.6737 - accuracy: 0.4877 - val_loss: 1.7845 - val_accuracy: 0.4751\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.4533 - accuracy: 0.5453 - val_loss: 1.6862 - val_accuracy: 0.4973\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 1.2419 - accuracy: 0.6120 - val_loss: 1.6895 - val_accuracy: 0.5140\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.0666 - accuracy: 0.6670 - val_loss: 1.6817 - val_accuracy: 0.5189\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.9214 - accuracy: 0.7130 - val_loss: 1.6629 - val_accuracy: 0.5319\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.7815 - accuracy: 0.7610 - val_loss: 1.6901 - val_accuracy: 0.5361\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.6670 - accuracy: 0.7923 - val_loss: 1.7143 - val_accuracy: 0.5327\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5777 - accuracy: 0.8228 - val_loss: 1.7572 - val_accuracy: 0.5394\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4842 - accuracy: 0.8511 - val_loss: 1.8087 - val_accuracy: 0.5429\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.4151 - accuracy: 0.8767 - val_loss: 1.8387 - val_accuracy: 0.5497\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3501 - accuracy: 0.8979 - val_loss: 1.8860 - val_accuracy: 0.5504\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.3011 - accuracy: 0.9112 - val_loss: 1.9000 - val_accuracy: 0.5572\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2530 - accuracy: 0.9256 - val_loss: 1.9161 - val_accuracy: 0.5520\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2217 - accuracy: 0.9359 - val_loss: 2.0210 - val_accuracy: 0.5560\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1884 - accuracy: 0.9457 - val_loss: 2.0607 - val_accuracy: 0.5535\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.1722 - accuracy: 0.9490 - val_loss: 2.0765 - val_accuracy: 0.5492\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.1858 - accuracy: 0.5227\n",
            "45.40149220558471 0.8009125282567017 0.4581331285244177 0.26233289834707907 0.25074444341103264 0.183969464598184 0.34022478387443733\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979179c890> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bf81a550> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 22s 32ms/step - loss: 4.5177 - accuracy: 0.0590 - val_loss: 3.4892 - val_accuracy: 0.2276\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.7967 - accuracy: 0.3577 - val_loss: 2.4750 - val_accuracy: 0.3720\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.7545 - accuracy: 0.5454 - val_loss: 2.1134 - val_accuracy: 0.4137\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2128 - accuracy: 0.6701 - val_loss: 1.9746 - val_accuracy: 0.4430\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8968 - accuracy: 0.7516 - val_loss: 1.9150 - val_accuracy: 0.4697\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.6707 - accuracy: 0.8202 - val_loss: 1.9135 - val_accuracy: 0.4867\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 31ms/step - loss: 0.5393 - accuracy: 0.8591 - val_loss: 1.9323 - val_accuracy: 0.4870\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.4167 - accuracy: 0.8958 - val_loss: 1.9340 - val_accuracy: 0.4917\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3344 - accuracy: 0.9212 - val_loss: 1.9289 - val_accuracy: 0.4948\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2699 - accuracy: 0.9368 - val_loss: 1.9554 - val_accuracy: 0.5053\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2390 - accuracy: 0.9438 - val_loss: 1.9543 - val_accuracy: 0.5123\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1899 - accuracy: 0.9569 - val_loss: 1.9865 - val_accuracy: 0.5071\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1566 - accuracy: 0.9669 - val_loss: 2.0044 - val_accuracy: 0.5111\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1431 - accuracy: 0.9694 - val_loss: 2.0312 - val_accuracy: 0.5075\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.1258 - accuracy: 0.9736 - val_loss: 2.0355 - val_accuracy: 0.5095\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 2.0259 - accuracy: 0.5156\n",
            "46.374362855694116 1.0 2.3275069777041457 0.2920762731682918 0.32014803584875484 0.2 0.2637624387189237\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791c48d90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d9b8dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfca0790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e2d9210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b6f2850> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b6f2890> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 21s 32ms/step - loss: 4.3760 - accuracy: 0.0464 - val_loss: 3.1211 - val_accuracy: 0.1932\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 3.0573 - accuracy: 0.1661 - val_loss: 2.4151 - val_accuracy: 0.2945\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 2.4108 - accuracy: 0.2950 - val_loss: 2.0442 - val_accuracy: 0.3886\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.9980 - accuracy: 0.3935 - val_loss: 1.8536 - val_accuracy: 0.4403\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.6880 - accuracy: 0.4834 - val_loss: 1.7240 - val_accuracy: 0.4764\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 1.4237 - accuracy: 0.5598 - val_loss: 1.6529 - val_accuracy: 0.4904\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.2421 - accuracy: 0.6138 - val_loss: 1.6524 - val_accuracy: 0.4925\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 1.0701 - accuracy: 0.6684 - val_loss: 1.6141 - val_accuracy: 0.5236\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.9243 - accuracy: 0.7115 - val_loss: 1.6264 - val_accuracy: 0.5296\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.8002 - accuracy: 0.7531 - val_loss: 1.6266 - val_accuracy: 0.5357\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.6712 - accuracy: 0.7911 - val_loss: 1.6441 - val_accuracy: 0.5239\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5780 - accuracy: 0.8216 - val_loss: 1.6977 - val_accuracy: 0.5432\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.5067 - accuracy: 0.8450 - val_loss: 1.7237 - val_accuracy: 0.5462\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.4172 - accuracy: 0.8754 - val_loss: 1.7670 - val_accuracy: 0.5490\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3728 - accuracy: 0.8899 - val_loss: 1.8416 - val_accuracy: 0.5462\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.3012 - accuracy: 0.9120 - val_loss: 1.8590 - val_accuracy: 0.5442\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 16s 30ms/step - loss: 0.2679 - accuracy: 0.9227 - val_loss: 1.9056 - val_accuracy: 0.5419\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 16s 31ms/step - loss: 0.2258 - accuracy: 0.9351 - val_loss: 1.9465 - val_accuracy: 0.5459\n",
            "128/128 [==============================] - 3s 17ms/step - loss: 1.9846 - accuracy: 0.5536\n",
            "Model N. 5   Accuracy =  0.5535888671875 Loss =  1.9845967292785645 parameters =  [46.37436286  1.          2.32750698  0.29207627  0.32014804  0.2\n",
            "  0.26376244  0.        ] \n",
            "\n",
            "Stopping search: Swarm best position change less than 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBTBSJfujcU3"
      },
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kJ0a-Cvjexu"
      },
      "source": [
        "count=0\r\n",
        "max=0\r\n",
        "lb=[0,0,0,0,0,0.001,0,0]\r\n",
        "ub=[70,1,3,0.65,0.65,0.2,1,3]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THW076VsjfDd"
      },
      "source": [
        "def create_model_xception(x):\r\n",
        "  print(x[0],x[1],x[2],x[3],x[4],x[5],x[6])\r\n",
        "  IMG_SHAPE1=(71,71,3) \r\n",
        "\r\n",
        "  dense=tf.keras.applications.Xception(input_shape=IMG_SHAPE1,\r\n",
        "                                               include_top=False,\r\n",
        "                                               weights='imagenet') \r\n",
        "  tempre=dense\r\n",
        "  for layer in tempre.layers[:(-1)*int(round(x[0]))]:\r\n",
        "    layer.trainable = False\r\n",
        "  \r\n",
        "  #vgg19.trainable=False\r\n",
        "  model = tf.keras.Sequential()\r\n",
        "  model.add(tempre)\r\n",
        "  if (int(round(x[1]))):\r\n",
        "    model.add(keras.layers.Flatten())\r\n",
        "  else:\r\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\r\n",
        "  \r\n",
        "  if (int(round(x[2]))==3):\r\n",
        "    model.add(keras.layers.Dense(2048, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(0.5))\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==2):\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==1):\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "\r\n",
        "  for layer in model.layers:\r\n",
        "    print(layer, layer.trainable)\r\n",
        "  model.add(keras.layers.Dense(100,activation=\"softmax\"))\r\n",
        "  if x[5]< 0.003:\r\n",
        "    learning_rate = 0.0000005\r\n",
        "  elif x[5]< 0.0075:\r\n",
        "    learning_rate = 0.000001\r\n",
        "  elif x[5]< 0.015:\r\n",
        "    learning_rate = 0.000005\r\n",
        "  elif x[5]< 0.035:\r\n",
        "    learning_rate = 0.00001\r\n",
        "  elif x[5]< 0.075:\r\n",
        "    learning_rate = 0.00005\r\n",
        "  elif x[5]< 0.125:\r\n",
        "    learning_rate = 0.0001\r\n",
        "  elif x[5]< 0.175:\r\n",
        "    learning_rate = 0.0005\r\n",
        "  else:\r\n",
        "    learning_rate = 0.001\r\n",
        "\r\n",
        "  if (x[6]<0.5):\r\n",
        "    opt = keras.optimizers.SGD(learning_rate=learning_rate)\r\n",
        "  else:\r\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU4Be3ELjfO1"
      },
      "source": [
        "def apple(x):\r\n",
        "  global max\r\n",
        "  model = create_model_xception(x)\r\n",
        "  if (x[7]<1):\r\n",
        "    model.fit(train_71_b64, epochs=30, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_71_b64,validation_steps=94,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_71_b64, verbose=1,steps=128)\r\n",
        "  elif (x[7]<2):\r\n",
        "    model.fit(train_71_b128, epochs=30, batch_size=128,steps_per_epoch=264 ,verbose=1,validation_data=validation_71_b128,validation_steps=47,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_71_b128, verbose=1,steps=64)\r\n",
        "  else:\r\n",
        "    model.fit(train_71_b256, epochs=30, batch_size=256, steps_per_epoch=132, verbose=1,validation_data=validation_71_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "    loss, acc = model.evaluate(test_71_b256, verbose=1,steps=32)\r\n",
        "  if acc>max:\r\n",
        "    global count \r\n",
        "    max=acc\r\n",
        "    count = count+1\r\n",
        "    print(\"Model N.\",count,\"  Accuracy = \",acc,\"Loss = \",loss, \"parameters = \",x,\"\\n\")\r\n",
        "  return (1/(1+acc))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul8NNyuxjfdg",
        "outputId": "6c6f8a0f-ea0d-461e-973d-8bb04de13f32"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.297384302708426 0.32974469915802496 1.3584507815633637 0.19696687392901008 0.49798093743211386 0.09023445476287048 0.7763904139796202\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f52610> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9799649f50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799671e10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799cff590> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 21s 114ms/step - loss: 2.9229 - accuracy: 0.3801 - val_loss: 1.1975 - val_accuracy: 0.6650\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.8552 - accuracy: 0.7557 - val_loss: 0.9731 - val_accuracy: 0.6971\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.5183 - accuracy: 0.8506 - val_loss: 0.9211 - val_accuracy: 0.7129\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.3316 - accuracy: 0.9163 - val_loss: 0.9067 - val_accuracy: 0.7188\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.2076 - accuracy: 0.9533 - val_loss: 0.9147 - val_accuracy: 0.7220\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.1346 - accuracy: 0.9755 - val_loss: 0.9291 - val_accuracy: 0.7223\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0845 - accuracy: 0.9882 - val_loss: 0.9712 - val_accuracy: 0.7222\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.0557 - accuracy: 0.9942 - val_loss: 0.9834 - val_accuracy: 0.7228\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0374 - accuracy: 0.9966 - val_loss: 1.0214 - val_accuracy: 0.7223\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0256 - accuracy: 0.9988 - val_loss: 1.0587 - val_accuracy: 0.7235\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.0193 - accuracy: 0.9992 - val_loss: 1.0844 - val_accuracy: 0.7243\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.0137 - accuracy: 0.9999 - val_loss: 1.1046 - val_accuracy: 0.7253\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0105 - accuracy: 0.9999 - val_loss: 1.1227 - val_accuracy: 0.7287\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.7251\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 14s 105ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.7259\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1770 - val_accuracy: 0.7231\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.7227\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 1.1754 - accuracy: 0.7294\n",
            "Model N. 1   Accuracy =  0.7293701171875 Loss =  1.1754173040390015 parameters =  [3.2973843  0.3297447  1.35845078 0.19696687 0.49798094 0.09023445\n",
            " 0.77639041 2.61941845] \n",
            "\n",
            "51.91507852946659 0.992195783016632 1.7025987085524388 0.44473387383877777 0.3161123036031167 0.17866813834483614 0.04838823462557518\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99ce0cddd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e2f9d50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e2e2810> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf809c10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e2e2310> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e2e2950> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 30s 91ms/step - loss: 4.4887 - accuracy: 0.0319 - val_loss: 3.7583 - val_accuracy: 0.2031\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 3.7059 - accuracy: 0.1182 - val_loss: 2.7081 - val_accuracy: 0.3491\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 2.9007 - accuracy: 0.2097 - val_loss: 2.0298 - val_accuracy: 0.4884\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 2.3631 - accuracy: 0.3292 - val_loss: 1.6446 - val_accuracy: 0.5559\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 1.9293 - accuracy: 0.4329 - val_loss: 1.3856 - val_accuracy: 0.5959\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 1.6163 - accuracy: 0.5154 - val_loss: 1.2369 - val_accuracy: 0.6218\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 1.4157 - accuracy: 0.5693 - val_loss: 1.1487 - val_accuracy: 0.6341\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 23s 89ms/step - loss: 1.2797 - accuracy: 0.6012 - val_loss: 1.0776 - val_accuracy: 0.6529\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 1.1420 - accuracy: 0.6409 - val_loss: 1.0301 - val_accuracy: 0.6661\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 1.0505 - accuracy: 0.6687 - val_loss: 0.9907 - val_accuracy: 0.6823\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 0.9780 - accuracy: 0.6885 - val_loss: 0.9610 - val_accuracy: 0.6900\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 0.9348 - accuracy: 0.7026 - val_loss: 0.9369 - val_accuracy: 0.6903\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.8587 - accuracy: 0.7250 - val_loss: 0.9162 - val_accuracy: 0.7031\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 0.8113 - accuracy: 0.7364 - val_loss: 0.8946 - val_accuracy: 0.7096\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.7601 - accuracy: 0.7535 - val_loss: 0.8807 - val_accuracy: 0.7163\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.7174 - accuracy: 0.7663 - val_loss: 0.8689 - val_accuracy: 0.7188\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.6838 - accuracy: 0.7761 - val_loss: 0.8538 - val_accuracy: 0.7214\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.6468 - accuracy: 0.7882 - val_loss: 0.8451 - val_accuracy: 0.7221\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.6203 - accuracy: 0.7970 - val_loss: 0.8397 - val_accuracy: 0.7254\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.5956 - accuracy: 0.8061 - val_loss: 0.8307 - val_accuracy: 0.7279\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.5515 - accuracy: 0.8162 - val_loss: 0.8253 - val_accuracy: 0.7314\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.5281 - accuracy: 0.8267 - val_loss: 0.8226 - val_accuracy: 0.7407\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 0.5021 - accuracy: 0.8355 - val_loss: 0.8162 - val_accuracy: 0.7410\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.4761 - accuracy: 0.8427 - val_loss: 0.8152 - val_accuracy: 0.7390\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.4576 - accuracy: 0.8484 - val_loss: 0.8155 - val_accuracy: 0.7453\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.4282 - accuracy: 0.8593 - val_loss: 0.8123 - val_accuracy: 0.7482\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.4033 - accuracy: 0.8644 - val_loss: 0.8129 - val_accuracy: 0.7498\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.3886 - accuracy: 0.8712 - val_loss: 0.8130 - val_accuracy: 0.7523\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.3661 - accuracy: 0.8799 - val_loss: 0.8179 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 24s 89ms/step - loss: 0.3500 - accuracy: 0.8854 - val_loss: 0.8186 - val_accuracy: 0.7498\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 0.7834 - accuracy: 0.7688\n",
            "Model N. 2   Accuracy =  0.768798828125 Loss =  0.7833930850028992 parameters =  [5.19150785e+01 9.92195783e-01 1.70259871e+00 4.44733874e-01\n",
            " 3.16112304e-01 1.78668138e-01 4.83882346e-02 1.73126981e+00] \n",
            "\n",
            "14.783790798070964 0.4666732763391528 0.8888708519713613 0.5387670764819256 0.5750693329283452 0.13051026149492376 0.6108935861939131\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d0a2c50> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f99e81ceb50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978df20ad0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97917bd6d0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 24s 69ms/step - loss: 1.5415 - accuracy: 0.6087 - val_loss: 0.8754 - val_accuracy: 0.7739\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0901 - accuracy: 0.9709 - val_loss: 1.0735 - val_accuracy: 0.7902\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 1.2505 - val_accuracy: 0.7656\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 17s 65ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 1.3514 - val_accuracy: 0.7638\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 1.5040 - val_accuracy: 0.7537\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 17s 65ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 1.5603 - val_accuracy: 0.7558\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.5312 - accuracy: 0.7673\n",
            "53.025713826965394 0.5641925318774089 1.6366805506356403 0.05950555350438621 0.5792201581965193 0.19507284059030452 0.7950051092131633\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791a97690> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f67e710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791afc450> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97990f9190> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792ad48d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791afc4d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 175ms/step - loss: 1.7025 - accuracy: 0.5844 - val_loss: 1.4736 - val_accuracy: 0.7526\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.1446 - accuracy: 0.9622 - val_loss: 1.3377 - val_accuracy: 0.7842\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0724 - accuracy: 0.9820 - val_loss: 1.2925 - val_accuracy: 0.7713\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0778 - accuracy: 0.9813 - val_loss: 1.2186 - val_accuracy: 0.7819\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0500 - accuracy: 0.9884 - val_loss: 1.3510 - val_accuracy: 0.7944\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 1.2096 - val_accuracy: 0.8101\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0496 - accuracy: 0.9897 - val_loss: 1.3104 - val_accuracy: 0.8107\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0454 - accuracy: 0.9913 - val_loss: 1.2199 - val_accuracy: 0.7996\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0479 - accuracy: 0.9908 - val_loss: 1.4811 - val_accuracy: 0.7850\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0406 - accuracy: 0.9914 - val_loss: 1.4552 - val_accuracy: 0.8047\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0239 - accuracy: 0.9955 - val_loss: 1.3028 - val_accuracy: 0.8192\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 1.3312 - val_accuracy: 0.8182\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0267 - accuracy: 0.9953 - val_loss: 1.3205 - val_accuracy: 0.8022\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 1.3307 - val_accuracy: 0.7936\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0287 - accuracy: 0.9949 - val_loss: 1.6019 - val_accuracy: 0.8039\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.5669 - accuracy: 0.7968\n",
            "Model N. 3   Accuracy =  0.7967529296875 Loss =  1.566881775856018 parameters =  [53.02571383  0.56419253  1.63668055  0.05950555  0.57922016  0.19507284\n",
            "  0.79500511  2.07744026] \n",
            "\n",
            "3.0310919862202046 0.2084983661501585 2.24667892111544 0.27302591919722385 0.4253640491927955 0.1411563779926197 0.27745569966720407\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d889510> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978f4fbb10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4fbe10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bcae290> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e2f8650> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978cfc5a50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 20s 112ms/step - loss: 4.5745 - accuracy: 0.0209 - val_loss: 4.3985 - val_accuracy: 0.0547\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 4.4441 - accuracy: 0.0373 - val_loss: 4.2896 - val_accuracy: 0.0938\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 4.3284 - accuracy: 0.0549 - val_loss: 4.1801 - val_accuracy: 0.1216\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 4.2132 - accuracy: 0.0731 - val_loss: 4.0656 - val_accuracy: 0.1450\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.1043 - accuracy: 0.0857 - val_loss: 3.9527 - val_accuracy: 0.1562\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.9861 - accuracy: 0.1073 - val_loss: 3.8411 - val_accuracy: 0.1766\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.8852 - accuracy: 0.1162 - val_loss: 3.7297 - val_accuracy: 0.2010\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.7847 - accuracy: 0.1268 - val_loss: 3.6258 - val_accuracy: 0.2253\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.6778 - accuracy: 0.1422 - val_loss: 3.5220 - val_accuracy: 0.2482\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.5786 - accuracy: 0.1572 - val_loss: 3.4295 - val_accuracy: 0.2702\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.4829 - accuracy: 0.1722 - val_loss: 3.3331 - val_accuracy: 0.2915\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.4010 - accuracy: 0.1835 - val_loss: 3.2469 - val_accuracy: 0.3102\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.3218 - accuracy: 0.1991 - val_loss: 3.1645 - val_accuracy: 0.3280\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.2402 - accuracy: 0.2126 - val_loss: 3.0831 - val_accuracy: 0.3424\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.1641 - accuracy: 0.2267 - val_loss: 3.0068 - val_accuracy: 0.3527\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.1001 - accuracy: 0.2427 - val_loss: 2.9396 - val_accuracy: 0.3774\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.0296 - accuracy: 0.2538 - val_loss: 2.8780 - val_accuracy: 0.3856\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 14s 108ms/step - loss: 2.9715 - accuracy: 0.2591 - val_loss: 2.8114 - val_accuracy: 0.4030\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 2.9158 - accuracy: 0.2714 - val_loss: 2.7529 - val_accuracy: 0.4108\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 2.8663 - accuracy: 0.2748 - val_loss: 2.6924 - val_accuracy: 0.4232\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.7987 - accuracy: 0.2940 - val_loss: 2.6390 - val_accuracy: 0.4303\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 2.7517 - accuracy: 0.3040 - val_loss: 2.5874 - val_accuracy: 0.4445\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.7077 - accuracy: 0.3073 - val_loss: 2.5379 - val_accuracy: 0.4504\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.6717 - accuracy: 0.3173 - val_loss: 2.4928 - val_accuracy: 0.4559\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.6164 - accuracy: 0.3241 - val_loss: 2.4467 - val_accuracy: 0.4614\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 2.5633 - accuracy: 0.3413 - val_loss: 2.4088 - val_accuracy: 0.4650\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.5329 - accuracy: 0.3456 - val_loss: 2.3650 - val_accuracy: 0.4723\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.4871 - accuracy: 0.3499 - val_loss: 2.3291 - val_accuracy: 0.4793\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.4510 - accuracy: 0.3634 - val_loss: 2.2891 - val_accuracy: 0.4816\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.4229 - accuracy: 0.3644 - val_loss: 2.2528 - val_accuracy: 0.4875\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 2.2213 - accuracy: 0.5101\n",
            "65.40084630725963 0.6121408551945782 1.1156878341920504 0.0017041621787982964 0.42394319608834047 0.16369316063882744 0.37691292216820704\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979976ffd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99ce2e1ed0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97993cee50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf683b90> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 36s 58ms/step - loss: 4.2594 - accuracy: 0.0694 - val_loss: 3.0486 - val_accuracy: 0.3100\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 31s 57ms/step - loss: 2.6204 - accuracy: 0.3670 - val_loss: 1.8946 - val_accuracy: 0.5133\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 30s 57ms/step - loss: 1.7612 - accuracy: 0.5599 - val_loss: 1.4688 - val_accuracy: 0.5838\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 30s 57ms/step - loss: 1.3244 - accuracy: 0.6386 - val_loss: 1.2389 - val_accuracy: 0.6270\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 30s 57ms/step - loss: 1.1103 - accuracy: 0.6760 - val_loss: 1.1102 - val_accuracy: 0.6602\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.9456 - accuracy: 0.7157 - val_loss: 1.0302 - val_accuracy: 0.6740\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.8325 - accuracy: 0.7462 - val_loss: 0.9748 - val_accuracy: 0.6907\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.7520 - accuracy: 0.7675 - val_loss: 0.9330 - val_accuracy: 0.7040\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 30s 57ms/step - loss: 0.6832 - accuracy: 0.7857 - val_loss: 0.9027 - val_accuracy: 0.7079\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.6432 - accuracy: 0.8024 - val_loss: 0.8752 - val_accuracy: 0.7212\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.5822 - accuracy: 0.8176 - val_loss: 0.8559 - val_accuracy: 0.7311\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.5315 - accuracy: 0.8374 - val_loss: 0.8439 - val_accuracy: 0.7400\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.4968 - accuracy: 0.8481 - val_loss: 0.8328 - val_accuracy: 0.7379\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.4568 - accuracy: 0.8640 - val_loss: 0.8192 - val_accuracy: 0.7420\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.4227 - accuracy: 0.8722 - val_loss: 0.8099 - val_accuracy: 0.7472\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.3883 - accuracy: 0.8863 - val_loss: 0.8082 - val_accuracy: 0.7440\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.3698 - accuracy: 0.8902 - val_loss: 0.8054 - val_accuracy: 0.7490\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.3391 - accuracy: 0.9029 - val_loss: 0.7987 - val_accuracy: 0.7462\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.3221 - accuracy: 0.9090 - val_loss: 0.7984 - val_accuracy: 0.7497\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2975 - accuracy: 0.9187 - val_loss: 0.8017 - val_accuracy: 0.7475\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2774 - accuracy: 0.9249 - val_loss: 0.7919 - val_accuracy: 0.7497\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2606 - accuracy: 0.9305 - val_loss: 0.7933 - val_accuracy: 0.7518\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2359 - accuracy: 0.9406 - val_loss: 0.7959 - val_accuracy: 0.7523\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2177 - accuracy: 0.9473 - val_loss: 0.7935 - val_accuracy: 0.7528\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.2022 - accuracy: 0.9510 - val_loss: 0.7989 - val_accuracy: 0.7563\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.1934 - accuracy: 0.9531 - val_loss: 0.8015 - val_accuracy: 0.7563\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.1793 - accuracy: 0.9602 - val_loss: 0.8000 - val_accuracy: 0.7616\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.1664 - accuracy: 0.9638 - val_loss: 0.8093 - val_accuracy: 0.7570\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.1581 - accuracy: 0.9670 - val_loss: 0.8071 - val_accuracy: 0.7573\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 30s 56ms/step - loss: 0.1501 - accuracy: 0.9689 - val_loss: 0.8082 - val_accuracy: 0.7568\n",
            "128/128 [==============================] - 5s 25ms/step - loss: 0.7804 - accuracy: 0.7626\n",
            "69.14936271297283 0.14417749727568396 0.8213077613658668 0.2556139157639423 0.02484897455278289 0.027100489200264817 0.1813671080498933\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e333a10> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978bbcdb90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dfe1050> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e49be50> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 32s 99ms/step - loss: 4.7427 - accuracy: 0.0087 - val_loss: 4.6840 - val_accuracy: 0.0068\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7391 - accuracy: 0.0098 - val_loss: 4.6989 - val_accuracy: 0.0073\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7367 - accuracy: 0.0089 - val_loss: 4.6928 - val_accuracy: 0.0088\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7341 - accuracy: 0.0093 - val_loss: 4.6860 - val_accuracy: 0.0093\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7224 - accuracy: 0.0104 - val_loss: 4.6879 - val_accuracy: 0.0093\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7246 - accuracy: 0.0105 - val_loss: 4.6887 - val_accuracy: 0.0093\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7216 - accuracy: 0.0098 - val_loss: 4.6806 - val_accuracy: 0.0093\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7202 - accuracy: 0.0109 - val_loss: 4.6932 - val_accuracy: 0.0100\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7176 - accuracy: 0.0121 - val_loss: 4.6738 - val_accuracy: 0.0093\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7124 - accuracy: 0.0133 - val_loss: 4.6782 - val_accuracy: 0.0113\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 25s 97ms/step - loss: 4.7082 - accuracy: 0.0114 - val_loss: 4.6776 - val_accuracy: 0.0106\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.7056 - accuracy: 0.0115 - val_loss: 4.6755 - val_accuracy: 0.0113\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.6966 - accuracy: 0.0119 - val_loss: 4.6655 - val_accuracy: 0.0113\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.6983 - accuracy: 0.0128 - val_loss: 4.6643 - val_accuracy: 0.0106\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 4.6660 - accuracy: 0.0107\n",
            "0.6250700739801018 0.5173688157128952 1.7334240586843577 0.37484583056303916 0.04795595082547585 0.14921850536916192 0.4260493387939267\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798e34a50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798e619d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799049950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978efb3210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792aab050> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dfe1d10> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 23s 34ms/step - loss: 3.7851 - accuracy: 0.1420 - val_loss: 2.1366 - val_accuracy: 0.4737\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 2.1010 - accuracy: 0.4424 - val_loss: 1.6754 - val_accuracy: 0.5539\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.7132 - accuracy: 0.5292 - val_loss: 1.5010 - val_accuracy: 0.5989\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.5161 - accuracy: 0.5792 - val_loss: 1.4107 - val_accuracy: 0.6085\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.4139 - accuracy: 0.6092 - val_loss: 1.3514 - val_accuracy: 0.6288\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.3208 - accuracy: 0.6306 - val_loss: 1.3070 - val_accuracy: 0.6416\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.2465 - accuracy: 0.6519 - val_loss: 1.2717 - val_accuracy: 0.6473\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.1959 - accuracy: 0.6644 - val_loss: 1.2415 - val_accuracy: 0.6567\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.1360 - accuracy: 0.6783 - val_loss: 1.2177 - val_accuracy: 0.6612\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.0893 - accuracy: 0.6894 - val_loss: 1.1966 - val_accuracy: 0.6632\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 1.0491 - accuracy: 0.7036 - val_loss: 1.1846 - val_accuracy: 0.6627\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 1.0252 - accuracy: 0.7113 - val_loss: 1.1671 - val_accuracy: 0.6664\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.9959 - accuracy: 0.7204 - val_loss: 1.1508 - val_accuracy: 0.6735\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.9674 - accuracy: 0.7266 - val_loss: 1.1454 - val_accuracy: 0.6739\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.9326 - accuracy: 0.7334 - val_loss: 1.1376 - val_accuracy: 0.6775\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.9127 - accuracy: 0.7400 - val_loss: 1.1187 - val_accuracy: 0.6785\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.8771 - accuracy: 0.7531 - val_loss: 1.1143 - val_accuracy: 0.6843\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.8605 - accuracy: 0.7558 - val_loss: 1.1070 - val_accuracy: 0.6848\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.8338 - accuracy: 0.7656 - val_loss: 1.1025 - val_accuracy: 0.6893\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.8185 - accuracy: 0.7691 - val_loss: 1.0952 - val_accuracy: 0.6912\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.7983 - accuracy: 0.7719 - val_loss: 1.0965 - val_accuracy: 0.6875\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.7757 - accuracy: 0.7803 - val_loss: 1.0823 - val_accuracy: 0.6956\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.7648 - accuracy: 0.7836 - val_loss: 1.0767 - val_accuracy: 0.6933\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.7387 - accuracy: 0.7933 - val_loss: 1.0751 - val_accuracy: 0.6953\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.7353 - accuracy: 0.7897 - val_loss: 1.0725 - val_accuracy: 0.6945\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 17s 33ms/step - loss: 0.7145 - accuracy: 0.7953 - val_loss: 1.0675 - val_accuracy: 0.7000\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6910 - accuracy: 0.8058 - val_loss: 1.0602 - val_accuracy: 0.6993\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6749 - accuracy: 0.8129 - val_loss: 1.0567 - val_accuracy: 0.7003\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6616 - accuracy: 0.8146 - val_loss: 1.0591 - val_accuracy: 0.6980\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 17s 32ms/step - loss: 0.6511 - accuracy: 0.8214 - val_loss: 1.0548 - val_accuracy: 0.6991\n",
            "128/128 [==============================] - 5s 24ms/step - loss: 1.0194 - accuracy: 0.7075\n",
            "55.91298717816701 0.5850467660777562 1.851310578182317 0.4041937038185668 0.44488369894883656 0.1715141774135409 0.7623822848532715\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e55cb50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97992ba810> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b7f8e90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4cd9d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4ffb10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b37e890> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 177ms/step - loss: 1.8772 - accuracy: 0.5393 - val_loss: 1.3079 - val_accuracy: 0.7762\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 1.3780 - val_accuracy: 0.7873\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0647 - accuracy: 0.9850 - val_loss: 1.2187 - val_accuracy: 0.7773\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0332 - accuracy: 0.9907 - val_loss: 1.3722 - val_accuracy: 0.7992\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0342 - accuracy: 0.9922 - val_loss: 1.4624 - val_accuracy: 0.7858\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0361 - accuracy: 0.9918 - val_loss: 1.4896 - val_accuracy: 0.7931\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0377 - accuracy: 0.9926 - val_loss: 1.2734 - val_accuracy: 0.8055\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 1.3235 - val_accuracy: 0.8053\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0261 - accuracy: 0.9952 - val_loss: 1.4826 - val_accuracy: 0.7954\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0223 - accuracy: 0.9966 - val_loss: 1.3320 - val_accuracy: 0.8029\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 1.4007 - val_accuracy: 0.7808\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.4051 - accuracy: 0.8075\n",
            "Model N. 4   Accuracy =  0.8074951171875 Loss =  1.4051239490509033 parameters =  [55.91298718  0.58504677  1.85131058  0.4041937   0.4448837   0.17151418\n",
            "  0.76238228  2.72977414] \n",
            "\n",
            "16.463947628391193 0.4243745485823337 0.9874049209351792 0.13607955630104135 0.26749297572773734 0.1704360164244593 0.9702700734701573\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978efb3ed0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f99bf684210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97991480d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf3f6210> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 23s 67ms/step - loss: 1.3526 - accuracy: 0.6618 - val_loss: 0.8976 - val_accuracy: 0.7866\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0565 - accuracy: 0.9829 - val_loss: 1.1873 - val_accuracy: 0.7768\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 1.3006 - val_accuracy: 0.7678\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 1.3320 - val_accuracy: 0.7773\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 17s 64ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.4076 - val_accuracy: 0.7620\n",
            "64/64 [==============================] - 4s 40ms/step - loss: 1.3108 - accuracy: 0.7819\n",
            "4.6910295545261675 0.0648503499280374 1.7425427062555858 0.25927440452143347 0.44981994893442295 0.13631220018411153 0.8809307590621613\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f4fe050> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97914b7050> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d0241d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bfc88710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dffde50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d009ed0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 20s 114ms/step - loss: 1.9347 - accuracy: 0.4916 - val_loss: 1.2082 - val_accuracy: 0.7210\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 0.1916 - accuracy: 0.9417 - val_loss: 1.3742 - val_accuracy: 0.7132\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 0.0330 - accuracy: 0.9929 - val_loss: 1.5546 - val_accuracy: 0.7207\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.6140 - val_accuracy: 0.7188\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 1.7265 - val_accuracy: 0.7174\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 1.6862 - accuracy: 0.7151\n",
            "70.0 1.0 0.5492012683040379 0.3361339839265208 0.39881157217826835 0.07915279888461009 0.3447369887947104\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f4524d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99e81d01d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791c9f710> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bfe48150> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 187ms/step - loss: 4.6205 - accuracy: 0.0175 - val_loss: 4.5630 - val_accuracy: 0.0264\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.4826 - accuracy: 0.0314 - val_loss: 4.4531 - val_accuracy: 0.0555\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.3497 - accuracy: 0.0543 - val_loss: 4.3130 - val_accuracy: 0.0750\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.2377 - accuracy: 0.0715 - val_loss: 4.1876 - val_accuracy: 0.0939\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.1399 - accuracy: 0.0829 - val_loss: 4.0824 - val_accuracy: 0.1100\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.0401 - accuracy: 0.0954 - val_loss: 3.9802 - val_accuracy: 0.1307\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.9391 - accuracy: 0.1051 - val_loss: 3.8844 - val_accuracy: 0.1400\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.8588 - accuracy: 0.1108 - val_loss: 3.7893 - val_accuracy: 0.1476\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.7631 - accuracy: 0.1230 - val_loss: 3.6938 - val_accuracy: 0.1619\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.6713 - accuracy: 0.1345 - val_loss: 3.6016 - val_accuracy: 0.1719\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.5890 - accuracy: 0.1353 - val_loss: 3.5052 - val_accuracy: 0.1771\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.5117 - accuracy: 0.1447 - val_loss: 3.4125 - val_accuracy: 0.1919\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.4203 - accuracy: 0.1567 - val_loss: 3.3151 - val_accuracy: 0.2074\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.3470 - accuracy: 0.1645 - val_loss: 3.2170 - val_accuracy: 0.2282\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.2679 - accuracy: 0.1679 - val_loss: 3.1274 - val_accuracy: 0.2440\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.1927 - accuracy: 0.1761 - val_loss: 3.0390 - val_accuracy: 0.2581\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.1108 - accuracy: 0.1840 - val_loss: 2.9572 - val_accuracy: 0.2788\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.0551 - accuracy: 0.1821 - val_loss: 2.8740 - val_accuracy: 0.2876\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.9674 - accuracy: 0.1991 - val_loss: 2.7983 - val_accuracy: 0.3132\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.9105 - accuracy: 0.2091 - val_loss: 2.7338 - val_accuracy: 0.3241\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.8702 - accuracy: 0.2180 - val_loss: 2.6712 - val_accuracy: 0.3400\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.7989 - accuracy: 0.2291 - val_loss: 2.6103 - val_accuracy: 0.3644\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.7549 - accuracy: 0.2385 - val_loss: 2.5565 - val_accuracy: 0.3745\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.7014 - accuracy: 0.2479 - val_loss: 2.5086 - val_accuracy: 0.3900\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.6440 - accuracy: 0.2640 - val_loss: 2.4554 - val_accuracy: 0.4015\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.5980 - accuracy: 0.2752 - val_loss: 2.4063 - val_accuracy: 0.4167\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.5545 - accuracy: 0.2864 - val_loss: 2.3644 - val_accuracy: 0.4264\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.5284 - accuracy: 0.2925 - val_loss: 2.3313 - val_accuracy: 0.4427\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.4691 - accuracy: 0.3059 - val_loss: 2.2791 - val_accuracy: 0.4486\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.4361 - accuracy: 0.3201 - val_loss: 2.2354 - val_accuracy: 0.4621\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 2.2373 - accuracy: 0.4603\n",
            "70.0 0.3291010403306489 2.166767931402074 0.6160347805443398 0.65 0.2 0.7592910741677575\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791658790> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978cdf3d50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ef99090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bcc9f50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bd02a90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978ef99910> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 189ms/step - loss: 1.9842 - accuracy: 0.4918 - val_loss: 1.3047 - val_accuracy: 0.7572\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.1549 - accuracy: 0.9622 - val_loss: 1.1868 - val_accuracy: 0.8029\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0808 - accuracy: 0.9811 - val_loss: 1.1942 - val_accuracy: 0.7964\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0732 - accuracy: 0.9844 - val_loss: 1.2694 - val_accuracy: 0.8143\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0429 - accuracy: 0.9911 - val_loss: 1.1619 - val_accuracy: 0.8060\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0631 - accuracy: 0.9872 - val_loss: 1.2085 - val_accuracy: 0.8029\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0440 - accuracy: 0.9904 - val_loss: 1.1315 - val_accuracy: 0.8278\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 1.3072 - val_accuracy: 0.8242\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0355 - accuracy: 0.9935 - val_loss: 1.2504 - val_accuracy: 0.8162\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0302 - accuracy: 0.9939 - val_loss: 1.3375 - val_accuracy: 0.8107\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0416 - accuracy: 0.9917 - val_loss: 1.3849 - val_accuracy: 0.8122\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 1.3438 - accuracy: 0.8217\n",
            "Model N. 5   Accuracy =  0.8216552734375 Loss =  1.34382164478302 parameters =  [70.          0.32910104  2.16676793  0.61603478  0.65        0.2\n",
            "  0.75929107  2.36150023] \n",
            "\n",
            "58.388659625280084 0.3840142168489955 2.7100150973830694 0.5016867796105542 0.65 0.2 0.2621592192116976\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798ede2d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9791af0250> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b926d10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4b6410> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf3940d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791a9d850> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfa43950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97991326d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 175ms/step - loss: 4.6633 - accuracy: 0.0173 - val_loss: 4.5335 - val_accuracy: 0.0488\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 4.5634 - accuracy: 0.0289 - val_loss: 4.4908 - val_accuracy: 0.0550\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 4.4875 - accuracy: 0.0368 - val_loss: 4.4131 - val_accuracy: 0.0584\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 4.4120 - accuracy: 0.0466 - val_loss: 4.3211 - val_accuracy: 0.0552\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 4.3219 - accuracy: 0.0486 - val_loss: 4.2291 - val_accuracy: 0.0469\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 4.2071 - accuracy: 0.0567 - val_loss: 4.0859 - val_accuracy: 0.0475\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 4.1154 - accuracy: 0.0531 - val_loss: 3.9537 - val_accuracy: 0.0579\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 3.9296 - accuracy: 0.0737\n",
            "4.955007145973967 0.3485027944827833 1.1561626970421945 0.5446941941934873 0.4252732354725745 0.13971330374745028 0.1737137482818038\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e0045d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e001510> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e001590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f378190> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 21s 114ms/step - loss: 4.6652 - accuracy: 0.0154 - val_loss: 4.5724 - val_accuracy: 0.0176\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.5966 - accuracy: 0.0189 - val_loss: 4.4904 - val_accuracy: 0.0241\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.5212 - accuracy: 0.0279 - val_loss: 4.4239 - val_accuracy: 0.0420\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.4552 - accuracy: 0.0369 - val_loss: 4.3577 - val_accuracy: 0.0602\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.3858 - accuracy: 0.0490 - val_loss: 4.2901 - val_accuracy: 0.0783\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.3266 - accuracy: 0.0584 - val_loss: 4.2225 - val_accuracy: 0.0996\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.2538 - accuracy: 0.0720 - val_loss: 4.1540 - val_accuracy: 0.1172\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.1809 - accuracy: 0.0876 - val_loss: 4.0872 - val_accuracy: 0.1286\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 4.1156 - accuracy: 0.0989 - val_loss: 4.0207 - val_accuracy: 0.1437\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 4.0391 - accuracy: 0.1107 - val_loss: 3.9486 - val_accuracy: 0.1634\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 14s 108ms/step - loss: 3.9816 - accuracy: 0.1175 - val_loss: 3.8822 - val_accuracy: 0.1820\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.9129 - accuracy: 0.1309 - val_loss: 3.8136 - val_accuracy: 0.1968\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.8458 - accuracy: 0.1404 - val_loss: 3.7447 - val_accuracy: 0.2126\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.7803 - accuracy: 0.1563 - val_loss: 3.6767 - val_accuracy: 0.2257\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.7156 - accuracy: 0.1572 - val_loss: 3.6084 - val_accuracy: 0.2391\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.6491 - accuracy: 0.1673 - val_loss: 3.5406 - val_accuracy: 0.2480\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.5835 - accuracy: 0.1804 - val_loss: 3.4792 - val_accuracy: 0.2599\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.5264 - accuracy: 0.1874 - val_loss: 3.4151 - val_accuracy: 0.2703\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.4504 - accuracy: 0.1956 - val_loss: 3.3497 - val_accuracy: 0.2891\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.3988 - accuracy: 0.2033 - val_loss: 3.2916 - val_accuracy: 0.3018\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 3.3417 - accuracy: 0.2185 - val_loss: 3.2317 - val_accuracy: 0.3138\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.2826 - accuracy: 0.2262 - val_loss: 3.1714 - val_accuracy: 0.3270\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.2292 - accuracy: 0.2337 - val_loss: 3.1188 - val_accuracy: 0.3394\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.1833 - accuracy: 0.2435 - val_loss: 3.0645 - val_accuracy: 0.3561\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.1359 - accuracy: 0.2483 - val_loss: 3.0095 - val_accuracy: 0.3688\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.0778 - accuracy: 0.2663 - val_loss: 2.9620 - val_accuracy: 0.3818\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 3.0286 - accuracy: 0.2700 - val_loss: 2.9162 - val_accuracy: 0.3945\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.9812 - accuracy: 0.2805 - val_loss: 2.8687 - val_accuracy: 0.4074\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 14s 107ms/step - loss: 2.9381 - accuracy: 0.2911 - val_loss: 2.8242 - val_accuracy: 0.4146\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 14s 106ms/step - loss: 2.8958 - accuracy: 0.3007 - val_loss: 2.7799 - val_accuracy: 0.4209\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 2.7558 - accuracy: 0.4305\n",
            "70.0 0.2085873411716297 0.8258573857994961 0.0 0.5501442240259411 0.12761622589336247 0.3388461964737926\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f45b890> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978d22a790> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799267950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce2b6ad0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 32s 100ms/step - loss: 4.6123 - accuracy: 0.0125 - val_loss: 4.5330 - val_accuracy: 0.0294\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.4787 - accuracy: 0.0346 - val_loss: 4.4002 - val_accuracy: 0.0615\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.3360 - accuracy: 0.0661 - val_loss: 4.2531 - val_accuracy: 0.0800\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.1773 - accuracy: 0.0978 - val_loss: 4.1073 - val_accuracy: 0.1107\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 4.0215 - accuracy: 0.1225 - val_loss: 3.9693 - val_accuracy: 0.1350\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 3.8526 - accuracy: 0.1525 - val_loss: 3.7848 - val_accuracy: 0.1456\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 25s 97ms/step - loss: 3.6983 - accuracy: 0.1758 - val_loss: 3.6887 - val_accuracy: 0.1720\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 3.5486 - accuracy: 0.2043 - val_loss: 3.4735 - val_accuracy: 0.2118\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 3.3856 - accuracy: 0.2397 - val_loss: 3.2911 - val_accuracy: 0.2407\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 3.2113 - accuracy: 0.2732 - val_loss: 3.1159 - val_accuracy: 0.2826\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 3.0431 - accuracy: 0.3104 - val_loss: 2.9566 - val_accuracy: 0.3128\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.8915 - accuracy: 0.3414 - val_loss: 2.8007 - val_accuracy: 0.3472\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.7535 - accuracy: 0.3736 - val_loss: 2.6576 - val_accuracy: 0.3830\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.6113 - accuracy: 0.4032 - val_loss: 2.5210 - val_accuracy: 0.4142\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.4780 - accuracy: 0.4301 - val_loss: 2.4035 - val_accuracy: 0.4415\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.3500 - accuracy: 0.4580 - val_loss: 2.2777 - val_accuracy: 0.4638\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.2497 - accuracy: 0.4799 - val_loss: 2.1803 - val_accuracy: 0.4799\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.1232 - accuracy: 0.5054 - val_loss: 2.0746 - val_accuracy: 0.5071\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 2.0137 - accuracy: 0.5302 - val_loss: 1.9737 - val_accuracy: 0.5311\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.9202 - accuracy: 0.5502 - val_loss: 1.8848 - val_accuracy: 0.5484\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.8267 - accuracy: 0.5771 - val_loss: 1.8042 - val_accuracy: 0.5552\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.7396 - accuracy: 0.5935 - val_loss: 1.7274 - val_accuracy: 0.5695\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.6601 - accuracy: 0.6139 - val_loss: 1.6546 - val_accuracy: 0.5886\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 25s 97ms/step - loss: 1.5848 - accuracy: 0.6302 - val_loss: 1.5907 - val_accuracy: 0.5982\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 26s 97ms/step - loss: 1.5072 - accuracy: 0.6444 - val_loss: 1.5331 - val_accuracy: 0.6084\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 26s 97ms/step - loss: 1.4422 - accuracy: 0.6558 - val_loss: 1.4738 - val_accuracy: 0.6150\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.3824 - accuracy: 0.6654 - val_loss: 1.4231 - val_accuracy: 0.6228\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.3334 - accuracy: 0.6719 - val_loss: 1.3751 - val_accuracy: 0.6283\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 25s 96ms/step - loss: 1.2708 - accuracy: 0.6864 - val_loss: 1.3342 - val_accuracy: 0.6355\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 25s 97ms/step - loss: 1.2407 - accuracy: 0.6902 - val_loss: 1.3014 - val_accuracy: 0.6449\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.2993 - accuracy: 0.6553\n",
            "48.11422840848032 0.6773102122187041 0.0 0.3412853352249971 0.24881242237853124 0.16106379507878307 0.6628392237224436\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798dc1190> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bcc5a10> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 29s 87ms/step - loss: 1.0497 - accuracy: 0.7143 - val_loss: 1.0600 - val_accuracy: 0.7783\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 1.3832 - val_accuracy: 0.7548\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0807 - accuracy: 0.9753 - val_loss: 1.4512 - val_accuracy: 0.7714\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 1.4340 - val_accuracy: 0.7741\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 1.2801 - val_accuracy: 0.7904\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 1.1819 - val_accuracy: 0.7842\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 1.1170 - val_accuracy: 0.8050\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 1.5709 - val_accuracy: 0.7778\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 22s 85ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 1.2435 - val_accuracy: 0.7784\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 1.4089 - val_accuracy: 0.8002\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 1.3314 - val_accuracy: 0.8047\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.3654 - accuracy: 0.8020\n",
            "25.128469709393045 0.06148201007245413 1.2528968618524723 0.2714918156140008 0.07104592731728435 0.08021998939364106 0.40665849075329596\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791be5890> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9a2010bc10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99ce34b510> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978ce1f750> True\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 28s 43ms/step - loss: 4.6777 - accuracy: 0.0056 - val_loss: 4.6416 - val_accuracy: 0.0033\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.6318 - accuracy: 0.0098 - val_loss: 4.5918 - val_accuracy: 0.0093\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.5915 - accuracy: 0.0152 - val_loss: 4.5512 - val_accuracy: 0.0160\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.5576 - accuracy: 0.0204 - val_loss: 4.5074 - val_accuracy: 0.0259\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.5202 - accuracy: 0.0275 - val_loss: 4.4632 - val_accuracy: 0.0374\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.4820 - accuracy: 0.0376 - val_loss: 4.4086 - val_accuracy: 0.0559\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.4333 - accuracy: 0.0478 - val_loss: 4.3343 - val_accuracy: 0.0793\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.3857 - accuracy: 0.0583 - val_loss: 4.2495 - val_accuracy: 0.0928\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.3278 - accuracy: 0.0678 - val_loss: 4.1659 - val_accuracy: 0.1046\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.2652 - accuracy: 0.0858 - val_loss: 4.0664 - val_accuracy: 0.1215\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 4.2078 - accuracy: 0.1004 - val_loss: 3.9896 - val_accuracy: 0.1393\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.1491 - accuracy: 0.1092 - val_loss: 3.9021 - val_accuracy: 0.1501\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 4.0918 - accuracy: 0.1199 - val_loss: 3.8234 - val_accuracy: 0.1632\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 4.0393 - accuracy: 0.1328 - val_loss: 3.7491 - val_accuracy: 0.1679\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 3.9814 - accuracy: 0.1419 - val_loss: 3.6597 - val_accuracy: 0.1820\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.9339 - accuracy: 0.1489 - val_loss: 3.5750 - val_accuracy: 0.1888\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 3.8807 - accuracy: 0.1626 - val_loss: 3.5413 - val_accuracy: 0.1995\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.8301 - accuracy: 0.1753 - val_loss: 3.4806 - val_accuracy: 0.2056\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 3.7792 - accuracy: 0.1819 - val_loss: 3.3947 - val_accuracy: 0.2211\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.7291 - accuracy: 0.1920 - val_loss: 3.3354 - val_accuracy: 0.2345\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.6696 - accuracy: 0.2007 - val_loss: 3.2895 - val_accuracy: 0.2478\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.6228 - accuracy: 0.2093 - val_loss: 3.2007 - val_accuracy: 0.2538\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.5633 - accuracy: 0.2249 - val_loss: 3.1498 - val_accuracy: 0.2655\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.5189 - accuracy: 0.2327 - val_loss: 3.0807 - val_accuracy: 0.2683\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 23s 43ms/step - loss: 3.4707 - accuracy: 0.2379 - val_loss: 3.0534 - val_accuracy: 0.2743\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.4176 - accuracy: 0.2497 - val_loss: 2.9373 - val_accuracy: 0.2817\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.3651 - accuracy: 0.2482 - val_loss: 2.9359 - val_accuracy: 0.2857\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.3201 - accuracy: 0.2665 - val_loss: 2.8845 - val_accuracy: 0.2957\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 22s 42ms/step - loss: 3.2648 - accuracy: 0.2741 - val_loss: 2.7774 - val_accuracy: 0.2989\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 23s 42ms/step - loss: 3.2142 - accuracy: 0.2837 - val_loss: 2.7530 - val_accuracy: 0.3092\n",
            "128/128 [==============================] - 5s 24ms/step - loss: 2.7149 - accuracy: 0.3224\n",
            "70.0 0.2433244871551259 2.908922332221815 0.5227678584461734 0.41367048376589194 0.08291451323654014 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979284ab50> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f99bfe48490> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4515d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799090590> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979908ced0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b9e9790> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97990b8790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799086b10> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 34s 102ms/step - loss: 2.9014 - accuracy: 0.2655 - val_loss: 0.7376 - val_accuracy: 0.7894\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 26s 99ms/step - loss: 0.2280 - accuracy: 0.9303 - val_loss: 0.9514 - val_accuracy: 0.8097\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 26s 99ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 1.1299 - val_accuracy: 0.8183\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 1.3111 - val_accuracy: 0.8078\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 1.4183 - val_accuracy: 0.8097\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 26s 99ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 1.3517 - val_accuracy: 0.7997\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 1.3675 - val_accuracy: 0.8070\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.2660 - accuracy: 0.8057\n",
            "70.0 0.42894305968725377 1.0623186084545784 0.65 0.65 0.1448497586770317 0.5612551814797616\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b9bbe10> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f99bf6f21d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e55a550> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e55aa50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 188ms/step - loss: 1.7260 - accuracy: 0.5664 - val_loss: 0.9674 - val_accuracy: 0.8022\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 1.0793 - val_accuracy: 0.7876\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0464 - accuracy: 0.9871 - val_loss: 1.2819 - val_accuracy: 0.7905\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 1.2023 - val_accuracy: 0.8076\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 1.0694 - val_accuracy: 0.8211\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 1.0949 - val_accuracy: 0.8208\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 1.1368 - val_accuracy: 0.8302\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.0810 - val_accuracy: 0.8171\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 1.2627 - val_accuracy: 0.8071\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 1.2100 - val_accuracy: 0.8125\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 1.1020 - val_accuracy: 0.8115\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.0184 - accuracy: 0.8232\n",
            "Model N. 6   Accuracy =  0.8232421875 Loss =  1.018408179283142 parameters =  [70.          0.42894306  1.06231861  0.65        0.65        0.14484976\n",
            "  0.56125518  2.86362096] \n",
            "\n",
            "52.75116322466465 0.33177367316896217 1.2293107557512746 0.49530171405184553 0.6032839770696805 0.1595151074835401 0.5703507299140494\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b7d9ed0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9798e962d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f58dad0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798e9b850> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 170ms/step - loss: 1.6463 - accuracy: 0.5938 - val_loss: 0.9882 - val_accuracy: 0.7793\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 1.0055 - val_accuracy: 0.8013\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 1.1135 - val_accuracy: 0.7879\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 1.0842 - val_accuracy: 0.7926\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 1.0440 - val_accuracy: 0.8104\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 1.1996 - val_accuracy: 0.7843\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 1.0859 - val_accuracy: 0.8138\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 1.1008 - val_accuracy: 0.8088\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.2053 - val_accuracy: 0.8034\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 1.1481 - val_accuracy: 0.8091\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 1.0536 - val_accuracy: 0.8278\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.0374 - val_accuracy: 0.8260\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.1460 - val_accuracy: 0.8195\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 1.0974 - val_accuracy: 0.8063\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 1.1908 - val_accuracy: 0.8027\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.1711 - accuracy: 0.8171\n",
            "70.0 0.9948537889239893 0.5601967187750247 0.41308959196683503 0.44259923750208435 0.06540630086473942 0.40294248953426026\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978de16350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979974fd50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791031290> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e2f8d10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 188ms/step - loss: 4.7914 - accuracy: 0.0122 - val_loss: 4.6519 - val_accuracy: 0.0125\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.7042 - accuracy: 0.0141 - val_loss: 4.6063 - val_accuracy: 0.0199\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.6358 - accuracy: 0.0200 - val_loss: 4.5529 - val_accuracy: 0.0285\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.5756 - accuracy: 0.0247 - val_loss: 4.4934 - val_accuracy: 0.0389\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.5151 - accuracy: 0.0324 - val_loss: 4.4404 - val_accuracy: 0.0454\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.4564 - accuracy: 0.0391 - val_loss: 4.3896 - val_accuracy: 0.0544\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.4061 - accuracy: 0.0480 - val_loss: 4.3392 - val_accuracy: 0.0640\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.3497 - accuracy: 0.0498 - val_loss: 4.2924 - val_accuracy: 0.0671\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.3019 - accuracy: 0.0567 - val_loss: 4.2449 - val_accuracy: 0.0732\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.2630 - accuracy: 0.0659 - val_loss: 4.1974 - val_accuracy: 0.0809\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.2122 - accuracy: 0.0697 - val_loss: 4.1522 - val_accuracy: 0.0897\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.1620 - accuracy: 0.0763 - val_loss: 4.1053 - val_accuracy: 0.0970\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.1202 - accuracy: 0.0789 - val_loss: 4.0570 - val_accuracy: 0.1063\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.0840 - accuracy: 0.0836 - val_loss: 4.0104 - val_accuracy: 0.1167\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.0410 - accuracy: 0.0906 - val_loss: 3.9660 - val_accuracy: 0.1193\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.9855 - accuracy: 0.0918 - val_loss: 3.9190 - val_accuracy: 0.1239\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.9485 - accuracy: 0.1018 - val_loss: 3.8684 - val_accuracy: 0.1410\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.9072 - accuracy: 0.1041 - val_loss: 3.8252 - val_accuracy: 0.1465\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.8564 - accuracy: 0.1156 - val_loss: 3.7759 - val_accuracy: 0.1496\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.8211 - accuracy: 0.1129 - val_loss: 3.7268 - val_accuracy: 0.1554\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.7658 - accuracy: 0.1175 - val_loss: 3.6811 - val_accuracy: 0.1680\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.7303 - accuracy: 0.1248 - val_loss: 3.6333 - val_accuracy: 0.1769\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.6899 - accuracy: 0.1334 - val_loss: 3.5871 - val_accuracy: 0.1862\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.6561 - accuracy: 0.1301 - val_loss: 3.5399 - val_accuracy: 0.1969\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.6058 - accuracy: 0.1385 - val_loss: 3.4929 - val_accuracy: 0.2078\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.5652 - accuracy: 0.1371 - val_loss: 3.4434 - val_accuracy: 0.2189\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.5305 - accuracy: 0.1409 - val_loss: 3.3916 - val_accuracy: 0.2280\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.4857 - accuracy: 0.1433 - val_loss: 3.3498 - val_accuracy: 0.2352\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.4451 - accuracy: 0.1508 - val_loss: 3.2997 - val_accuracy: 0.2417\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.4128 - accuracy: 0.1553 - val_loss: 3.2526 - val_accuracy: 0.2474\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 3.2402 - accuracy: 0.2335\n",
            "70.0 0.3336709125872662 2.1978322262919416 0.65 0.65 0.2 0.6538905157558734\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798df6810> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f979168df10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f172790> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791632390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979168bed0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f172450> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 189ms/step - loss: 1.9986 - accuracy: 0.4898 - val_loss: 1.2791 - val_accuracy: 0.7782\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.1570 - accuracy: 0.9610 - val_loss: 1.4799 - val_accuracy: 0.7843\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0808 - accuracy: 0.9816 - val_loss: 1.3766 - val_accuracy: 0.7931\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0696 - accuracy: 0.9860 - val_loss: 1.2285 - val_accuracy: 0.8075\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0482 - accuracy: 0.9903 - val_loss: 1.6669 - val_accuracy: 0.7773\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0365 - accuracy: 0.9921 - val_loss: 1.2699 - val_accuracy: 0.7907\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0352 - accuracy: 0.9924 - val_loss: 1.2601 - val_accuracy: 0.8268\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 184ms/step - loss: 0.0344 - accuracy: 0.9923 - val_loss: 1.4694 - val_accuracy: 0.8092\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0490 - accuracy: 0.9910 - val_loss: 1.0801 - val_accuracy: 0.8317\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0203 - accuracy: 0.9956 - val_loss: 1.3094 - val_accuracy: 0.8215\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 1.1000 - val_accuracy: 0.8385\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 1.3268 - val_accuracy: 0.8192\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 1.4177 - val_accuracy: 0.8223\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 1.2154 - val_accuracy: 0.8296\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0269 - accuracy: 0.9953 - val_loss: 1.2026 - val_accuracy: 0.8242\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.3383 - accuracy: 0.8201\n",
            "67.2361875775793 0.3451131470575616 2.238765980536919 0.65 0.65 0.1886925227590713 0.49651529050069854\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9793ac86d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9791670190> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4c7350> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f4c7d90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791b17350> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97938c3890> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 183ms/step - loss: 4.6798 - accuracy: 0.0176 - val_loss: 4.5173 - val_accuracy: 0.0374\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 4.5570 - accuracy: 0.0264 - val_loss: 4.4666 - val_accuracy: 0.0728\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 4.4842 - accuracy: 0.0408 - val_loss: 4.3844 - val_accuracy: 0.0938\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 4.4033 - accuracy: 0.0463 - val_loss: 4.2850 - val_accuracy: 0.1074\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 4.3163 - accuracy: 0.0504 - val_loss: 4.1633 - val_accuracy: 0.1162\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 4.2121 - accuracy: 0.0597 - val_loss: 4.0288 - val_accuracy: 0.1159\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 4.0991 - accuracy: 0.0633 - val_loss: 3.8793 - val_accuracy: 0.1232\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.9809 - accuracy: 0.0658 - val_loss: 3.7403 - val_accuracy: 0.1265\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.8592 - accuracy: 0.0688 - val_loss: 3.5826 - val_accuracy: 0.1340\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.7460 - accuracy: 0.0746 - val_loss: 3.4555 - val_accuracy: 0.1523\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.6566 - accuracy: 0.0754 - val_loss: 3.3425 - val_accuracy: 0.1702\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.5585 - accuracy: 0.0775 - val_loss: 3.2409 - val_accuracy: 0.1903\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 3.4806 - accuracy: 0.0823 - val_loss: 3.1661 - val_accuracy: 0.2176\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.4199 - accuracy: 0.0794 - val_loss: 3.0946 - val_accuracy: 0.2362\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.3583 - accuracy: 0.0878 - val_loss: 3.0372 - val_accuracy: 0.2749\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.3028 - accuracy: 0.0947 - val_loss: 2.9766 - val_accuracy: 0.2900\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 3.2514 - accuracy: 0.0988 - val_loss: 2.9176 - val_accuracy: 0.3123\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 3.2070 - accuracy: 0.1037 - val_loss: 2.8626 - val_accuracy: 0.3232\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 3.1528 - accuracy: 0.1120 - val_loss: 2.8079 - val_accuracy: 0.3366\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 3.1011 - accuracy: 0.1230 - val_loss: 2.7496 - val_accuracy: 0.3438\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 3.0552 - accuracy: 0.1287 - val_loss: 2.6910 - val_accuracy: 0.3551\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 3.0020 - accuracy: 0.1403 - val_loss: 2.6307 - val_accuracy: 0.3709\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 2.9405 - accuracy: 0.1516 - val_loss: 2.5714 - val_accuracy: 0.3765\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 2.8921 - accuracy: 0.1607 - val_loss: 2.5086 - val_accuracy: 0.3942\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 2.8298 - accuracy: 0.1754 - val_loss: 2.4455 - val_accuracy: 0.4049\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 2.7850 - accuracy: 0.1868 - val_loss: 2.3839 - val_accuracy: 0.4225\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 2.7146 - accuracy: 0.2025 - val_loss: 2.3234 - val_accuracy: 0.4393\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 2.6638 - accuracy: 0.2150 - val_loss: 2.2672 - val_accuracy: 0.4481\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 2.6136 - accuracy: 0.2239 - val_loss: 2.2079 - val_accuracy: 0.4556\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 2.5608 - accuracy: 0.2352 - val_loss: 2.1481 - val_accuracy: 0.4714\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 2.1602 - accuracy: 0.4750\n",
            "21.479547547391633 0.39844875643835204 0.80763224256254 0.65 0.5097870686794426 0.14274868956039538 0.1653794751390517\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b606590> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9798f64d50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798f64910> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798e96550> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 23s 133ms/step - loss: 4.7025 - accuracy: 0.0117 - val_loss: 4.5899 - val_accuracy: 0.0125\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.6343 - accuracy: 0.0165 - val_loss: 4.5464 - val_accuracy: 0.0249\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.5854 - accuracy: 0.0218 - val_loss: 4.5178 - val_accuracy: 0.0361\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.5439 - accuracy: 0.0267 - val_loss: 4.4916 - val_accuracy: 0.0472\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.5064 - accuracy: 0.0313 - val_loss: 4.4575 - val_accuracy: 0.0607\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.4673 - accuracy: 0.0404 - val_loss: 4.4155 - val_accuracy: 0.0732\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.4203 - accuracy: 0.0469 - val_loss: 4.3620 - val_accuracy: 0.0944\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 4.3739 - accuracy: 0.0544 - val_loss: 4.2951 - val_accuracy: 0.1061\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.3153 - accuracy: 0.0597 - val_loss: 4.2076 - val_accuracy: 0.1159\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 4.2575 - accuracy: 0.0722 - val_loss: 4.1196 - val_accuracy: 0.1383\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 4.1886 - accuracy: 0.0782 - val_loss: 4.0417 - val_accuracy: 0.1519\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 4.1324 - accuracy: 0.0877 - val_loss: 3.9555 - val_accuracy: 0.1647\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 4.0689 - accuracy: 0.0944 - val_loss: 3.8681 - val_accuracy: 0.1820\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 4.0004 - accuracy: 0.1061 - val_loss: 3.8027 - val_accuracy: 0.1870\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.9457 - accuracy: 0.1136 - val_loss: 3.7302 - val_accuracy: 0.1955\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.8877 - accuracy: 0.1236 - val_loss: 3.6636 - val_accuracy: 0.2046\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 3.8387 - accuracy: 0.1284 - val_loss: 3.5820 - val_accuracy: 0.2152\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.7710 - accuracy: 0.1415 - val_loss: 3.5085 - val_accuracy: 0.2313\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.7299 - accuracy: 0.1471 - val_loss: 3.4630 - val_accuracy: 0.2437\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.6738 - accuracy: 0.1530 - val_loss: 3.3996 - val_accuracy: 0.2552\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 3.6147 - accuracy: 0.1629 - val_loss: 3.3395 - val_accuracy: 0.2674\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.5597 - accuracy: 0.1755 - val_loss: 3.2753 - val_accuracy: 0.2749\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 3.5078 - accuracy: 0.1822 - val_loss: 3.2094 - val_accuracy: 0.2850\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.4450 - accuracy: 0.1880 - val_loss: 3.1663 - val_accuracy: 0.2900\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.3963 - accuracy: 0.1929 - val_loss: 3.0975 - val_accuracy: 0.2980\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.3468 - accuracy: 0.1990 - val_loss: 3.0370 - val_accuracy: 0.3133\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.2890 - accuracy: 0.2078 - val_loss: 2.9843 - val_accuracy: 0.3249\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 3.2432 - accuracy: 0.2129 - val_loss: 2.9256 - val_accuracy: 0.3338\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 17s 127ms/step - loss: 3.1730 - accuracy: 0.2288 - val_loss: 2.8785 - val_accuracy: 0.3387\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 17s 126ms/step - loss: 3.1343 - accuracy: 0.2265 - val_loss: 2.8223 - val_accuracy: 0.3486\n",
            "32/32 [==============================] - 4s 77ms/step - loss: 2.8079 - accuracy: 0.3536\n",
            "70.0 0.13179881017035733 0.8863271007036143 0.335226348574814 0.6394682667358503 0.1255130767445943 0.476151572104194\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d9bfd90> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97917bd750> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97937c8650> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97999c4290> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 186ms/step - loss: 4.6501 - accuracy: 0.0154 - val_loss: 4.5899 - val_accuracy: 0.0286\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.5826 - accuracy: 0.0312 - val_loss: 4.5478 - val_accuracy: 0.0272\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.5278 - accuracy: 0.0427 - val_loss: 4.4892 - val_accuracy: 0.0470\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.4662 - accuracy: 0.0526 - val_loss: 4.4290 - val_accuracy: 0.0544\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.4024 - accuracy: 0.0609 - val_loss: 4.3634 - val_accuracy: 0.0602\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.3448 - accuracy: 0.0695 - val_loss: 4.3082 - val_accuracy: 0.0693\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.2745 - accuracy: 0.0779 - val_loss: 4.2360 - val_accuracy: 0.0739\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.2005 - accuracy: 0.0856 - val_loss: 4.1661 - val_accuracy: 0.0819\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.1344 - accuracy: 0.0915 - val_loss: 4.0960 - val_accuracy: 0.0907\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.0657 - accuracy: 0.1009 - val_loss: 4.0255 - val_accuracy: 0.1061\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.9941 - accuracy: 0.1065 - val_loss: 3.9463 - val_accuracy: 0.1188\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.9183 - accuracy: 0.1192 - val_loss: 3.8688 - val_accuracy: 0.1335\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.8379 - accuracy: 0.1288 - val_loss: 3.7920 - val_accuracy: 0.1545\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.7632 - accuracy: 0.1386 - val_loss: 3.7094 - val_accuracy: 0.1714\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.6810 - accuracy: 0.1469 - val_loss: 3.6215 - val_accuracy: 0.1938\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.6009 - accuracy: 0.1589 - val_loss: 3.5413 - val_accuracy: 0.2015\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.5243 - accuracy: 0.1610 - val_loss: 3.4563 - val_accuracy: 0.2148\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.4479 - accuracy: 0.1713 - val_loss: 3.3706 - val_accuracy: 0.2295\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.3618 - accuracy: 0.1880 - val_loss: 3.2909 - val_accuracy: 0.2381\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.2806 - accuracy: 0.1964 - val_loss: 3.2101 - val_accuracy: 0.2458\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.2102 - accuracy: 0.2057 - val_loss: 3.1376 - val_accuracy: 0.2594\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.1429 - accuracy: 0.2124 - val_loss: 3.0645 - val_accuracy: 0.2728\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.0629 - accuracy: 0.2326 - val_loss: 2.9973 - val_accuracy: 0.2803\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.0158 - accuracy: 0.2292 - val_loss: 2.9293 - val_accuracy: 0.2928\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.9510 - accuracy: 0.2430 - val_loss: 2.8678 - val_accuracy: 0.3014\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.8865 - accuracy: 0.2530 - val_loss: 2.8079 - val_accuracy: 0.3158\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.8319 - accuracy: 0.2701 - val_loss: 2.7477 - val_accuracy: 0.3275\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.7700 - accuracy: 0.2791 - val_loss: 2.6946 - val_accuracy: 0.3397\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 2.7186 - accuracy: 0.2875 - val_loss: 2.6364 - val_accuracy: 0.3608\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.6654 - accuracy: 0.3050 - val_loss: 2.5843 - val_accuracy: 0.3765\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 2.5720 - accuracy: 0.3794\n",
            "46.924251755389875 0.9356373482374049 0.0 0.5864041362914585 0.40982865089121245 0.2 0.8120750039390177\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f28ef50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e36dbd0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 29s 87ms/step - loss: 1.0206 - accuracy: 0.7179 - val_loss: 1.1055 - val_accuracy: 0.7681\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.1130 - accuracy: 0.9661 - val_loss: 1.1185 - val_accuracy: 0.7926\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0756 - accuracy: 0.9782 - val_loss: 1.3442 - val_accuracy: 0.7929\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0610 - accuracy: 0.9835 - val_loss: 1.0051 - val_accuracy: 0.8082\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 1.2579 - val_accuracy: 0.8075\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 1.1180 - val_accuracy: 0.8024\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 1.1163 - val_accuracy: 0.7989\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 1.2274 - val_accuracy: 0.8182\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 1.3395 - val_accuracy: 0.7985\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 1.2308 - val_accuracy: 0.7882\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 1.2348 - val_accuracy: 0.8034\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 22s 84ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.2555 - val_accuracy: 0.7984\n",
            "64/64 [==============================] - 4s 42ms/step - loss: 1.1999 - accuracy: 0.8236\n",
            "Model N. 7   Accuracy =  0.8236083984375 Loss =  1.1999105215072632 parameters =  [46.92425176  0.93563735  0.          0.58640414  0.40982865  0.2\n",
            "  0.812075    1.54950297] \n",
            "\n",
            "40.26650873877753 0.25536628388245214 0.36051290589921736 0.4668092688811223 0.2644339493653102 0.16242399045674888 0.48310463313342694\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b3ddd90> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9791bdbad0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 27s 83ms/step - loss: 4.5909 - accuracy: 0.0193 - val_loss: 4.4708 - val_accuracy: 0.0454\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 4.4361 - accuracy: 0.0502 - val_loss: 4.2958 - val_accuracy: 0.0780\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 4.2711 - accuracy: 0.0857 - val_loss: 4.0558 - val_accuracy: 0.1293\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 21s 80ms/step - loss: 4.0940 - accuracy: 0.1289 - val_loss: 3.8545 - val_accuracy: 0.1725\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.9280 - accuracy: 0.1715 - val_loss: 3.6969 - val_accuracy: 0.2119\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.7875 - accuracy: 0.2127 - val_loss: 3.5283 - val_accuracy: 0.2429\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.6423 - accuracy: 0.2520 - val_loss: 3.3830 - val_accuracy: 0.2761\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.5103 - accuracy: 0.2861 - val_loss: 3.2241 - val_accuracy: 0.3092\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.3656 - accuracy: 0.3285 - val_loss: 3.0658 - val_accuracy: 0.3426\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.2341 - accuracy: 0.3618 - val_loss: 2.9430 - val_accuracy: 0.3797\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 3.0978 - accuracy: 0.3934 - val_loss: 2.7868 - val_accuracy: 0.4031\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.9687 - accuracy: 0.4224 - val_loss: 2.6488 - val_accuracy: 0.4270\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.8440 - accuracy: 0.4467 - val_loss: 2.5172 - val_accuracy: 0.4466\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.7184 - accuracy: 0.4709 - val_loss: 2.4229 - val_accuracy: 0.4561\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.6055 - accuracy: 0.4876 - val_loss: 2.2814 - val_accuracy: 0.4707\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.4758 - accuracy: 0.5103 - val_loss: 2.1845 - val_accuracy: 0.4845\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.3646 - accuracy: 0.5230 - val_loss: 2.1079 - val_accuracy: 0.4973\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.2625 - accuracy: 0.5437 - val_loss: 2.0108 - val_accuracy: 0.5125\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.1660 - accuracy: 0.5497 - val_loss: 1.9111 - val_accuracy: 0.5194\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 2.0842 - accuracy: 0.5640 - val_loss: 1.8117 - val_accuracy: 0.5274\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.9832 - accuracy: 0.5786 - val_loss: 1.7452 - val_accuracy: 0.5407\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.8998 - accuracy: 0.5909 - val_loss: 1.6953 - val_accuracy: 0.5462\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 21s 80ms/step - loss: 1.8135 - accuracy: 0.6020 - val_loss: 1.6316 - val_accuracy: 0.5580\n",
            "Epoch 24/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.7458 - accuracy: 0.6202 - val_loss: 1.5779 - val_accuracy: 0.5736\n",
            "Epoch 25/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.6666 - accuracy: 0.6314 - val_loss: 1.5318 - val_accuracy: 0.5893\n",
            "Epoch 26/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.6014 - accuracy: 0.6462 - val_loss: 1.4710 - val_accuracy: 0.6021\n",
            "Epoch 27/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.5334 - accuracy: 0.6552 - val_loss: 1.4355 - val_accuracy: 0.6112\n",
            "Epoch 28/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.4932 - accuracy: 0.6615 - val_loss: 1.3853 - val_accuracy: 0.6169\n",
            "Epoch 29/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.4194 - accuracy: 0.6701 - val_loss: 1.3511 - val_accuracy: 0.6267\n",
            "Epoch 30/30\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 1.3864 - accuracy: 0.6773 - val_loss: 1.3236 - val_accuracy: 0.6302\n",
            "64/64 [==============================] - 4s 40ms/step - loss: 1.3075 - accuracy: 0.6458\n",
            "70.0 0.8786229962596568 0.648119438565196 0.592446850162363 0.3987007817511415 0.060724728212894985 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99bf6bd190> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e2d5710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e2e33d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97914b1f10> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 34s 103ms/step - loss: 2.5233 - accuracy: 0.3829 - val_loss: 0.7700 - val_accuracy: 0.7568\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.2408 - accuracy: 0.9261 - val_loss: 0.8394 - val_accuracy: 0.7804\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 27s 100ms/step - loss: 0.0417 - accuracy: 0.9901 - val_loss: 0.9229 - val_accuracy: 0.7854\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.9874 - val_accuracy: 0.7789\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 1.0445 - val_accuracy: 0.7776\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 1.0907 - val_accuracy: 0.7803\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 26s 100ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.1324 - val_accuracy: 0.7731\n",
            "64/64 [==============================] - 4s 42ms/step - loss: 1.1569 - accuracy: 0.7986\n",
            "70.0 0.4519389978354973 0.7124649141793952 0.65 0.65 0.16664561442373213 0.37965782982012597\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798fc8150> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e2c6310> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791aeab10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e2c6110> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 188ms/step - loss: 4.7080 - accuracy: 0.0163 - val_loss: 4.5897 - val_accuracy: 0.0355\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.6276 - accuracy: 0.0258 - val_loss: 4.5517 - val_accuracy: 0.0535\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.5762 - accuracy: 0.0315 - val_loss: 4.5078 - val_accuracy: 0.0664\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.5336 - accuracy: 0.0409 - val_loss: 4.4663 - val_accuracy: 0.0775\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.4854 - accuracy: 0.0490 - val_loss: 4.4244 - val_accuracy: 0.0854\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.4485 - accuracy: 0.0543 - val_loss: 4.3782 - val_accuracy: 0.0962\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.3915 - accuracy: 0.0617 - val_loss: 4.3258 - val_accuracy: 0.1073\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.3359 - accuracy: 0.0728 - val_loss: 4.2655 - val_accuracy: 0.1232\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.2762 - accuracy: 0.0755 - val_loss: 4.1995 - val_accuracy: 0.1257\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.2091 - accuracy: 0.0878 - val_loss: 4.1302 - val_accuracy: 0.1366\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 4.1456 - accuracy: 0.0923 - val_loss: 4.0597 - val_accuracy: 0.1432\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.0860 - accuracy: 0.0969 - val_loss: 3.9876 - val_accuracy: 0.1506\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 4.0186 - accuracy: 0.0996 - val_loss: 3.9123 - val_accuracy: 0.1571\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.9506 - accuracy: 0.1039 - val_loss: 3.8390 - val_accuracy: 0.1605\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.8748 - accuracy: 0.1131 - val_loss: 3.7624 - val_accuracy: 0.1678\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.8151 - accuracy: 0.1125 - val_loss: 3.6855 - val_accuracy: 0.1794\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.7422 - accuracy: 0.1199 - val_loss: 3.6060 - val_accuracy: 0.1929\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.6701 - accuracy: 0.1226 - val_loss: 3.5290 - val_accuracy: 0.2056\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.5994 - accuracy: 0.1271 - val_loss: 3.4467 - val_accuracy: 0.2184\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.5364 - accuracy: 0.1334 - val_loss: 3.3664 - val_accuracy: 0.2287\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.4596 - accuracy: 0.1376 - val_loss: 3.2907 - val_accuracy: 0.2424\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.4020 - accuracy: 0.1452 - val_loss: 3.2153 - val_accuracy: 0.2549\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.3236 - accuracy: 0.1553 - val_loss: 3.1399 - val_accuracy: 0.2694\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.2616 - accuracy: 0.1616 - val_loss: 3.0691 - val_accuracy: 0.2897\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 3.1941 - accuracy: 0.1708 - val_loss: 2.9950 - val_accuracy: 0.2995\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.1279 - accuracy: 0.1814 - val_loss: 2.9250 - val_accuracy: 0.3096\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.0688 - accuracy: 0.1912 - val_loss: 2.8573 - val_accuracy: 0.3320\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.0054 - accuracy: 0.2087 - val_loss: 2.7880 - val_accuracy: 0.3467\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.9383 - accuracy: 0.2176 - val_loss: 2.7177 - val_accuracy: 0.3651\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.8874 - accuracy: 0.2251 - val_loss: 2.6536 - val_accuracy: 0.3735\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 2.6484 - accuracy: 0.3896\n",
            "70.0 0.6115101976587989 0.6454799241681002 0.65 0.5012394874644148 0.2 0.4995210422727908\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f97999a6310> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e4bc990> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97990b1250> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792822b50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 190ms/step - loss: 4.5980 - accuracy: 0.0269 - val_loss: 4.2191 - val_accuracy: 0.1390\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 3.8933 - accuracy: 0.1017 - val_loss: 3.5068 - val_accuracy: 0.2692\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 3.3463 - accuracy: 0.1604 - val_loss: 2.6791 - val_accuracy: 0.3991\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.8741 - accuracy: 0.2355 - val_loss: 2.2013 - val_accuracy: 0.4767\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 2.5042 - accuracy: 0.3110 - val_loss: 1.8678 - val_accuracy: 0.5479\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 184ms/step - loss: 2.1705 - accuracy: 0.3954 - val_loss: 1.6434 - val_accuracy: 0.5771\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.9177 - accuracy: 0.4514 - val_loss: 1.4843 - val_accuracy: 0.5911\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 184ms/step - loss: 1.7268 - accuracy: 0.5000 - val_loss: 1.3707 - val_accuracy: 0.6100\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.5820 - accuracy: 0.5366 - val_loss: 1.2766 - val_accuracy: 0.6204\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.4386 - accuracy: 0.5753 - val_loss: 1.2091 - val_accuracy: 0.6380\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.3376 - accuracy: 0.5956 - val_loss: 1.1477 - val_accuracy: 0.6450\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.2605 - accuracy: 0.6141 - val_loss: 1.0990 - val_accuracy: 0.6551\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 1.1861 - accuracy: 0.6384 - val_loss: 1.0632 - val_accuracy: 0.6659\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 1.1213 - accuracy: 0.6588 - val_loss: 1.0285 - val_accuracy: 0.6704\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 1.0596 - accuracy: 0.6718 - val_loss: 0.9955 - val_accuracy: 0.6849\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 1.0147 - accuracy: 0.6839 - val_loss: 0.9755 - val_accuracy: 0.6877\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.9745 - accuracy: 0.6979 - val_loss: 0.9526 - val_accuracy: 0.6938\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.9219 - accuracy: 0.7092 - val_loss: 0.9338 - val_accuracy: 0.6987\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.8874 - accuracy: 0.7226 - val_loss: 0.9197 - val_accuracy: 0.6981\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.8560 - accuracy: 0.7324 - val_loss: 0.9072 - val_accuracy: 0.6982\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.8161 - accuracy: 0.7434 - val_loss: 0.8890 - val_accuracy: 0.7062\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.7787 - accuracy: 0.7595 - val_loss: 0.8803 - val_accuracy: 0.7147\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.7474 - accuracy: 0.7645 - val_loss: 0.8656 - val_accuracy: 0.7160\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.7614 - accuracy: 0.7655 - val_loss: 0.8589 - val_accuracy: 0.7178\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.7134 - accuracy: 0.7716 - val_loss: 0.8458 - val_accuracy: 0.7251\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.6699 - accuracy: 0.7856 - val_loss: 0.8358 - val_accuracy: 0.7280\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.6562 - accuracy: 0.7913 - val_loss: 0.8249 - val_accuracy: 0.7316\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.6349 - accuracy: 0.7990 - val_loss: 0.8200 - val_accuracy: 0.7306\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.6132 - accuracy: 0.8034 - val_loss: 0.8106 - val_accuracy: 0.7367\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 182ms/step - loss: 0.5936 - accuracy: 0.8099 - val_loss: 0.8087 - val_accuracy: 0.7407\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 0.8104 - accuracy: 0.7468\n",
            "62.00056885630025 0.9466615837284094 0.7229376970544241 0.5406653664773303 0.41813869997778835 0.19620285453616024 0.5044246685806668\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b7d5f50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99d0399710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f979375f250> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf722050> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 183ms/step - loss: 1.3975 - accuracy: 0.6469 - val_loss: 1.0987 - val_accuracy: 0.7881\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.1020 - accuracy: 0.9721 - val_loss: 1.2302 - val_accuracy: 0.7803\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0714 - accuracy: 0.9810 - val_loss: 1.4042 - val_accuracy: 0.7954\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0366 - accuracy: 0.9904 - val_loss: 1.1413 - val_accuracy: 0.8236\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 1.1837 - val_accuracy: 0.8125\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0489 - accuracy: 0.9882 - val_loss: 1.4799 - val_accuracy: 0.7948\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 1.0811 - val_accuracy: 0.8211\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 1.1172 - val_accuracy: 0.8228\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.2314 - accuracy: 0.8141\n",
            "64.16916098793372 0.3839715661216409 1.2626560063068566 0.6119447566578403 0.5763332490333968 0.2 0.668839130587141\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f4f00d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978dcc8390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f4d7e50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dc8bdd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 181ms/step - loss: 1.4633 - accuracy: 0.6268 - val_loss: 1.0602 - val_accuracy: 0.7856\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0944 - accuracy: 0.9726 - val_loss: 1.0234 - val_accuracy: 0.7969\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 1.2215 - val_accuracy: 0.7900\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 1.0695 - val_accuracy: 0.8112\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 1.0259 - val_accuracy: 0.8143\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0287 - accuracy: 0.9932 - val_loss: 1.1226 - val_accuracy: 0.8040\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 1.1445 - val_accuracy: 0.8185\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 1.1200 - val_accuracy: 0.8197\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 1.0679 - val_accuracy: 0.8094\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 1.1268 - val_accuracy: 0.8283\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 1.0963 - val_accuracy: 0.8268\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.1532 - val_accuracy: 0.8389\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 1.3617 - val_accuracy: 0.8153\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 1.0967 - val_accuracy: 0.8289\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 1.0545 - val_accuracy: 0.8317\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 1.1521 - val_accuracy: 0.8260\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.2615 - accuracy: 0.8254\n",
            "Model N. 8   Accuracy =  0.825439453125 Loss =  1.2615426778793335 parameters =  [64.16916099  0.38397157  1.26265601  0.61194476  0.57633325  0.2\n",
            "  0.66883913  2.82005717] \n",
            "\n",
            "66.07894393217342 0.38415488750032034 0.9507037619492764 0.65 0.65 0.19103357595026035 0.814035784014107\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f02cbd0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9798f6e4d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798f9dc50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e44d710> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 184ms/step - loss: 1.5326 - accuracy: 0.6120 - val_loss: 1.1206 - val_accuracy: 0.7920\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0969 - accuracy: 0.9746 - val_loss: 1.2016 - val_accuracy: 0.8008\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0644 - accuracy: 0.9840 - val_loss: 1.3552 - val_accuracy: 0.7910\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0455 - accuracy: 0.9884 - val_loss: 1.0200 - val_accuracy: 0.8122\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 1.2080 - val_accuracy: 0.8013\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0294 - accuracy: 0.9935 - val_loss: 1.2867 - val_accuracy: 0.7993\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 1.1138 - val_accuracy: 0.8159\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 1.1534 - val_accuracy: 0.8104\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 1.1803 - val_accuracy: 0.8180\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.1482 - val_accuracy: 0.8273\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 1.2951 - val_accuracy: 0.8270\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 1.1842 - val_accuracy: 0.8180\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 1.1513 - val_accuracy: 0.8271\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 1.3314 - val_accuracy: 0.8159\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3631 - accuracy: 0.8171\n",
            "57.16091777178253 0.35433859695831044 1.1070310833432488 0.566360379589134 0.533732105297439 0.19888187219116216 0.5072475297350127\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b7c9110> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f979280d950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d99ed50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d062d10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 173ms/step - loss: 1.4625 - accuracy: 0.6304 - val_loss: 1.0139 - val_accuracy: 0.7894\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0750 - accuracy: 0.9773 - val_loss: 1.1657 - val_accuracy: 0.7957\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0509 - accuracy: 0.9858 - val_loss: 1.1793 - val_accuracy: 0.7882\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 1.2307 - val_accuracy: 0.7801\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0362 - accuracy: 0.9906 - val_loss: 1.2858 - val_accuracy: 0.7873\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0193 - accuracy: 0.9956 - val_loss: 1.1404 - val_accuracy: 0.8084\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 1.0346 - val_accuracy: 0.8156\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 1.2444 - val_accuracy: 0.8049\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0325 - accuracy: 0.9928 - val_loss: 1.1464 - val_accuracy: 0.8122\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 1.1329 - val_accuracy: 0.8088\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 1.2411 - val_accuracy: 0.7904\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3055 - accuracy: 0.7971\n",
            "67.59917502849784 0.38028030380085387 1.2078106490841791 0.5231385370320096 0.5681171526388 0.16834127649210512 0.6535622327919529\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792c727d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978f1c8690> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99592137d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf6a5050> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 185ms/step - loss: 1.6118 - accuracy: 0.5997 - val_loss: 0.8680 - val_accuracy: 0.8031\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 1.1229 - val_accuracy: 0.7839\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 1.1153 - val_accuracy: 0.7821\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0357 - accuracy: 0.9898 - val_loss: 1.0610 - val_accuracy: 0.8075\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 1.1176 - val_accuracy: 0.7892\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 1.0650 - val_accuracy: 0.8029\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 1.0258 - val_accuracy: 0.8156\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.0230 - val_accuracy: 0.8322\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.0952 - val_accuracy: 0.8118\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0223 - accuracy: 0.9948 - val_loss: 1.0944 - val_accuracy: 0.8149\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 1.1780 - val_accuracy: 0.8136\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 1.2352 - val_accuracy: 0.8008\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.1303 - accuracy: 0.8177\n",
            "52.69192144949692 0.7163839616472103 0.5092598424975767 0.65 0.5971170647139932 0.2 0.7739312347874358\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e2fc8d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b838d90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792aacdd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791707150> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 171ms/step - loss: 1.6209 - accuracy: 0.6107 - val_loss: 1.2508 - val_accuracy: 0.7741\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.1406 - accuracy: 0.9618 - val_loss: 1.4121 - val_accuracy: 0.7729\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0726 - accuracy: 0.9810 - val_loss: 1.4292 - val_accuracy: 0.7933\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0533 - accuracy: 0.9858 - val_loss: 1.1451 - val_accuracy: 0.8049\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0394 - accuracy: 0.9903 - val_loss: 1.1564 - val_accuracy: 0.8125\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0286 - accuracy: 0.9931 - val_loss: 1.1960 - val_accuracy: 0.7931\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0510 - accuracy: 0.9890 - val_loss: 1.2883 - val_accuracy: 0.7977\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0312 - accuracy: 0.9930 - val_loss: 1.2473 - val_accuracy: 0.8140\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 1.4128 - val_accuracy: 0.8040\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 1.2209 - val_accuracy: 0.8145\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 1.2858 - val_accuracy: 0.8045\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0288 - accuracy: 0.9934 - val_loss: 1.1916 - val_accuracy: 0.8146\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 1.4280 - val_accuracy: 0.7961\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 1.4773 - val_accuracy: 0.8200\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 1.5744 - val_accuracy: 0.8135\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 1.3758 - val_accuracy: 0.8171\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0238 - accuracy: 0.9965 - val_loss: 1.3993 - val_accuracy: 0.8145\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0265 - accuracy: 0.9948 - val_loss: 1.3328 - val_accuracy: 0.8092\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.2114 - accuracy: 0.8341\n",
            "Model N. 9   Accuracy =  0.8341064453125 Loss =  1.2114187479019165 parameters =  [52.69192145  0.71638396  0.50925984  0.65        0.59711706  0.2\n",
            "  0.77393123  2.39469069] \n",
            "\n",
            "32.57422492664468 0.7024165447261315 0.4592549769191534 0.65 0.5949571955714841 0.2 0.5408093879138057\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99bf6ff290> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792b67490> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 26s 79ms/step - loss: 1.0927 - accuracy: 0.7117 - val_loss: 1.2090 - val_accuracy: 0.7525\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 20s 75ms/step - loss: 0.0977 - accuracy: 0.9681 - val_loss: 1.1643 - val_accuracy: 0.7939\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 20s 75ms/step - loss: 0.0504 - accuracy: 0.9853 - val_loss: 1.1945 - val_accuracy: 0.7894\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 20s 75ms/step - loss: 0.0472 - accuracy: 0.9864 - val_loss: 1.1955 - val_accuracy: 0.7902\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 20s 76ms/step - loss: 0.0391 - accuracy: 0.9904 - val_loss: 1.2222 - val_accuracy: 0.7856\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 20s 76ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 1.3442 - val_accuracy: 0.7922\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.3980 - accuracy: 0.7877\n",
            "57.6128849807835 0.9707874039242187 0.0 0.593037649541315 0.5446196965063789 0.15652734481595373 0.8904261918647739\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e4a0890> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b7e6c50> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 31s 93ms/step - loss: 0.9805 - accuracy: 0.7292 - val_loss: 1.0114 - val_accuracy: 0.7859\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 1.3778 - val_accuracy: 0.7640\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0491 - accuracy: 0.9849 - val_loss: 1.1640 - val_accuracy: 0.7926\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 1.1421 - val_accuracy: 0.8042\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0261 - accuracy: 0.9934 - val_loss: 1.1757 - val_accuracy: 0.8034\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 1.1010 - val_accuracy: 0.8055\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.3017 - val_accuracy: 0.8039\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 1.0077 - val_accuracy: 0.8195\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 1.0694 - val_accuracy: 0.8306\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 1.1259 - val_accuracy: 0.8087\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 1.0129 - val_accuracy: 0.8203\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 1.2737 - val_accuracy: 0.8030\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 24s 90ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 1.2751 - val_accuracy: 0.8073\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.2491 - accuracy: 0.8170\n",
            "70.0 0.4922084677264238 0.3611861930835991 0.65 0.65 0.19026202149486357 0.46658555704192767\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f3b13d0> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e004e50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 187ms/step - loss: 4.6046 - accuracy: 0.0150 - val_loss: 4.5350 - val_accuracy: 0.0251\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.4436 - accuracy: 0.0442 - val_loss: 4.4114 - val_accuracy: 0.0718\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.2694 - accuracy: 0.0871 - val_loss: 4.2175 - val_accuracy: 0.1193\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 4.0948 - accuracy: 0.1387 - val_loss: 4.0191 - val_accuracy: 0.1577\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.9273 - accuracy: 0.1785 - val_loss: 3.8296 - val_accuracy: 0.2033\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.7528 - accuracy: 0.2224 - val_loss: 3.6423 - val_accuracy: 0.2414\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.5850 - accuracy: 0.2588 - val_loss: 3.4610 - val_accuracy: 0.2808\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.4173 - accuracy: 0.2900 - val_loss: 3.2778 - val_accuracy: 0.3112\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.2543 - accuracy: 0.3236 - val_loss: 3.1072 - val_accuracy: 0.3351\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 3.0976 - accuracy: 0.3588 - val_loss: 2.9476 - val_accuracy: 0.3584\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.9441 - accuracy: 0.3810 - val_loss: 2.8079 - val_accuracy: 0.3730\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.8023 - accuracy: 0.4103 - val_loss: 2.6697 - val_accuracy: 0.3976\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.6588 - accuracy: 0.4395 - val_loss: 2.5525 - val_accuracy: 0.4248\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.5478 - accuracy: 0.4582 - val_loss: 2.4392 - val_accuracy: 0.4489\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.4258 - accuracy: 0.4767 - val_loss: 2.3319 - val_accuracy: 0.4777\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.3042 - accuracy: 0.5054 - val_loss: 2.2279 - val_accuracy: 0.4967\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.2052 - accuracy: 0.5240 - val_loss: 2.1419 - val_accuracy: 0.5169\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 2.1028 - accuracy: 0.5468 - val_loss: 2.0487 - val_accuracy: 0.5306\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.9971 - accuracy: 0.5723 - val_loss: 1.9652 - val_accuracy: 0.5513\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.9040 - accuracy: 0.5909 - val_loss: 1.8757 - val_accuracy: 0.5719\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.8093 - accuracy: 0.6043 - val_loss: 1.7964 - val_accuracy: 0.5838\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.7270 - accuracy: 0.6156 - val_loss: 1.7204 - val_accuracy: 0.5936\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.6407 - accuracy: 0.6310 - val_loss: 1.6519 - val_accuracy: 0.6042\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.5649 - accuracy: 0.6410 - val_loss: 1.5929 - val_accuracy: 0.6048\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.4993 - accuracy: 0.6443 - val_loss: 1.5312 - val_accuracy: 0.6102\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.4284 - accuracy: 0.6561 - val_loss: 1.4766 - val_accuracy: 0.6180\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.3671 - accuracy: 0.6701 - val_loss: 1.4308 - val_accuracy: 0.6217\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 1.3106 - accuracy: 0.6762 - val_loss: 1.3826 - val_accuracy: 0.6302\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.2574 - accuracy: 0.6895 - val_loss: 1.3414 - val_accuracy: 0.6406\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 1.2061 - accuracy: 0.7024 - val_loss: 1.3024 - val_accuracy: 0.6476\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.3028 - accuracy: 0.6703\n",
            "60.58269986632163 0.7877632242865991 0.5266788133990263 0.65 0.5802430003388632 0.2 0.704125618481531\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99d039d310> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791a35310> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f2707d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f577e10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 179ms/step - loss: 1.5688 - accuracy: 0.6122 - val_loss: 1.3122 - val_accuracy: 0.7832\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.1035 - accuracy: 0.9733 - val_loss: 1.7115 - val_accuracy: 0.7726\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0753 - accuracy: 0.9821 - val_loss: 1.5544 - val_accuracy: 0.7866\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0635 - accuracy: 0.9857 - val_loss: 1.0821 - val_accuracy: 0.8057\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0418 - accuracy: 0.9908 - val_loss: 1.3679 - val_accuracy: 0.8021\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0260 - accuracy: 0.9934 - val_loss: 1.3078 - val_accuracy: 0.8084\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 1.2734 - val_accuracy: 0.8079\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0317 - accuracy: 0.9931 - val_loss: 1.3039 - val_accuracy: 0.8140\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 1.3804 - val_accuracy: 0.8117\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 1.3978 - val_accuracy: 0.8009\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 1.3265 - val_accuracy: 0.8200\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 1.4281 - val_accuracy: 0.8122\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0264 - accuracy: 0.9940 - val_loss: 1.3126 - val_accuracy: 0.8037\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 1.6077 - val_accuracy: 0.8076\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0217 - accuracy: 0.9962 - val_loss: 1.2934 - val_accuracy: 0.8171\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.5607 - accuracy: 0.8193\n",
            "54.75224110488053 0.9186047918706477 0.6392673599414992 0.65 0.5716086194442094 0.2 0.6786922477698352\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dd65f90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9799215190> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97991262d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9799d3cbd0> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 30s 94ms/step - loss: 1.6175 - accuracy: 0.5981 - val_loss: 1.1113 - val_accuracy: 0.7478\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.1937 - accuracy: 0.9483 - val_loss: 0.8984 - val_accuracy: 0.7957\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0877 - accuracy: 0.9773 - val_loss: 1.2151 - val_accuracy: 0.7872\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0769 - accuracy: 0.9806 - val_loss: 1.1789 - val_accuracy: 0.7979\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 24s 92ms/step - loss: 0.0492 - accuracy: 0.9884 - val_loss: 1.5051 - val_accuracy: 0.7856\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0570 - accuracy: 0.9861 - val_loss: 1.2159 - val_accuracy: 0.8042\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0400 - accuracy: 0.9902 - val_loss: 1.7637 - val_accuracy: 0.7819\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0569 - accuracy: 0.9884 - val_loss: 1.1515 - val_accuracy: 0.8073\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 1.4232 - val_accuracy: 0.7852\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0366 - accuracy: 0.9914 - val_loss: 1.3516 - val_accuracy: 0.8097\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0367 - accuracy: 0.9916 - val_loss: 1.5655 - val_accuracy: 0.8132\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0354 - accuracy: 0.9927 - val_loss: 1.3505 - val_accuracy: 0.7852\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0341 - accuracy: 0.9933 - val_loss: 1.4266 - val_accuracy: 0.8155\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0297 - accuracy: 0.9932 - val_loss: 1.5291 - val_accuracy: 0.8000\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0377 - accuracy: 0.9911 - val_loss: 1.1451 - val_accuracy: 0.8165\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 1.2959 - val_accuracy: 0.8200\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 1.3748 - val_accuracy: 0.8172\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0335 - accuracy: 0.9935 - val_loss: 1.4070 - val_accuracy: 0.7952\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 1.2907 - val_accuracy: 0.8143\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 24s 91ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 1.2440 - val_accuracy: 0.8117\n",
            "64/64 [==============================] - 4s 41ms/step - loss: 1.1881 - accuracy: 0.8186\n",
            "60.34704265363743 0.4308931405320485 0.26994076681218093 0.6114858853011763 0.5499096651613075 0.2 0.7266933027713642\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798ea6d10> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9798fba850> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 1.1450 - accuracy: 0.7211 - val_loss: 1.0193 - val_accuracy: 0.7941\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.9816 - val_accuracy: 0.7910\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0535 - accuracy: 0.9837 - val_loss: 1.0124 - val_accuracy: 0.7912\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.9927 - val_accuracy: 0.8003\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 1.0082 - val_accuracy: 0.8057\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 1.1163 - val_accuracy: 0.8052\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.2170 - val_accuracy: 0.7938\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 1.1741 - val_accuracy: 0.8166\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 1.0295 - val_accuracy: 0.8218\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 1.0822 - val_accuracy: 0.8140\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.9514 - val_accuracy: 0.8201\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 1.0407 - val_accuracy: 0.8289\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 1.0756 - val_accuracy: 0.8112\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 1.0988 - val_accuracy: 0.8097\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 1.0798 - val_accuracy: 0.8167\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 1.2129 - val_accuracy: 0.8084\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.2121 - accuracy: 0.8210\n",
            "53.86532606106903 0.6751424648318418 0.0814682863046915 0.65 0.629442673158769 0.19717003069538505 0.9366060662434613\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792827f90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791588990> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 172ms/step - loss: 1.0066 - accuracy: 0.7292 - val_loss: 1.4201 - val_accuracy: 0.7467\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 1.1670 - val_accuracy: 0.7938\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0583 - accuracy: 0.9835 - val_loss: 1.1115 - val_accuracy: 0.7856\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 1.1295 - val_accuracy: 0.8079\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 1.2226 - val_accuracy: 0.8022\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0207 - accuracy: 0.9948 - val_loss: 1.3129 - val_accuracy: 0.7967\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0374 - accuracy: 0.9921 - val_loss: 1.4192 - val_accuracy: 0.7944\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 1.1983 - val_accuracy: 0.8078\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.1836 - accuracy: 0.8118\n",
            "70.0 0.4076357090591196 0.8073117306215527 0.5255450158701123 0.5806280750850992 0.2 0.8634217331887188\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e1a5810> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e18a090> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f66f490> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e35ff90> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 189ms/step - loss: 1.4145 - accuracy: 0.6384 - val_loss: 1.2136 - val_accuracy: 0.7834\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0836 - accuracy: 0.9754 - val_loss: 1.0186 - val_accuracy: 0.8000\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.9864 - val_accuracy: 0.8208\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.9054 - val_accuracy: 0.8312\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 1.2265 - val_accuracy: 0.8096\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0341 - accuracy: 0.9910 - val_loss: 1.2469 - val_accuracy: 0.8096\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0317 - accuracy: 0.9919 - val_loss: 1.0188 - val_accuracy: 0.8213\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 183ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.0633 - val_accuracy: 0.8245\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.1288 - accuracy: 0.8303\n",
            "59.410711261005616 0.5914568373132825 1.3407149657887936 0.6285283041038239 0.5369816920334294 0.2 0.8466697367300458\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e1c2d90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798c66210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978cee4610> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97916c9cd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 180ms/step - loss: 1.6247 - accuracy: 0.6070 - val_loss: 1.2672 - val_accuracy: 0.7842\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.1022 - accuracy: 0.9711 - val_loss: 1.3133 - val_accuracy: 0.7783\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0698 - accuracy: 0.9814 - val_loss: 1.3902 - val_accuracy: 0.7782\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 1.3620 - val_accuracy: 0.8022\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0242 - accuracy: 0.9945 - val_loss: 1.5261 - val_accuracy: 0.7777\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 1.2035 - val_accuracy: 0.8016\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 1.1080 - val_accuracy: 0.8102\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 1.1590 - val_accuracy: 0.8135\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 1.7999 - val_accuracy: 0.7783\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0266 - accuracy: 0.9941 - val_loss: 1.4079 - val_accuracy: 0.8078\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0269 - accuracy: 0.9944 - val_loss: 1.4363 - val_accuracy: 0.8088\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0228 - accuracy: 0.9954 - val_loss: 1.3412 - val_accuracy: 0.8210\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 1.3052 - val_accuracy: 0.8029\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 1.3081 - val_accuracy: 0.8236\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 1.4310 - val_accuracy: 0.8110\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0233 - accuracy: 0.9952 - val_loss: 1.4065 - val_accuracy: 0.8125\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 1.2452 - val_accuracy: 0.8151\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 1.0711 - val_accuracy: 0.8343\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 1.1599 - val_accuracy: 0.8140\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 1.1077 - val_accuracy: 0.8328\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 1.5688 - val_accuracy: 0.8029\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 1.2872 - val_accuracy: 0.8205\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.4022 - accuracy: 0.8257\n",
            "55.57575629655044 0.606757268352113 0.7638897637463651 0.65 0.65 0.2 0.7548593502116447\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f0655d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791878210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791084fd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97910846d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 1.6533 - accuracy: 0.5962 - val_loss: 1.2150 - val_accuracy: 0.7651\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1221 - accuracy: 0.9662 - val_loss: 1.1022 - val_accuracy: 0.8062\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0665 - accuracy: 0.9833 - val_loss: 1.1908 - val_accuracy: 0.7936\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0482 - accuracy: 0.9886 - val_loss: 1.1884 - val_accuracy: 0.7931\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0527 - accuracy: 0.9876 - val_loss: 1.6553 - val_accuracy: 0.7747\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0416 - accuracy: 0.9906 - val_loss: 1.0272 - val_accuracy: 0.8118\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 1.2787 - val_accuracy: 0.8200\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 1.3554 - val_accuracy: 0.7933\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0269 - accuracy: 0.9934 - val_loss: 1.1072 - val_accuracy: 0.8244\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 1.2109 - val_accuracy: 0.8231\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 1.2509 - val_accuracy: 0.8239\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 1.3975 - val_accuracy: 0.8044\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 1.4851 - val_accuracy: 0.7909\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.5035 - accuracy: 0.7941\n",
            "29.689316102973432 0.9329537481622237 0.5253598790299511 0.65 0.65 0.2 0.8017200738020693\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f320d10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e5754d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d9ae250> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97990cbf10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 25s 146ms/step - loss: 1.9091 - accuracy: 0.5555 - val_loss: 0.9545 - val_accuracy: 0.7819\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 18s 139ms/step - loss: 0.1163 - accuracy: 0.9631 - val_loss: 1.5353 - val_accuracy: 0.7624\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 19s 141ms/step - loss: 0.0627 - accuracy: 0.9834 - val_loss: 1.4001 - val_accuracy: 0.7756\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 18s 140ms/step - loss: 0.0369 - accuracy: 0.9911 - val_loss: 1.3858 - val_accuracy: 0.8032\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 18s 139ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 1.3986 - val_accuracy: 0.7923\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 18s 139ms/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 1.5792 - val_accuracy: 0.7822\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 18s 140ms/step - loss: 0.0377 - accuracy: 0.9903 - val_loss: 1.2543 - val_accuracy: 0.8035\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 18s 140ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 1.9429 - val_accuracy: 0.7884\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 18s 140ms/step - loss: 0.0447 - accuracy: 0.9906 - val_loss: 1.6062 - val_accuracy: 0.7949\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 18s 139ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 1.3844 - val_accuracy: 0.7917\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 18s 140ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 1.4607 - val_accuracy: 0.7959\n",
            "32/32 [==============================] - 4s 82ms/step - loss: 1.4810 - accuracy: 0.7963\n",
            "46.641311766037916 0.9925647830447136 0.0 0.6392816773521758 0.65 0.2 0.7855958620422886\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798edb710> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791860a50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 163ms/step - loss: 1.0249 - accuracy: 0.7245 - val_loss: 1.2735 - val_accuracy: 0.7604\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 1.3481 - val_accuracy: 0.7588\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 1.2260 - val_accuracy: 0.7979\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 1.2940 - val_accuracy: 0.7834\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 1.3503 - val_accuracy: 0.7949\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 1.4474 - val_accuracy: 0.7873\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 1.5014 - val_accuracy: 0.7952\n",
            "32/32 [==============================] - 4s 82ms/step - loss: 1.4161 - accuracy: 0.7882\n",
            "55.91691911271067 0.6791406194869296 0.4699276165237408 0.65 0.624981065901572 0.19213988904983648 0.8381689588892787\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799640350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bf6f2b10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 173ms/step - loss: 1.0053 - accuracy: 0.7267 - val_loss: 1.3806 - val_accuracy: 0.7599\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0685 - accuracy: 0.9793 - val_loss: 1.2526 - val_accuracy: 0.7899\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0497 - accuracy: 0.9861 - val_loss: 1.1379 - val_accuracy: 0.7985\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 1.2243 - val_accuracy: 0.7941\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 1.3066 - val_accuracy: 0.7979\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 1.4102 - val_accuracy: 0.7852\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0244 - accuracy: 0.9945 - val_loss: 1.1497 - val_accuracy: 0.8109\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 1.2545 - val_accuracy: 0.8081\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 1.1914 - val_accuracy: 0.8136\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 1.1133 - val_accuracy: 0.8066\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 1.1654 - val_accuracy: 0.8066\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 1.2490 - val_accuracy: 0.8158\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 1.2131 - val_accuracy: 0.8184\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.2736 - val_accuracy: 0.8055\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 1.2802 - val_accuracy: 0.7972\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.2945 - val_accuracy: 0.8115\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 1.8098 - val_accuracy: 0.7889\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.5304 - accuracy: 0.8127\n",
            "53.4514696017394 0.853450878293418 0.4588087352775232 0.65 0.6309319910479079 0.2 0.8189206975057048\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e44df50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b972710> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 169ms/step - loss: 1.0924 - accuracy: 0.7112 - val_loss: 1.0283 - val_accuracy: 0.7824\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 1.0771 - val_accuracy: 0.7874\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 1.1661 - val_accuracy: 0.7957\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 1.2155 - val_accuracy: 0.7884\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0395 - accuracy: 0.9904 - val_loss: 1.1040 - val_accuracy: 0.8040\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 1.1303 - val_accuracy: 0.8125\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 1.2226 - val_accuracy: 0.8143\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.3195 - val_accuracy: 0.8070\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 1.3420 - val_accuracy: 0.7904\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 1.4764 - val_accuracy: 0.7995\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0363 - accuracy: 0.9914 - val_loss: 1.2982 - val_accuracy: 0.8135\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.3232 - accuracy: 0.8209\n",
            "49.661590767053944 0.79556905446153 0.5666704129331921 0.65 0.65 0.2 0.7752889586107589\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d30ecd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9799056b10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799076810> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e34e910> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 30s 91ms/step - loss: 1.8550 - accuracy: 0.5686 - val_loss: 1.0184 - val_accuracy: 0.7560\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.1867 - accuracy: 0.9479 - val_loss: 1.0417 - val_accuracy: 0.7892\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0859 - accuracy: 0.9784 - val_loss: 1.2987 - val_accuracy: 0.7668\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0700 - accuracy: 0.9827 - val_loss: 1.1977 - val_accuracy: 0.7995\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 1.1870 - val_accuracy: 0.8050\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0703 - accuracy: 0.9842 - val_loss: 1.2399 - val_accuracy: 0.8073\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0515 - accuracy: 0.9884 - val_loss: 1.2365 - val_accuracy: 0.8005\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0440 - accuracy: 0.9898 - val_loss: 1.2679 - val_accuracy: 0.8065\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0403 - accuracy: 0.9910 - val_loss: 1.1893 - val_accuracy: 0.8117\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 1.5070 - val_accuracy: 0.8042\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0454 - accuracy: 0.9917 - val_loss: 1.2803 - val_accuracy: 0.8020\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0693 - accuracy: 0.9876 - val_loss: 1.6878 - val_accuracy: 0.8000\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0298 - accuracy: 0.9929 - val_loss: 1.1938 - val_accuracy: 0.8120\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0624 - accuracy: 0.9914 - val_loss: 1.5502 - val_accuracy: 0.8022\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0410 - accuracy: 0.9916 - val_loss: 1.6417 - val_accuracy: 0.8032\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0310 - accuracy: 0.9939 - val_loss: 1.4024 - val_accuracy: 0.8168\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0219 - accuracy: 0.9958 - val_loss: 1.4721 - val_accuracy: 0.8029\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 1.5091 - val_accuracy: 0.7916\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0231 - accuracy: 0.9961 - val_loss: 1.3228 - val_accuracy: 0.8221\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 1.4591 - val_accuracy: 0.8062\n",
            "Epoch 21/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 1.4127 - val_accuracy: 0.8208\n",
            "Epoch 22/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0269 - accuracy: 0.9957 - val_loss: 1.3558 - val_accuracy: 0.8140\n",
            "Epoch 23/30\n",
            "264/264 [==============================] - 23s 88ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 1.3997 - val_accuracy: 0.7949\n",
            "64/64 [==============================] - 4s 43ms/step - loss: 1.3176 - accuracy: 0.8214\n",
            "55.33418506881906 0.6824640700758555 0.4066616791681358 0.6213708805415327 0.5673859852769597 0.2 0.7325332005468856\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f06c390> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978cd9f0d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 174ms/step - loss: 1.1042 - accuracy: 0.7089 - val_loss: 1.3549 - val_accuracy: 0.7599\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0757 - accuracy: 0.9766 - val_loss: 1.1545 - val_accuracy: 0.7865\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0555 - accuracy: 0.9841 - val_loss: 1.1762 - val_accuracy: 0.7993\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 1.0806 - val_accuracy: 0.8105\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 1.1295 - val_accuracy: 0.8037\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 1.0978 - val_accuracy: 0.8050\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 1.2343 - val_accuracy: 0.8132\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.9903 - val_accuracy: 0.8291\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 1.0316 - val_accuracy: 0.8184\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 1.8403 - val_accuracy: 0.7770\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 1.0232 - val_accuracy: 0.8260\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 1.1228 - val_accuracy: 0.8229\n",
            "32/32 [==============================] - 4s 83ms/step - loss: 1.1421 - accuracy: 0.8199\n",
            "51.33126398664284 0.7988025480435724 0.0 0.65 0.601033038204879 0.2 0.9370681176533641\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978cd96c10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b7d9450> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 168ms/step - loss: 1.0724 - accuracy: 0.7092 - val_loss: 1.4596 - val_accuracy: 0.7565\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0721 - accuracy: 0.9783 - val_loss: 1.3569 - val_accuracy: 0.7646\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 1.3382 - val_accuracy: 0.7734\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 1.2326 - val_accuracy: 0.7912\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0323 - accuracy: 0.9919 - val_loss: 1.1708 - val_accuracy: 0.8099\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 1.1968 - val_accuracy: 0.7988\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 1.2177 - val_accuracy: 0.8026\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 1.3045 - val_accuracy: 0.8008\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 1.3643 - val_accuracy: 0.7855\n",
            "32/32 [==============================] - 4s 82ms/step - loss: 1.2476 - accuracy: 0.8042\n",
            "63.830998900920044 0.6711763583353075 0.5660694434834209 0.5338090379360098 0.6106534649643846 0.2 0.9898354951929313\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979179a750> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978dd7d810> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978def6d10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b6fce10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 185ms/step - loss: 1.5169 - accuracy: 0.6251 - val_loss: 1.2117 - val_accuracy: 0.7811\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0949 - accuracy: 0.9726 - val_loss: 1.4197 - val_accuracy: 0.8027\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0731 - accuracy: 0.9801 - val_loss: 1.1085 - val_accuracy: 0.8018\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0436 - accuracy: 0.9900 - val_loss: 1.2083 - val_accuracy: 0.8182\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 1.1382 - val_accuracy: 0.8241\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0375 - accuracy: 0.9904 - val_loss: 1.1422 - val_accuracy: 0.8055\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0326 - accuracy: 0.9928 - val_loss: 1.3648 - val_accuracy: 0.8011\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 1.2601 - val_accuracy: 0.8066\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0290 - accuracy: 0.9936 - val_loss: 1.2596 - val_accuracy: 0.8058\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.2406 - accuracy: 0.8190\n",
            "52.24644326926787 0.7203140863926795 1.0142800873576707 0.65 0.5530603079361741 0.2 0.9011371843660415\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d9c1610> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e041590> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97990bedd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99ce548150> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 172ms/step - loss: 1.8359 - accuracy: 0.5532 - val_loss: 1.2444 - val_accuracy: 0.7782\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.1037 - accuracy: 0.9718 - val_loss: 1.1800 - val_accuracy: 0.7801\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0681 - accuracy: 0.9830 - val_loss: 1.2891 - val_accuracy: 0.8040\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0494 - accuracy: 0.9888 - val_loss: 1.3328 - val_accuracy: 0.7922\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0332 - accuracy: 0.9919 - val_loss: 1.1839 - val_accuracy: 0.7998\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 1.4845 - val_accuracy: 0.7749\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 1.3537 - val_accuracy: 0.7962\n",
            "32/32 [==============================] - 4s 83ms/step - loss: 1.4188 - accuracy: 0.8112\n",
            "54.00819061188755 0.6781792113688248 0.605036067713157 0.65 0.65 0.2 0.7564906650687482\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978bd21b10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bcfd950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9793b26ed0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792d89b10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 173ms/step - loss: 1.7095 - accuracy: 0.5948 - val_loss: 1.2657 - val_accuracy: 0.7847\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.1281 - accuracy: 0.9650 - val_loss: 1.3363 - val_accuracy: 0.7679\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0712 - accuracy: 0.9808 - val_loss: 1.5599 - val_accuracy: 0.7716\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0716 - accuracy: 0.9828 - val_loss: 1.3124 - val_accuracy: 0.7936\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 1.2770 - val_accuracy: 0.8037\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0265 - accuracy: 0.9943 - val_loss: 1.2426 - val_accuracy: 0.8022\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0267 - accuracy: 0.9945 - val_loss: 1.4122 - val_accuracy: 0.7863\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 1.5288 - val_accuracy: 0.8066\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0284 - accuracy: 0.9934 - val_loss: 1.5429 - val_accuracy: 0.7959\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0277 - accuracy: 0.9949 - val_loss: 1.5095 - val_accuracy: 0.8172\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 1.5077 - val_accuracy: 0.8027\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0324 - accuracy: 0.9932 - val_loss: 1.2620 - val_accuracy: 0.7954\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 1.3764 - val_accuracy: 0.7983\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 1.6012 - val_accuracy: 0.7961\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.3596 - accuracy: 0.8180\n",
            "47.50971757690143 0.8325988335998036 0.553840301988125 0.65 0.65 0.2 0.9163962875236126\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e34b0d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9793a98390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978de0e310> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d7b2810> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 27s 164ms/step - loss: 1.7635 - accuracy: 0.5820 - val_loss: 1.3444 - val_accuracy: 0.7495\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.1280 - accuracy: 0.9664 - val_loss: 1.2333 - val_accuracy: 0.7822\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0678 - accuracy: 0.9838 - val_loss: 1.2246 - val_accuracy: 0.7974\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 1.1682 - val_accuracy: 0.7951\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0348 - accuracy: 0.9919 - val_loss: 1.2775 - val_accuracy: 0.7980\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0449 - accuracy: 0.9901 - val_loss: 1.3550 - val_accuracy: 0.8024\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0443 - accuracy: 0.9909 - val_loss: 1.2404 - val_accuracy: 0.8089\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 1.3671 - val_accuracy: 0.8027\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 1.4728 - val_accuracy: 0.7987\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0514 - accuracy: 0.9887 - val_loss: 1.4582 - val_accuracy: 0.8018\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0270 - accuracy: 0.9940 - val_loss: 1.2824 - val_accuracy: 0.8138\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 1.5225 - val_accuracy: 0.8022\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 1.5313 - val_accuracy: 0.7873\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 1.5402 - val_accuracy: 0.8031\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 1.5219 - val_accuracy: 0.7933\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.3718 - accuracy: 0.8118\n",
            "44.91414503662574 0.9489029023825549 0.41279049930437206 0.65 0.65 0.2 0.7547896881884277\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b2b6b50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e34a990> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 27s 162ms/step - loss: 1.0250 - accuracy: 0.7257 - val_loss: 1.1790 - val_accuracy: 0.7712\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 157ms/step - loss: 0.0767 - accuracy: 0.9763 - val_loss: 1.3766 - val_accuracy: 0.7754\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 1.3506 - val_accuracy: 0.7661\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 157ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 1.1574 - val_accuracy: 0.8022\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 1.2294 - val_accuracy: 0.7969\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0176 - accuracy: 0.9955 - val_loss: 1.0563 - val_accuracy: 0.8123\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.2678 - val_accuracy: 0.8014\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 1.3486 - val_accuracy: 0.7944\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 1.2110 - val_accuracy: 0.7882\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 156ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 1.1964 - val_accuracy: 0.8109\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.2357 - accuracy: 0.8187\n",
            "49.6066184936309 0.6652748774394645 0.7041781522904619 0.65 0.5940835603549269 0.1869103595634945 1.0\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f43d9d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d9a2dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9793ba57d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97991d2290> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 168ms/step - loss: 2.0083 - accuracy: 0.5365 - val_loss: 1.2495 - val_accuracy: 0.7723\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.1229 - accuracy: 0.9658 - val_loss: 1.3313 - val_accuracy: 0.7837\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 1.1682 - val_accuracy: 0.7826\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0553 - accuracy: 0.9867 - val_loss: 1.2687 - val_accuracy: 0.7925\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 1.2684 - val_accuracy: 0.8076\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0260 - accuracy: 0.9934 - val_loss: 1.2691 - val_accuracy: 0.8047\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 1.2652 - val_accuracy: 0.8099\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0314 - accuracy: 0.9930 - val_loss: 1.1151 - val_accuracy: 0.8135\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 1.3075 - val_accuracy: 0.7905\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 1.4220 - val_accuracy: 0.8001\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 1.3797 - val_accuracy: 0.8057\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 1.3063 - val_accuracy: 0.8130\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.3153 - accuracy: 0.8140\n",
            "49.581985268212506 0.8021579316963692 0.4486174245306136 0.65 0.6456038382352327 0.2 0.8332726682688838\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f7c3d50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b711610> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 165ms/step - loss: 1.0845 - accuracy: 0.7118 - val_loss: 1.5057 - val_accuracy: 0.7664\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0648 - accuracy: 0.9801 - val_loss: 1.1948 - val_accuracy: 0.7756\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 1.2619 - val_accuracy: 0.7965\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 1.3748 - val_accuracy: 0.7899\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 1.2087 - val_accuracy: 0.7962\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0389 - accuracy: 0.9896 - val_loss: 1.2251 - val_accuracy: 0.7985\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 1.0536 - val_accuracy: 0.8031\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 1.1827 - val_accuracy: 0.8055\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 1.4453 - val_accuracy: 0.8014\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 1.4390 - val_accuracy: 0.8075\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 1.2288 - val_accuracy: 0.8138\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0188 - accuracy: 0.9955 - val_loss: 1.2127 - val_accuracy: 0.8040\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 2.0138 - val_accuracy: 0.7939\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0294 - accuracy: 0.9934 - val_loss: 1.3425 - val_accuracy: 0.8042\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.2809 - val_accuracy: 0.8040\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.1877 - accuracy: 0.8162\n",
            "48.68149642775298 0.6684350020398511 0.49570787204387695 0.65 0.65 0.2 0.8235263734153915\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792aa60d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791558510> True\n",
            "Epoch 1/30\n",
            "264/264 [==============================] - 29s 89ms/step - loss: 1.0214 - accuracy: 0.7186 - val_loss: 1.1045 - val_accuracy: 0.7743\n",
            "Epoch 2/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.1182 - accuracy: 0.9634 - val_loss: 1.4387 - val_accuracy: 0.7763\n",
            "Epoch 3/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0683 - accuracy: 0.9806 - val_loss: 1.1001 - val_accuracy: 0.7984\n",
            "Epoch 4/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0522 - accuracy: 0.9868 - val_loss: 1.3676 - val_accuracy: 0.7783\n",
            "Epoch 5/30\n",
            "264/264 [==============================] - 23s 85ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 1.2301 - val_accuracy: 0.7877\n",
            "Epoch 6/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 1.2493 - val_accuracy: 0.7884\n",
            "Epoch 7/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0395 - accuracy: 0.9903 - val_loss: 1.3316 - val_accuracy: 0.7987\n",
            "Epoch 8/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 1.2748 - val_accuracy: 0.7904\n",
            "Epoch 9/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0346 - accuracy: 0.9918 - val_loss: 1.2343 - val_accuracy: 0.8132\n",
            "Epoch 10/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 1.3005 - val_accuracy: 0.7989\n",
            "Epoch 11/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 1.0771 - val_accuracy: 0.8163\n",
            "Epoch 12/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 1.3415 - val_accuracy: 0.8177\n",
            "Epoch 13/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 1.3091 - val_accuracy: 0.8115\n",
            "Epoch 14/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.9711 - val_accuracy: 0.8057\n",
            "Epoch 15/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 1.2151 - val_accuracy: 0.8215\n",
            "Epoch 16/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 1.2237 - val_accuracy: 0.8261\n",
            "Epoch 17/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 1.4248 - val_accuracy: 0.8068\n",
            "Epoch 18/30\n",
            "264/264 [==============================] - 23s 87ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 1.2348 - val_accuracy: 0.8032\n",
            "Epoch 19/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 1.3420 - val_accuracy: 0.8042\n",
            "Epoch 20/30\n",
            "264/264 [==============================] - 23s 86ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 1.2994 - val_accuracy: 0.8087\n",
            "64/64 [==============================] - 4s 42ms/step - loss: 1.3091 - accuracy: 0.8171\n",
            "53.35765319528605 0.7941254355650732 0.6742025483153427 0.632238005557482 0.583876555382057 0.2 0.743461648318499\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d873490> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e34e950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f14e910> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e1d02d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 171ms/step - loss: 1.8197 - accuracy: 0.5674 - val_loss: 1.0877 - val_accuracy: 0.7759\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.1176 - accuracy: 0.9681 - val_loss: 1.1238 - val_accuracy: 0.7848\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0705 - accuracy: 0.9810 - val_loss: 1.1216 - val_accuracy: 0.8045\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0504 - accuracy: 0.9884 - val_loss: 1.2238 - val_accuracy: 0.7952\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0467 - accuracy: 0.9884 - val_loss: 1.2035 - val_accuracy: 0.7902\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 1.3419 - val_accuracy: 0.8166\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0438 - accuracy: 0.9898 - val_loss: 1.3275 - val_accuracy: 0.8006\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0291 - accuracy: 0.9928 - val_loss: 1.4966 - val_accuracy: 0.7928\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 1.3187 - val_accuracy: 0.8039\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0266 - accuracy: 0.9940 - val_loss: 1.1439 - val_accuracy: 0.8255\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0197 - accuracy: 0.9966 - val_loss: 1.3765 - val_accuracy: 0.8167\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0260 - accuracy: 0.9946 - val_loss: 1.4370 - val_accuracy: 0.8110\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 1.3230 - val_accuracy: 0.8203\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 1.4551 - val_accuracy: 0.7995\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.4687 - accuracy: 0.8073\n",
            "54.2003693531221 0.6459561639843368 0.5464010556344577 0.65 0.6047755655123511 0.2 0.7646923985131078\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978bcd0310> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f531c50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978b3e8f90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f546d10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 173ms/step - loss: 1.9308 - accuracy: 0.5566 - val_loss: 1.1228 - val_accuracy: 0.7726\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.1186 - accuracy: 0.9682 - val_loss: 1.2569 - val_accuracy: 0.7933\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0915 - accuracy: 0.9767 - val_loss: 1.2740 - val_accuracy: 0.7918\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0446 - accuracy: 0.9882 - val_loss: 1.1164 - val_accuracy: 0.8034\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0505 - accuracy: 0.9873 - val_loss: 1.3838 - val_accuracy: 0.8052\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0286 - accuracy: 0.9925 - val_loss: 1.5200 - val_accuracy: 0.7964\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0313 - accuracy: 0.9927 - val_loss: 1.5118 - val_accuracy: 0.7868\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0350 - accuracy: 0.9930 - val_loss: 1.2816 - val_accuracy: 0.8260\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0278 - accuracy: 0.9940 - val_loss: 1.2803 - val_accuracy: 0.8027\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 1.1008 - val_accuracy: 0.8154\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.2555 - val_accuracy: 0.8143\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 1.2505 - val_accuracy: 0.8075\n",
            "32/32 [==============================] - 4s 83ms/step - loss: 1.3658 - accuracy: 0.8092\n",
            "54.61490167727381 0.809557335880075 0.48471963606705437 0.6248815473894312 0.6235561669510268 0.2 0.8931328763214413\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e16ae50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e1519d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 174ms/step - loss: 1.0338 - accuracy: 0.7204 - val_loss: 1.0848 - val_accuracy: 0.7900\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 1.3673 - val_accuracy: 0.7751\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0499 - accuracy: 0.9859 - val_loss: 1.0969 - val_accuracy: 0.7948\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 1.0029 - val_accuracy: 0.8110\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 1.1034 - val_accuracy: 0.8133\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.1458 - val_accuracy: 0.8001\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 1.1895 - val_accuracy: 0.8065\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 1.3612 - val_accuracy: 0.8022\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 1.2072 - val_accuracy: 0.8167\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 1.2310 - val_accuracy: 0.8105\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 1.2334 - val_accuracy: 0.8071\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 1.1251 - val_accuracy: 0.8153\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 1.1741 - val_accuracy: 0.8208\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 1.1434 - val_accuracy: 0.8135\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 1.2008 - val_accuracy: 0.8271\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 1.1691 - val_accuracy: 0.8184\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.2819 - val_accuracy: 0.8081\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 1.2564 - val_accuracy: 0.8193\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 1.3581 - val_accuracy: 0.8180\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.2952 - accuracy: 0.8179\n",
            "51.10281896692446 0.7658826268291146 0.507356762563635 0.65 0.5717577071958226 0.2 0.8472511888662593\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f99ce337450> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978da6f090> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bb07cd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f78e550> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 169ms/step - loss: 1.8102 - accuracy: 0.5639 - val_loss: 1.2435 - val_accuracy: 0.7651\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.1170 - accuracy: 0.9686 - val_loss: 1.3611 - val_accuracy: 0.7664\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0775 - accuracy: 0.9806 - val_loss: 1.2841 - val_accuracy: 0.7923\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0525 - accuracy: 0.9869 - val_loss: 1.3973 - val_accuracy: 0.7965\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0495 - accuracy: 0.9881 - val_loss: 1.2365 - val_accuracy: 0.7993\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 1.2642 - val_accuracy: 0.8009\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 1.4522 - val_accuracy: 0.7814\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 1.3525 - val_accuracy: 0.7980\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0401 - accuracy: 0.9911 - val_loss: 1.3589 - val_accuracy: 0.8008\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 1.2503 - val_accuracy: 0.8195\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 1.3002 - val_accuracy: 0.8159\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 1.3375 - val_accuracy: 0.8112\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.4320 - val_accuracy: 0.7979\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 1.3810 - val_accuracy: 0.7952\n",
            "32/32 [==============================] - 4s 84ms/step - loss: 1.4903 - accuracy: 0.7919\n",
            "52.93431522086161 0.7315627783661031 0.4065469897142789 0.65 0.65 0.2 0.7698973360681767\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e5b5d10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b8380d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 171ms/step - loss: 1.0645 - accuracy: 0.7129 - val_loss: 1.2068 - val_accuracy: 0.7695\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 1.4079 - val_accuracy: 0.7861\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0498 - accuracy: 0.9855 - val_loss: 1.3524 - val_accuracy: 0.7752\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0371 - accuracy: 0.9899 - val_loss: 1.2452 - val_accuracy: 0.7995\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 1.1557 - val_accuracy: 0.7948\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 1.1312 - val_accuracy: 0.8140\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 1.4312 - val_accuracy: 0.8055\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 1.2528 - val_accuracy: 0.7983\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 1.1097 - val_accuracy: 0.8166\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 1.4056 - val_accuracy: 0.7915\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 1.0954 - val_accuracy: 0.8151\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 1.2428 - val_accuracy: 0.7982\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 1.2362 - val_accuracy: 0.8190\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 1.0116 - val_accuracy: 0.8188\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 1.0628 - val_accuracy: 0.8231\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.3069 - val_accuracy: 0.8057\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 1.1823 - val_accuracy: 0.8254\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.2434 - val_accuracy: 0.8206\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 1.0668 - val_accuracy: 0.8231\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 1.1197 - val_accuracy: 0.8309\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 6.6458e-05 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.8312\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 2.0989e-05 - accuracy: 1.0000 - val_loss: 1.3069 - val_accuracy: 0.8330\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 6.7208e-06 - accuracy: 1.0000 - val_loss: 1.3103 - val_accuracy: 0.8337\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 5.8131e-06 - accuracy: 1.0000 - val_loss: 1.3384 - val_accuracy: 0.8324\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 6.8016e-06 - accuracy: 1.0000 - val_loss: 1.3783 - val_accuracy: 0.8288\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 3.0456e-06 - accuracy: 1.0000 - val_loss: 1.3553 - val_accuracy: 0.8309\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 3.0775e-06 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.8309\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.4285 - accuracy: 0.8313\n",
            "56.61727862765982 0.7128251158404963 0.5450160080565104 0.65 0.65 0.2 0.8567160077917957\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792c33e10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979182d290> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfc93cd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791484ed0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 1.7059 - accuracy: 0.5919 - val_loss: 1.0722 - val_accuracy: 0.7762\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1142 - accuracy: 0.9687 - val_loss: 1.1068 - val_accuracy: 0.8006\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0640 - accuracy: 0.9822 - val_loss: 1.2363 - val_accuracy: 0.7918\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0685 - accuracy: 0.9833 - val_loss: 1.3400 - val_accuracy: 0.7896\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 1.1521 - val_accuracy: 0.8083\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0331 - accuracy: 0.9916 - val_loss: 1.1639 - val_accuracy: 0.8195\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0275 - accuracy: 0.9945 - val_loss: 1.2640 - val_accuracy: 0.8006\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0316 - accuracy: 0.9922 - val_loss: 1.5742 - val_accuracy: 0.7868\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 1.2894 - val_accuracy: 0.8027\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0351 - accuracy: 0.9930 - val_loss: 1.2355 - val_accuracy: 0.8063\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.2980 - accuracy: 0.8082\n",
            "51.44808141726346 0.8502657600896433 0.7069049122791681 0.65 0.6077742790997783 0.2 0.7510070036421761\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792a8c350> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bfc876d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfc87950> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d01ef90> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 168ms/step - loss: 1.9096 - accuracy: 0.5575 - val_loss: 1.2692 - val_accuracy: 0.7764\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.1160 - accuracy: 0.9673 - val_loss: 1.3673 - val_accuracy: 0.7700\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0623 - accuracy: 0.9835 - val_loss: 1.3889 - val_accuracy: 0.7716\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0548 - accuracy: 0.9848 - val_loss: 1.2440 - val_accuracy: 0.7907\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0523 - accuracy: 0.9880 - val_loss: 1.1614 - val_accuracy: 0.8096\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0399 - accuracy: 0.9894 - val_loss: 1.1117 - val_accuracy: 0.7996\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 1.3048 - val_accuracy: 0.8053\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 162ms/step - loss: 0.0311 - accuracy: 0.9945 - val_loss: 1.0971 - val_accuracy: 0.8005\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 1.2345 - val_accuracy: 0.8081\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3819 - accuracy: 0.8049\n",
            "54.54177030016973 0.6701593394962199 0.7094429665215521 0.65 0.603789905676827 0.17489979594313418 0.8463537900559779\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e486890> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bcd7c90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e488890> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e14cf50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 1.7902 - accuracy: 0.5659 - val_loss: 1.1644 - val_accuracy: 0.7845\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0631 - accuracy: 0.9827 - val_loss: 1.2114 - val_accuracy: 0.7891\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0396 - accuracy: 0.9894 - val_loss: 1.5297 - val_accuracy: 0.7782\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 1.3689 - val_accuracy: 0.7832\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 1.5905 - val_accuracy: 0.7778\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 1.5365 - val_accuracy: 0.7863\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.5483 - accuracy: 0.7992\n",
            "49.671755472281426 0.7154268809616179 0.49546628528806524 0.65 0.6024095203351368 0.2 0.8115020621741188\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b804e90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978cf8e9d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 27s 165ms/step - loss: 1.0932 - accuracy: 0.7094 - val_loss: 1.1435 - val_accuracy: 0.7772\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 159ms/step - loss: 0.0755 - accuracy: 0.9767 - val_loss: 1.1553 - val_accuracy: 0.7905\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 1.2996 - val_accuracy: 0.7853\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 1.3329 - val_accuracy: 0.7860\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 1.2248 - val_accuracy: 0.8065\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 1.1803 - val_accuracy: 0.8107\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.3012 - val_accuracy: 0.8063\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 1.1987 - val_accuracy: 0.7939\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 1.3160 - val_accuracy: 0.8016\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 1.3956 - val_accuracy: 0.7956\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3965 - accuracy: 0.7969\n",
            "50.83309265913466 0.6318064002743333 0.49896723191422365 0.65 0.648820709755117 0.2 0.7972157947633762\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e1b8f10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99ce360790> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 166ms/step - loss: 1.0515 - accuracy: 0.7182 - val_loss: 1.1782 - val_accuracy: 0.7785\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 1.2172 - val_accuracy: 0.7782\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0570 - accuracy: 0.9838 - val_loss: 1.4479 - val_accuracy: 0.7894\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 1.4160 - val_accuracy: 0.7754\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 1.4210 - val_accuracy: 0.7948\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 1.1458 - val_accuracy: 0.8000\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 1.2281 - val_accuracy: 0.7980\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 1.1221 - val_accuracy: 0.8135\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 1.3545 - val_accuracy: 0.8008\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 1.2988 - val_accuracy: 0.8075\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 21s 160ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 1.1291 - val_accuracy: 0.8127\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 21s 161ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.1338 - val_accuracy: 0.8076\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.1769 - accuracy: 0.8168\n",
            "55.96635881475825 0.719651446937258 0.8637390839640535 0.6376116118398537 0.5998559120600819 0.2 0.7520336524926702\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979181a210> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b7ce650> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978decc450> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792c61a10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 175ms/step - loss: 1.5212 - accuracy: 0.6308 - val_loss: 1.5705 - val_accuracy: 0.7454\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.1321 - accuracy: 0.9626 - val_loss: 1.2289 - val_accuracy: 0.7866\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0648 - accuracy: 0.9839 - val_loss: 1.7024 - val_accuracy: 0.7882\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0638 - accuracy: 0.9828 - val_loss: 1.4326 - val_accuracy: 0.7760\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0516 - accuracy: 0.9884 - val_loss: 1.3317 - val_accuracy: 0.7980\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0212 - accuracy: 0.9958 - val_loss: 1.2101 - val_accuracy: 0.8063\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 1.4058 - val_accuracy: 0.7876\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0333 - accuracy: 0.9919 - val_loss: 1.1661 - val_accuracy: 0.8099\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 1.4172 - val_accuracy: 0.8237\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0300 - accuracy: 0.9946 - val_loss: 1.2337 - val_accuracy: 0.8211\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 1.2006 - val_accuracy: 0.8075\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 1.3402 - val_accuracy: 0.7949\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 1.1781 - val_accuracy: 0.8135\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.1205 - accuracy: 0.8369\n",
            "Model N. 10   Accuracy =  0.8369140625 Loss =  1.1204833984375 parameters =  [55.96635881  0.71965145  0.86373908  0.63761161  0.59985591  0.2\n",
            "  0.75203365  2.43877902] \n",
            "\n",
            "56.714138351522266 0.5427093663015186 1.1297234324370655 0.6453179202540037 0.614587148477697 0.199852867488122 0.6826778571949119\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f16a510> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e37ab50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9798ee2090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e3d4a10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 173ms/step - loss: 1.7019 - accuracy: 0.5880 - val_loss: 1.4896 - val_accuracy: 0.7695\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.1123 - accuracy: 0.9676 - val_loss: 1.2151 - val_accuracy: 0.7819\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0743 - accuracy: 0.9818 - val_loss: 1.1820 - val_accuracy: 0.7852\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0525 - accuracy: 0.9867 - val_loss: 1.1732 - val_accuracy: 0.7826\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 1.3436 - val_accuracy: 0.7928\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 1.3878 - val_accuracy: 0.7964\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 1.1916 - val_accuracy: 0.8229\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0331 - accuracy: 0.9927 - val_loss: 1.3531 - val_accuracy: 0.8081\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 1.1249 - val_accuracy: 0.8086\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 1.1846 - val_accuracy: 0.8154\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 1.2444 - val_accuracy: 0.8239\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 1.1638 - val_accuracy: 0.8252\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 1.3238 - val_accuracy: 0.8094\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0278 - accuracy: 0.9948 - val_loss: 1.2673 - val_accuracy: 0.8177\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 1.3213 - val_accuracy: 0.8040\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0276 - accuracy: 0.9954 - val_loss: 1.3480 - val_accuracy: 0.8120\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.3529 - accuracy: 0.8215\n",
            "57.464901642656386 0.7069973379814013 0.47913039634535015 0.6321199413948553 0.5893845204094479 0.2 0.7299525765788377\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e35fed0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978d30a6d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 172ms/step - loss: 1.0541 - accuracy: 0.7189 - val_loss: 1.3151 - val_accuracy: 0.7720\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0662 - accuracy: 0.9797 - val_loss: 1.4178 - val_accuracy: 0.7829\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0518 - accuracy: 0.9846 - val_loss: 1.4129 - val_accuracy: 0.7731\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0367 - accuracy: 0.9901 - val_loss: 1.1985 - val_accuracy: 0.7972\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 1.0886 - val_accuracy: 0.8110\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 1.0119 - val_accuracy: 0.8154\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 1.0636 - val_accuracy: 0.8145\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.3195 - val_accuracy: 0.7964\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 1.1894 - val_accuracy: 0.8105\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 1.1306 - val_accuracy: 0.8029\n",
            "32/32 [==============================] - 4s 84ms/step - loss: 1.1265 - accuracy: 0.8176\n",
            "58.691096710139774 0.7328910924312968 0.49864039152228934 0.6442866697879817 0.5791289460630005 0.2 0.7475030585409498\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9792c95250> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792aa9810> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 178ms/step - loss: 1.0751 - accuracy: 0.7125 - val_loss: 1.3208 - val_accuracy: 0.7503\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0735 - accuracy: 0.9766 - val_loss: 1.2291 - val_accuracy: 0.7734\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0380 - accuracy: 0.9891 - val_loss: 1.1065 - val_accuracy: 0.8083\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0319 - accuracy: 0.9923 - val_loss: 1.2338 - val_accuracy: 0.8003\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 1.1664 - val_accuracy: 0.8026\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 1.4964 - val_accuracy: 0.7889\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0251 - accuracy: 0.9940 - val_loss: 1.1042 - val_accuracy: 0.8047\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.0795 - accuracy: 0.8248\n",
            "54.23836841688196 0.7491634065701708 0.5338825739295927 0.65 0.5789889794755618 0.2 0.766114573995092\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f662190> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978b53aad0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978eeb8bd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f654b10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 172ms/step - loss: 3.0739 - accuracy: 0.3139 - val_loss: 0.8216 - val_accuracy: 0.7708\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.1462 - accuracy: 0.9575 - val_loss: 0.8987 - val_accuracy: 0.8044\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 1.0613 - val_accuracy: 0.8075\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0437 - accuracy: 0.9884 - val_loss: 1.0896 - val_accuracy: 0.7954\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 1.2977 - val_accuracy: 0.7913\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0438 - accuracy: 0.9895 - val_loss: 1.2283 - val_accuracy: 0.8000\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0366 - accuracy: 0.9906 - val_loss: 1.1150 - val_accuracy: 0.8078\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 1.1845 - val_accuracy: 0.8000\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 1.1744 - val_accuracy: 0.8031\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 1.2028 - val_accuracy: 0.8101\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0181 - accuracy: 0.9960 - val_loss: 1.2228 - val_accuracy: 0.7982\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0247 - accuracy: 0.9934 - val_loss: 1.3905 - val_accuracy: 0.8011\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 1.1552 - val_accuracy: 0.8188\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 1.2323 - val_accuracy: 0.8197\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 1.3200 - val_accuracy: 0.8097\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 1.3492 - val_accuracy: 0.7979\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 1.3946 - val_accuracy: 0.8133\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 1.2954 - val_accuracy: 0.8070\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3011 - accuracy: 0.8229\n",
            "58.09421953072572 0.6611428666802425 0.8444783701549714 0.65 0.6251550013567704 0.2 0.7704852303708811\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b58a6d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9792cf4990> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9799d09350> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f03a550> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 177ms/step - loss: 1.8553 - accuracy: 0.5572 - val_loss: 1.1536 - val_accuracy: 0.7616\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1215 - accuracy: 0.9652 - val_loss: 1.2556 - val_accuracy: 0.7729\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0639 - accuracy: 0.9824 - val_loss: 1.1510 - val_accuracy: 0.7992\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 1.2266 - val_accuracy: 0.8019\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0488 - accuracy: 0.9883 - val_loss: 1.2079 - val_accuracy: 0.8024\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0423 - accuracy: 0.9898 - val_loss: 1.1761 - val_accuracy: 0.8027\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0455 - accuracy: 0.9908 - val_loss: 1.3860 - val_accuracy: 0.7852\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 1.5448 - val_accuracy: 0.7900\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 1.3296 - val_accuracy: 0.8164\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.2599 - val_accuracy: 0.8055\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0322 - accuracy: 0.9936 - val_loss: 1.2255 - val_accuracy: 0.8224\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 1.3077 - val_accuracy: 0.7928\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0377 - accuracy: 0.9921 - val_loss: 1.5554 - val_accuracy: 0.7860\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0331 - accuracy: 0.9924 - val_loss: 1.2457 - val_accuracy: 0.8118\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.4696 - val_accuracy: 0.8281\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 1.4882 - val_accuracy: 0.8133\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 1.5341 - val_accuracy: 0.8084\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 1.3349 - val_accuracy: 0.8105\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 1.2843 - val_accuracy: 0.8092\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.3080 - accuracy: 0.8116\n",
            "52.810221600679895 0.7550759868771423 0.8661640137127695 0.6472166781323127 0.5965147854612155 0.2 0.7511690320933294\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e3488d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f4fce90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bcae150> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b53a250> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 172ms/step - loss: 1.7018 - accuracy: 0.6037 - val_loss: 1.1677 - val_accuracy: 0.7850\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.1144 - accuracy: 0.9694 - val_loss: 1.4387 - val_accuracy: 0.7865\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0842 - accuracy: 0.9793 - val_loss: 1.4115 - val_accuracy: 0.7894\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 1.4540 - val_accuracy: 0.7962\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0624 - accuracy: 0.9854 - val_loss: 1.3725 - val_accuracy: 0.7900\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0336 - accuracy: 0.9922 - val_loss: 1.3273 - val_accuracy: 0.8133\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0278 - accuracy: 0.9941 - val_loss: 1.4166 - val_accuracy: 0.8045\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 1.6773 - val_accuracy: 0.7905\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0408 - accuracy: 0.9915 - val_loss: 1.2686 - val_accuracy: 0.8140\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 1.5024 - val_accuracy: 0.7923\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0344 - accuracy: 0.9918 - val_loss: 1.3619 - val_accuracy: 0.8096\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 1.4208 - val_accuracy: 0.8034\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 165ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 1.3905 - val_accuracy: 0.7992\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3568 - accuracy: 0.8136\n",
            "63.62577575046592 0.6131523144584631 0.838645139761373 0.65 0.6118977375640263 0.1830098863869264 0.6732837662381068\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9799642fd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bf6a4fd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf694e90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f64ff50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 184ms/step - loss: 1.6753 - accuracy: 0.5911 - val_loss: 1.3403 - val_accuracy: 0.7756\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.1208 - accuracy: 0.9661 - val_loss: 1.2090 - val_accuracy: 0.7886\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0657 - accuracy: 0.9830 - val_loss: 1.4252 - val_accuracy: 0.7907\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0533 - accuracy: 0.9879 - val_loss: 1.2891 - val_accuracy: 0.8105\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0387 - accuracy: 0.9903 - val_loss: 1.5577 - val_accuracy: 0.7928\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0349 - accuracy: 0.9925 - val_loss: 1.3407 - val_accuracy: 0.8050\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 1.2630 - val_accuracy: 0.8201\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: 1.2047 - val_accuracy: 0.8078\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 1.2180 - val_accuracy: 0.8188\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 1.3239 - val_accuracy: 0.8110\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 1.2963 - val_accuracy: 0.8136\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3435 - accuracy: 0.8312\n",
            "50.60548352484431 0.6724172785205632 0.6551982211174945 0.6449076323326738 0.5898192592296579 0.2 0.7776039166738672\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f531110> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bad8150> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99ce3601d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978b4cb4d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 169ms/step - loss: 1.5974 - accuracy: 0.6113 - val_loss: 1.2311 - val_accuracy: 0.7695\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.1281 - accuracy: 0.9632 - val_loss: 1.2491 - val_accuracy: 0.7928\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0690 - accuracy: 0.9828 - val_loss: 1.3921 - val_accuracy: 0.7943\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 1.4269 - val_accuracy: 0.7993\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 1.3597 - val_accuracy: 0.7974\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0456 - accuracy: 0.9901 - val_loss: 1.4290 - val_accuracy: 0.8031\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 1.5797 - val_accuracy: 0.7778\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0253 - accuracy: 0.9950 - val_loss: 1.3436 - val_accuracy: 0.8066\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0246 - accuracy: 0.9945 - val_loss: 1.4671 - val_accuracy: 0.7926\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 1.6672 - val_accuracy: 0.7974\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 164ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 1.2401 - val_accuracy: 0.8162\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 1.3380 - val_accuracy: 0.8026\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 21s 163ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 1.5316 - val_accuracy: 0.8065\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0280 - accuracy: 0.9949 - val_loss: 1.5089 - val_accuracy: 0.8091\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 163ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 1.5653 - val_accuracy: 0.8034\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.6007 - accuracy: 0.8047\n",
            "53.38656190348467 0.7372043240821037 0.6233690713074619 0.6464285322879908 0.6061057335664704 0.2 0.7745086935234627\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9793b54f10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9791aa6350> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978dbc9310> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791be5ad0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 28s 172ms/step - loss: 1.8693 - accuracy: 0.5646 - val_loss: 1.2683 - val_accuracy: 0.7620\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0978 - accuracy: 0.9726 - val_loss: 1.2149 - val_accuracy: 0.7814\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0783 - accuracy: 0.9806 - val_loss: 1.2424 - val_accuracy: 0.7952\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0613 - accuracy: 0.9844 - val_loss: 1.2664 - val_accuracy: 0.7975\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 1.1410 - val_accuracy: 0.8232\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0358 - accuracy: 0.9918 - val_loss: 1.0481 - val_accuracy: 0.8141\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0357 - accuracy: 0.9920 - val_loss: 1.3981 - val_accuracy: 0.7931\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0365 - accuracy: 0.9925 - val_loss: 1.1050 - val_accuracy: 0.8053\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 1.3188 - val_accuracy: 0.8034\n",
            "32/32 [==============================] - 4s 88ms/step - loss: 1.3249 - accuracy: 0.8185\n",
            "57.27071162449435 0.6824144526233504 0.958507351788409 0.6402984149810396 0.6078455903990945 0.2 0.7563196545797557\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e1ef7d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979914e750> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978ce1fa90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e44da90> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 4.2168 - accuracy: 0.0515 - val_loss: 6.2878 - val_accuracy: 0.1024\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 1.7620 - accuracy: 0.4330 - val_loss: 0.8274 - val_accuracy: 0.7780\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1903 - accuracy: 0.9448 - val_loss: 1.0335 - val_accuracy: 0.7751\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 1.2800 - val_accuracy: 0.7878\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 1.1484 - val_accuracy: 0.8107\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 1.1632 - val_accuracy: 0.7985\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 1.0514 - val_accuracy: 0.8177\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 1.4501 - val_accuracy: 0.8096\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0266 - accuracy: 0.9940 - val_loss: 1.0339 - val_accuracy: 0.8143\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 1.1152 - val_accuracy: 0.8125\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0316 - accuracy: 0.9932 - val_loss: 1.1721 - val_accuracy: 0.7948\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.2085 - accuracy: 0.8096\n",
            "57.862347859106016 0.5184571661323922 1.3143791259196635 0.6401903622125046 0.6189919960982075 0.19978679303368505 0.7002066759964273\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978eebf550> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978bca9b10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9791a51e50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9792c94b90> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 175ms/step - loss: 1.6570 - accuracy: 0.5937 - val_loss: 1.3739 - val_accuracy: 0.7663\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1159 - accuracy: 0.9673 - val_loss: 1.2256 - val_accuracy: 0.7790\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0852 - accuracy: 0.9807 - val_loss: 1.2059 - val_accuracy: 0.7944\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0603 - accuracy: 0.9849 - val_loss: 1.3918 - val_accuracy: 0.7900\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0477 - accuracy: 0.9878 - val_loss: 1.1202 - val_accuracy: 0.8078\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0224 - accuracy: 0.9950 - val_loss: 1.3053 - val_accuracy: 0.8094\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0322 - accuracy: 0.9934 - val_loss: 1.3861 - val_accuracy: 0.8032\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0357 - accuracy: 0.9929 - val_loss: 1.2447 - val_accuracy: 0.8094\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0356 - accuracy: 0.9917 - val_loss: 1.4417 - val_accuracy: 0.8050\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 1.3722 - val_accuracy: 0.7988\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.3075 - accuracy: 0.8193\n",
            "63.29069995967898 0.5660052127008766 0.7694212596635623 0.6149873274013273 0.5708987402603233 0.2 0.66898032547634\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f04c710> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f53b6d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f074890> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d9e4090> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 183ms/step - loss: 1.5175 - accuracy: 0.6262 - val_loss: 1.3012 - val_accuracy: 0.7733\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.1113 - accuracy: 0.9705 - val_loss: 1.2390 - val_accuracy: 0.7830\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0655 - accuracy: 0.9835 - val_loss: 1.3525 - val_accuracy: 0.7918\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0471 - accuracy: 0.9883 - val_loss: 1.1188 - val_accuracy: 0.8096\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0369 - accuracy: 0.9914 - val_loss: 1.1094 - val_accuracy: 0.8123\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0290 - accuracy: 0.9936 - val_loss: 1.2071 - val_accuracy: 0.8042\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 1.2029 - val_accuracy: 0.8026\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0321 - accuracy: 0.9930 - val_loss: 1.2320 - val_accuracy: 0.8052\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 1.3108 - val_accuracy: 0.8057\n",
            "32/32 [==============================] - 4s 84ms/step - loss: 1.2950 - accuracy: 0.8303\n",
            "62.38197203680875 0.6577966856163161 0.9515869797344916 0.6346956253758433 0.5762971218321625 0.2 0.7070557176157841\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9793973cd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bfb63410> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bfc97810> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9798e7d550> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 182ms/step - loss: 2.2266 - accuracy: 0.4884 - val_loss: 1.2663 - val_accuracy: 0.7676\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.1093 - accuracy: 0.9691 - val_loss: 1.3238 - val_accuracy: 0.7967\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0679 - accuracy: 0.9827 - val_loss: 1.7284 - val_accuracy: 0.7559\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0513 - accuracy: 0.9882 - val_loss: 1.1323 - val_accuracy: 0.8029\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0314 - accuracy: 0.9922 - val_loss: 1.0778 - val_accuracy: 0.8055\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 1.3446 - val_accuracy: 0.7956\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 1.2534 - val_accuracy: 0.8141\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 1.2271 - val_accuracy: 0.8065\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 1.2544 - val_accuracy: 0.8104\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 1.3210 - val_accuracy: 0.8132\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0321 - accuracy: 0.9929 - val_loss: 4.5043 - val_accuracy: 0.8045\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 3.5307 - accuracy: 0.7970\n",
            "54.96015075653271 0.736478911446687 0.6874837245107915 0.6490920337852493 0.5627806297823262 0.2 0.7644930991405945\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979148ec50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f97914b2490> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792b2f5d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e151b50> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 176ms/step - loss: 1.7018 - accuracy: 0.5901 - val_loss: 1.4975 - val_accuracy: 0.7563\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.1320 - accuracy: 0.9644 - val_loss: 1.4299 - val_accuracy: 0.7869\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0927 - accuracy: 0.9783 - val_loss: 1.2938 - val_accuracy: 0.7907\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0414 - accuracy: 0.9886 - val_loss: 1.3409 - val_accuracy: 0.8040\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0378 - accuracy: 0.9912 - val_loss: 1.3293 - val_accuracy: 0.8079\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0318 - accuracy: 0.9919 - val_loss: 1.2560 - val_accuracy: 0.8052\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0542 - accuracy: 0.9886 - val_loss: 1.2826 - val_accuracy: 0.8000\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 1.4269 - val_accuracy: 0.7918\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 1.2684 - val_accuracy: 0.8140\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 1.2549 - val_accuracy: 0.8135\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 1.2554 - val_accuracy: 0.8118\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 1.5032 - val_accuracy: 0.8034\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0350 - accuracy: 0.9932 - val_loss: 1.3923 - val_accuracy: 0.8073\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.3052 - accuracy: 0.8153\n",
            "54.698895163931965 0.6414292149135223 0.8907198272212637 0.6470286954288093 0.6182276638009082 0.2 0.75537432335688\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798e4f950> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798e15e50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9792b63b90> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978dcf6c10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 175ms/step - loss: 1.6768 - accuracy: 0.5943 - val_loss: 1.1238 - val_accuracy: 0.7715\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1185 - accuracy: 0.9682 - val_loss: 1.6137 - val_accuracy: 0.7699\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0720 - accuracy: 0.9807 - val_loss: 1.2601 - val_accuracy: 0.7951\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0497 - accuracy: 0.9873 - val_loss: 1.1653 - val_accuracy: 0.8044\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0435 - accuracy: 0.9899 - val_loss: 1.2260 - val_accuracy: 0.8040\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 1.4575 - val_accuracy: 0.8001\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0351 - accuracy: 0.9922 - val_loss: 1.1222 - val_accuracy: 0.8136\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0249 - accuracy: 0.9942 - val_loss: 1.1348 - val_accuracy: 0.8115\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 1.1733 - val_accuracy: 0.8081\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 1.3692 - val_accuracy: 0.8022\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0400 - accuracy: 0.9924 - val_loss: 1.1572 - val_accuracy: 0.8143\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 1.3274 - val_accuracy: 0.7956\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0240 - accuracy: 0.9955 - val_loss: 1.2237 - val_accuracy: 0.8174\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 1.1905 - val_accuracy: 0.8143\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 1.5193 - val_accuracy: 0.8076\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 1.1613 - val_accuracy: 0.8180\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 1.3347 - val_accuracy: 0.8120\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 1.3135 - val_accuracy: 0.8019\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0244 - accuracy: 0.9955 - val_loss: 1.3776 - val_accuracy: 0.8133\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 1.3865 - val_accuracy: 0.8105\n",
            "32/32 [==============================] - 4s 81ms/step - loss: 1.4339 - accuracy: 0.8092\n",
            "52.94521968034243 0.7867179180775052 0.9145737152344849 0.638848799436805 0.6113521225840045 0.2 0.7528757259488158\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791ae0450> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978dc98450> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978f47bb10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978bc9a810> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 174ms/step - loss: 2.4209 - accuracy: 0.4535 - val_loss: 1.2911 - val_accuracy: 0.7536\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 166ms/step - loss: 0.1188 - accuracy: 0.9679 - val_loss: 1.2323 - val_accuracy: 0.7941\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0689 - accuracy: 0.9812 - val_loss: 1.1423 - val_accuracy: 0.8014\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0514 - accuracy: 0.9874 - val_loss: 1.0134 - val_accuracy: 0.8236\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 1.2611 - val_accuracy: 0.8112\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 1.1856 - val_accuracy: 0.7967\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 167ms/step - loss: 0.0334 - accuracy: 0.9925 - val_loss: 1.2633 - val_accuracy: 0.8016\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 1.2217 - val_accuracy: 0.7985\n",
            "32/32 [==============================] - 4s 83ms/step - loss: 1.2334 - accuracy: 0.8170\n",
            "62.52433261580541 0.6174464080472718 0.9111847552583737 0.6475316701183429 0.6094235926301149 0.2 0.6382744217767754\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979922bd10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f99bf6b3450> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf6b3590> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf6a1250> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 185ms/step - loss: 1.5967 - accuracy: 0.6058 - val_loss: 1.4486 - val_accuracy: 0.7467\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.1175 - accuracy: 0.9694 - val_loss: 1.2816 - val_accuracy: 0.7783\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0869 - accuracy: 0.9769 - val_loss: 1.2746 - val_accuracy: 0.8031\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0533 - accuracy: 0.9869 - val_loss: 1.3313 - val_accuracy: 0.7894\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0519 - accuracy: 0.9888 - val_loss: 1.2024 - val_accuracy: 0.8050\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0372 - accuracy: 0.9910 - val_loss: 1.0293 - val_accuracy: 0.8156\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 1.3864 - val_accuracy: 0.8021\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 1.5313 - val_accuracy: 0.7962\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 1.3397 - val_accuracy: 0.8104\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0406 - accuracy: 0.9916 - val_loss: 1.2051 - val_accuracy: 0.8302\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0286 - accuracy: 0.9947 - val_loss: 1.2690 - val_accuracy: 0.8224\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 1.6309 - val_accuracy: 0.7957\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0352 - accuracy: 0.9919 - val_loss: 1.4480 - val_accuracy: 0.8075\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 24s 178ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 1.2067 - val_accuracy: 0.8161\n",
            "32/32 [==============================] - 4s 82ms/step - loss: 1.0776 - accuracy: 0.8285\n",
            "54.32625855796436 0.7019009063818111 0.8524781578844371 0.6371342790422375 0.5992122372717196 0.2 0.7524892732223021\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978b99afd0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e191e10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e1ee610> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97916b2510> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 175ms/step - loss: 4.1936 - accuracy: 0.0476 - val_loss: 3.0377 - val_accuracy: 0.0456\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 3.0353 - accuracy: 0.0517 - val_loss: 3.0080 - val_accuracy: 0.0448\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 3.0165 - accuracy: 0.0491 - val_loss: 3.0051 - val_accuracy: 0.0422\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 3.0124 - accuracy: 0.0498 - val_loss: 3.0018 - val_accuracy: 0.0405\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 168ms/step - loss: 3.0102 - accuracy: 0.0506 - val_loss: 3.0022 - val_accuracy: 0.0439\n",
            "32/32 [==============================] - 4s 88ms/step - loss: 2.9986 - accuracy: 0.0507\n",
            "54.603093882522415 0.8051687639108897 0.8431290228017684 0.6445775035611342 0.5809982228992244 0.2 0.7569524444679135\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f979161c890> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9793ac6950> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97915ec1d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978d006890> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 176ms/step - loss: 1.5822 - accuracy: 0.6149 - val_loss: 1.2486 - val_accuracy: 0.7601\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1171 - accuracy: 0.9685 - val_loss: 1.2505 - val_accuracy: 0.7839\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 1.3123 - val_accuracy: 0.7845\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 1.2504 - val_accuracy: 0.7918\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0662 - accuracy: 0.9865 - val_loss: 1.3669 - val_accuracy: 0.8099\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0490 - accuracy: 0.9893 - val_loss: 1.3225 - val_accuracy: 0.8019\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 1.2736 - val_accuracy: 0.7982\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 1.1624 - val_accuracy: 0.8223\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0201 - accuracy: 0.9960 - val_loss: 1.3168 - val_accuracy: 0.7985\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 1.5869 - val_accuracy: 0.8018\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0298 - accuracy: 0.9940 - val_loss: 1.2347 - val_accuracy: 0.8175\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 1.2679 - val_accuracy: 0.8092\n",
            "32/32 [==============================] - 4s 83ms/step - loss: 1.4776 - accuracy: 0.8098\n",
            "57.284882907556344 0.6882838289292486 0.9924024354497926 0.6401026023722948 0.605754948116584 0.2 0.7576742113131989\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978eec5b90> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f007d50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9a2006b090> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9791b94850> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 177ms/step - loss: 1.8150 - accuracy: 0.5759 - val_loss: 1.3582 - val_accuracy: 0.7549\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.1340 - accuracy: 0.9633 - val_loss: 0.9765 - val_accuracy: 0.7987\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0671 - accuracy: 0.9826 - val_loss: 1.1819 - val_accuracy: 0.8034\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0554 - accuracy: 0.9859 - val_loss: 1.3187 - val_accuracy: 0.7865\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 1.2303 - val_accuracy: 0.7956\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0369 - accuracy: 0.9914 - val_loss: 1.2158 - val_accuracy: 0.8065\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 1.4427 - val_accuracy: 0.8075\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 1.4995 - val_accuracy: 0.7826\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0525 - accuracy: 0.9881 - val_loss: 1.2082 - val_accuracy: 0.8063\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 1.3218 - val_accuracy: 0.8097\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 1.4324 - val_accuracy: 0.8065\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0274 - accuracy: 0.9943 - val_loss: 1.2918 - val_accuracy: 0.8221\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0294 - accuracy: 0.9934 - val_loss: 1.2212 - val_accuracy: 0.8039\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 1.5424 - val_accuracy: 0.8133\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0364 - accuracy: 0.9934 - val_loss: 1.1893 - val_accuracy: 0.8158\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 1.3416 - val_accuracy: 0.8193\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.3060 - accuracy: 0.8247\n",
            "56.47951227446433 0.6357805622188681 1.291936847187201 0.6366561565199065 0.6059842554658121 0.1997914813935006 0.7406581116877601\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978d31fa50> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798ca7610> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97914b6a50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97914b6cd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 177ms/step - loss: 1.6269 - accuracy: 0.6073 - val_loss: 1.3587 - val_accuracy: 0.7772\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.1243 - accuracy: 0.9652 - val_loss: 1.1832 - val_accuracy: 0.7847\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0743 - accuracy: 0.9805 - val_loss: 1.3169 - val_accuracy: 0.7760\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0542 - accuracy: 0.9865 - val_loss: 1.1445 - val_accuracy: 0.7969\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 171ms/step - loss: 0.0333 - accuracy: 0.9918 - val_loss: 1.2224 - val_accuracy: 0.8037\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0301 - accuracy: 0.9932 - val_loss: 1.3153 - val_accuracy: 0.8042\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0294 - accuracy: 0.9937 - val_loss: 1.2464 - val_accuracy: 0.8105\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0254 - accuracy: 0.9947 - val_loss: 1.2461 - val_accuracy: 0.8032\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 1.5649 - val_accuracy: 0.8014\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0521 - accuracy: 0.9896 - val_loss: 1.3028 - val_accuracy: 0.7970\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 1.2578 - val_accuracy: 0.8066\n",
            "32/32 [==============================] - 4s 85ms/step - loss: 1.3572 - accuracy: 0.8123\n",
            "66.6428149314813 0.44804425118324187 0.9436290942818912 0.604862470721008 0.579856685156465 0.2 0.7204183543307597\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978dff9850> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f978e317750> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978e329d10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978e00fdd0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 187ms/step - loss: 1.3972 - accuracy: 0.6498 - val_loss: 1.1487 - val_accuracy: 0.7736\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0690 - accuracy: 0.9800 - val_loss: 1.2166 - val_accuracy: 0.7821\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0699 - accuracy: 0.9803 - val_loss: 1.1545 - val_accuracy: 0.8083\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 1.2415 - val_accuracy: 0.7962\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 1.1281 - val_accuracy: 0.8094\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 1.1523 - val_accuracy: 0.8039\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 1.2031 - val_accuracy: 0.8081\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 1.0350 - val_accuracy: 0.8175\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 24s 179ms/step - loss: 0.0297 - accuracy: 0.9932 - val_loss: 1.0619 - val_accuracy: 0.8237\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 1.1262 - val_accuracy: 0.8151\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 1.2205 - val_accuracy: 0.8092\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 1.1335 - val_accuracy: 0.8192\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.1612 - val_accuracy: 0.8236\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.0557 - accuracy: 0.8413\n",
            "Model N. 11   Accuracy =  0.84130859375 Loss =  1.0557042360305786 parameters =  [66.64281493  0.44804425  0.94362909  0.60486247  0.57985669  0.2\n",
            "  0.72041835  2.60542578] \n",
            "\n",
            "67.70008693960364 0.4284254435686703 1.3471481572588404 0.6268709470311651 0.5581734024082305 0.2 0.7250711235626771\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978f06ff90> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f97995b9a10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978d4eef50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97916e9e10> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 31s 188ms/step - loss: 1.4311 - accuracy: 0.6402 - val_loss: 1.1292 - val_accuracy: 0.7915\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.0895 - accuracy: 0.9747 - val_loss: 1.0681 - val_accuracy: 0.8088\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.0726 - accuracy: 0.9814 - val_loss: 1.2250 - val_accuracy: 0.7954\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.0382 - accuracy: 0.9906 - val_loss: 1.3453 - val_accuracy: 0.7920\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.0482 - accuracy: 0.9885 - val_loss: 1.0435 - val_accuracy: 0.8062\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 24s 181ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 1.2092 - val_accuracy: 0.8019\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.3193 - accuracy: 0.8080\n",
            "59.34998616689157 0.6472361531663554 0.9460085325709489 0.6064069193796261 0.5780850329204325 0.2 0.751140305713382\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978cdbf790> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f995920c210> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f978bbd6dd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f979181a410> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 180ms/step - loss: 2.3546 - accuracy: 0.4606 - val_loss: 1.2664 - val_accuracy: 0.7539\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 1.0902 - val_accuracy: 0.7996\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0572 - accuracy: 0.9847 - val_loss: 1.0235 - val_accuracy: 0.7988\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0505 - accuracy: 0.9868 - val_loss: 1.1405 - val_accuracy: 0.8091\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 1.0983 - val_accuracy: 0.7998\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0330 - accuracy: 0.9920 - val_loss: 1.1729 - val_accuracy: 0.8094\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 1.2784 - val_accuracy: 0.7995\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0244 - accuracy: 0.9947 - val_loss: 1.0827 - val_accuracy: 0.8164\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 1.2535 - val_accuracy: 0.8083\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 1.0529 - val_accuracy: 0.8162\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.9623 - val_accuracy: 0.8294\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 1.2940 - val_accuracy: 0.8101\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 1.1635 - val_accuracy: 0.8166\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 172ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.1420 - val_accuracy: 0.8255\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 1.3131 - val_accuracy: 0.8052\n",
            "32/32 [==============================] - 4s 80ms/step - loss: 1.2980 - accuracy: 0.8129\n",
            "62.88488845431797 0.5658774204668281 0.8246018824413918 0.6183650680393895 0.6110278229526146 0.2 0.7720317310690115\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e5b5590> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978e3136d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf6982d0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f99bf6b69d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 181ms/step - loss: 1.5563 - accuracy: 0.6221 - val_loss: 1.2663 - val_accuracy: 0.7817\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.1196 - accuracy: 0.9674 - val_loss: 1.2355 - val_accuracy: 0.7751\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 1.2727 - val_accuracy: 0.7956\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0487 - accuracy: 0.9876 - val_loss: 1.1642 - val_accuracy: 0.8071\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0313 - accuracy: 0.9922 - val_loss: 1.4272 - val_accuracy: 0.7843\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0467 - accuracy: 0.9897 - val_loss: 1.1509 - val_accuracy: 0.8102\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 1.1420 - val_accuracy: 0.8128\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 1.1961 - val_accuracy: 0.8182\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 1.4164 - val_accuracy: 0.8089\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0361 - accuracy: 0.9930 - val_loss: 1.2437 - val_accuracy: 0.8016\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 23s 178ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 1.4076 - val_accuracy: 0.8042\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 1.2130 - val_accuracy: 0.8193\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 1.3158 - val_accuracy: 0.8110\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 1.3769 - val_accuracy: 0.8071\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 1.2513 - val_accuracy: 0.8105\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 1.1636 - val_accuracy: 0.8182\n",
            "32/32 [==============================] - 4s 78ms/step - loss: 1.2332 - accuracy: 0.8221\n",
            "55.44758350363733 0.6957393218983493 0.77860313951706 0.6351433557781594 0.603374208911373 0.2 0.7242379163503159\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9798f5f9d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9798f50790> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f99bf330390> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f995925e490> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 174ms/step - loss: 1.7062 - accuracy: 0.5867 - val_loss: 1.0201 - val_accuracy: 0.7965\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.1161 - accuracy: 0.9669 - val_loss: 1.1573 - val_accuracy: 0.7863\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0717 - accuracy: 0.9819 - val_loss: 1.2262 - val_accuracy: 0.7964\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0457 - accuracy: 0.9877 - val_loss: 1.3779 - val_accuracy: 0.7965\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0356 - accuracy: 0.9907 - val_loss: 1.3963 - val_accuracy: 0.8045\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0362 - accuracy: 0.9919 - val_loss: 1.2129 - val_accuracy: 0.8073\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0318 - accuracy: 0.9936 - val_loss: 1.2969 - val_accuracy: 0.7977\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0419 - accuracy: 0.9908 - val_loss: 1.2105 - val_accuracy: 0.8211\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0244 - accuracy: 0.9946 - val_loss: 1.2123 - val_accuracy: 0.8219\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0214 - accuracy: 0.9956 - val_loss: 1.3701 - val_accuracy: 0.7952\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 22s 169ms/step - loss: 0.0291 - accuracy: 0.9946 - val_loss: 1.4748 - val_accuracy: 0.7863\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0286 - accuracy: 0.9928 - val_loss: 1.1086 - val_accuracy: 0.8328\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 1.0016 - val_accuracy: 0.8280\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 1.3624 - val_accuracy: 0.8210\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 23s 171ms/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 1.2216 - val_accuracy: 0.8314\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 22s 170ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 1.6156 - val_accuracy: 0.8149\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.6047 - accuracy: 0.8160\n",
            "62.10347503753473 0.6057316730974183 0.9381968601838023 0.6372519958921001 0.5915230156057876 0.2 0.7021873684132127\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f978e49af10> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f979146e050> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9a34582b10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f978f05c510> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 30s 183ms/step - loss: 1.5525 - accuracy: 0.6204 - val_loss: 1.3323 - val_accuracy: 0.7892\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.1305 - accuracy: 0.9668 - val_loss: 1.2819 - val_accuracy: 0.7869\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0608 - accuracy: 0.9844 - val_loss: 1.1256 - val_accuracy: 0.7878\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0458 - accuracy: 0.9877 - val_loss: 1.1578 - val_accuracy: 0.8175\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0524 - accuracy: 0.9877 - val_loss: 1.3341 - val_accuracy: 0.7967\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0406 - accuracy: 0.9910 - val_loss: 1.1794 - val_accuracy: 0.8114\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 177ms/step - loss: 0.0295 - accuracy: 0.9940 - val_loss: 1.4444 - val_accuracy: 0.7970\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0322 - accuracy: 0.9924 - val_loss: 1.2448 - val_accuracy: 0.8158\n",
            "32/32 [==============================] - 4s 79ms/step - loss: 1.2562 - accuracy: 0.8215\n",
            "60.94311933441572 0.657344113868644 0.897801580674454 0.6109813586039101 0.6120500954918444 0.2 0.7447198265776428\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f9791b773d0> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f978f297d50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f97990a3d10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f97910298d0> True\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 29s 179ms/step - loss: 1.5395 - accuracy: 0.6202 - val_loss: 1.4362 - val_accuracy: 0.7692\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.1124 - accuracy: 0.9699 - val_loss: 1.0825 - val_accuracy: 0.7936\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0665 - accuracy: 0.9822 - val_loss: 1.2489 - val_accuracy: 0.7775\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0529 - accuracy: 0.9887 - val_loss: 1.2782 - val_accuracy: 0.7747\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0508 - accuracy: 0.9876 - val_loss: 1.2441 - val_accuracy: 0.7957\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0449 - accuracy: 0.9892 - val_loss: 1.3284 - val_accuracy: 0.8123\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0371 - accuracy: 0.9915 - val_loss: 1.1329 - val_accuracy: 0.8138\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0243 - accuracy: 0.9959 - val_loss: 1.7843 - val_accuracy: 0.7826\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.0361 - accuracy: 0.9937 - val_loss: 1.1878 - val_accuracy: 0.8052\n",
            "Epoch 10/30\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9950"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1WrARnk6zgY"
      },
      "source": [
        "### Συμπεράσματα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OBvANpk63jQ"
      },
      "source": [
        "Παραπάνω εφαρμόσαμε τον αλγόριθμο βελτιστοποίησης PSO. Να υπενθυμίσουμε ότι ο αλγόριθμος αυτός δεν βρίσκει ολικό μέγιστο (ή ελάχιστο), αλλά τοπικό. Συνεπώς δεν μπορούμε να είμαστε σίγουροι ότι έχουμε την βέλτιστη αρχιτεκτονική για το κάθε μοντέλο, αλλά έχουμε μια καλη εκτίμηση για τις δυνατότητες του κάθε μοντέλου καθώς και την αρχιτεκτονική που ταιριάζει περισσότερο στο classification πρόβλημα που αντιμετωπίζουμε. \r\n",
        "\r\n",
        "Από τα αποτελέσματα που έχουμε θα αναλύσουμε τις αρχιτεκτονικές για το κάθε μοντέλο, θα εντοπίσουμε κοινά στοιχεία, και σύμφωνα με αυτά θα προσπαθήσουμε μέσω πειραμάτων αυτή τη φορά να κατασκευάσουμε την αρχιτεκτόνική ενός μοντέλου που αναφέρεται και στο demo notebook , το VGG16.\r\n",
        "\r\n",
        "**DenseNet121**:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.   Best Accuracy on Test Set 0.6829833984375 \r\n",
        "2.   UnFreezed Layers = 120, Flatten, No extra Dense Layer, learning_rate = 0.001, optimizer = Adam, batch size = 64.\r\n",
        "3.   Total params: 7,140,004\r\n",
        "4.   Trainable params: 2,825,828\r\n",
        "5.   Non-trainable params: 4,314,176\r\n",
        "\r\n",
        "**ResNet50**:\r\n",
        "\r\n",
        "\r\n",
        "1.   Best Accuracy on Test Set 0.5535888671875\r\n",
        "2.   UnFreezed Layers = 47, Flatten, 2 Extra Dense Layers, Dropout1=0.29207627, Dropout2 = 0.32014804, learning rate=0.001, optimizer = SGD, batch size = 64.\r\n",
        "3. Total params: 26,239,076\r\n",
        "4. Trainable params: 18,761,316\r\n",
        "5. Non-trainable params: 7,477,760\r\n",
        "\r\n",
        "**Xception**:\r\n",
        "\r\n",
        "1.  Best Accuracy on Test Set 0.84130859375 \r\n",
        "2.  UnFreezed Layers = 67, GlobalAvgPooling2D, 1 Extra Dense Layers, Dropout1= 0.57985669, learning rate =  0.01 , optimizer = Adam, batch size = 256.\r\n",
        "3. Total params: 21,961,868\r\n",
        "4. Trainable params: 15,958,652\r\n",
        "5. Non-trainable params: 6,003,216\r\n",
        "\r\n",
        "\r\n",
        "Δεν μπορούμε να βγάλουμε πολλά κοινά στοιχεία για τις αρχιτεκτονικές παρά μόνο για τα UnFreezed layers που τείνουν να είναι σχεδόν όλα. Δηλαδή τα μόνα μη εκπαιδεύσιμα στρώματα να είναι ορισμένα στην αρχή. Τέλος φαίνεται να υπάρχει μια κλίση προς αρκετά μεγάλο learning rate , γεγονός που μας προβληματίζει.\r\n",
        "\r\n",
        "Έχοντας μια είκονα για τις μετρικές και τις αρχιτεκτονικές που ξεχώρισαν, προχωράμε στο VGG16 μέσω πειραμάτων.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZl66spHT2fv"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brrPzjk_UXpk"
      },
      "source": [
        "def create_model_vgg16(x):\r\n",
        "  \r\n",
        "  print(x[0],x[1],x[2],x[3],x[4],x[5],x[6])\r\n",
        "  IMG_SHAPE1=(75,75,3) \r\n",
        "  vgg=tf.keras.applications.VGG16(input_shape=IMG_SHAPE1,include_top=False,weights='imagenet') \r\n",
        "  tempre=vgg\r\n",
        "  \r\n",
        "  for layer in tempre.layers[:(-1)*int(round(x[0]))]:\r\n",
        "    layer.trainable = False\r\n",
        "  \r\n",
        "  for layer in tempre.layers:\r\n",
        "    print(layer, layer.trainable)\r\n",
        "  model = tf.keras.Sequential()\r\n",
        "  model.add(tempre)\r\n",
        "  if (int(round(x[1]))):\r\n",
        "    model.add(keras.layers.Flatten())\r\n",
        "  else:\r\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\r\n",
        "  \r\n",
        "  if (int(round(x[2]))==3):\r\n",
        "    model.add(keras.layers.Dense(2048, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(0.5))\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==2):\r\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[4]))\r\n",
        "  elif (int(round(x[2]))==1):\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dropout(x[3]))\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "\r\n",
        "  #for layer in model.layers:\r\n",
        "    #print(layer, layer.trainable)\r\n",
        "  model.add(keras.layers.Dense(100,activation=\"softmax\"))\r\n",
        "  if x[5]< 0.003:\r\n",
        "    learning_rate = 0.0000005\r\n",
        "  elif x[5]< 0.0075:\r\n",
        "    learning_rate = 0.000001\r\n",
        "  elif x[5]< 0.015:\r\n",
        "    learning_rate = 0.000005\r\n",
        "  elif x[5]< 0.035:\r\n",
        "    learning_rate = 0.00001\r\n",
        "  elif x[5]< 0.075:\r\n",
        "    learning_rate = 0.00005\r\n",
        "  elif x[5]< 0.125:\r\n",
        "    learning_rate = 0.0001\r\n",
        "  elif x[5]< 0.175:\r\n",
        "    learning_rate = 0.0005\r\n",
        "  else:\r\n",
        "    learning_rate = 0.001\r\n",
        "\r\n",
        "  if (x[6]<0.5):\r\n",
        "    opt = keras.optimizers.SGD(learning_rate=learning_rate)\r\n",
        "  else:\r\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "  return model\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3NFKLCxv6PL"
      },
      "source": [
        "##### 1o Πείραμα - Αρχιτεκτονική με Freezed όλα τα  Στρώματα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDEchVSAw_fC",
        "outputId": "ec4b0934-719a-4db6-80a8-99d5cf622f78"
      },
      "source": [
        "x=[1,1,0,0.4,0.4,0.07,1]\r\n",
        "model1=create_model_vgg16(x)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1 0 0.4 0.4 0.07 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6b50060cd0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b402940d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2763a90> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b502274d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b50286850> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b0203c650> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1d05450> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1d03910> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b50047d50> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1d030d0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1d775d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1daf5d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1d465d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1d03650> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1d70f10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b50175850> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b500aa650> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1dee650> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1de4790> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gqNbLIww8Au",
        "outputId": "e311e478-eccf-4225-8d27-c5be782d166f"
      },
      "source": [
        "start = time.time()\r\n",
        "history1=model1.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 30s 48ms/step - loss: 4.7508 - accuracy: 0.0134 - val_loss: 4.5818 - val_accuracy: 0.0189\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 4.5271 - accuracy: 0.0241 - val_loss: 4.4174 - val_accuracy: 0.0316\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 4.3735 - accuracy: 0.0426 - val_loss: 4.2963 - val_accuracy: 0.0527\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 4.2589 - accuracy: 0.0601 - val_loss: 4.1967 - val_accuracy: 0.0710\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 4.1635 - accuracy: 0.0854 - val_loss: 4.1111 - val_accuracy: 0.0885\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 5s 35ms/step - loss: 4.0818 - accuracy: 0.1015 - val_loss: 4.0365 - val_accuracy: 0.1019\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 4s 31ms/step - loss: 4.0019 - accuracy: 0.1159 - val_loss: 3.9683 - val_accuracy: 0.1157\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.9337 - accuracy: 0.1284 - val_loss: 3.9070 - val_accuracy: 0.1287\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.8768 - accuracy: 0.1437 - val_loss: 3.8489 - val_accuracy: 0.1400\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.8197 - accuracy: 0.1548 - val_loss: 3.7937 - val_accuracy: 0.1510\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.7631 - accuracy: 0.1636 - val_loss: 3.7468 - val_accuracy: 0.1566\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.7143 - accuracy: 0.1741 - val_loss: 3.7007 - val_accuracy: 0.1665\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.6650 - accuracy: 0.1846 - val_loss: 3.6571 - val_accuracy: 0.1745\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.6311 - accuracy: 0.1905 - val_loss: 3.6191 - val_accuracy: 0.1829\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.5947 - accuracy: 0.1979 - val_loss: 3.5835 - val_accuracy: 0.1882\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.5471 - accuracy: 0.2073 - val_loss: 3.5512 - val_accuracy: 0.1953\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.5037 - accuracy: 0.2179 - val_loss: 3.5170 - val_accuracy: 0.2004\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.4831 - accuracy: 0.2164 - val_loss: 3.4869 - val_accuracy: 0.2046\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.4521 - accuracy: 0.2208 - val_loss: 3.4580 - val_accuracy: 0.2085\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.4184 - accuracy: 0.2277 - val_loss: 3.4333 - val_accuracy: 0.2106\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.3884 - accuracy: 0.2283 - val_loss: 3.4064 - val_accuracy: 0.2165\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.3710 - accuracy: 0.2329 - val_loss: 3.3816 - val_accuracy: 0.2204\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.3494 - accuracy: 0.2382 - val_loss: 3.3596 - val_accuracy: 0.2254\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.3184 - accuracy: 0.2430 - val_loss: 3.3362 - val_accuracy: 0.2288\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.2865 - accuracy: 0.2475 - val_loss: 3.3179 - val_accuracy: 0.2305\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.2704 - accuracy: 0.2495 - val_loss: 3.2981 - val_accuracy: 0.2323\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.2548 - accuracy: 0.2504 - val_loss: 3.2773 - val_accuracy: 0.2365\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.2313 - accuracy: 0.2524 - val_loss: 3.2645 - val_accuracy: 0.2388\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.2071 - accuracy: 0.2585 - val_loss: 3.2465 - val_accuracy: 0.2407\n",
            "Epoch 30/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.1874 - accuracy: 0.2607 - val_loss: 3.2298 - val_accuracy: 0.2438\n",
            "Epoch 31/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.1818 - accuracy: 0.2572 - val_loss: 3.2121 - val_accuracy: 0.2472\n",
            "Epoch 32/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.1625 - accuracy: 0.2659 - val_loss: 3.1973 - val_accuracy: 0.2495\n",
            "Epoch 33/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.1415 - accuracy: 0.2672 - val_loss: 3.1880 - val_accuracy: 0.2495\n",
            "Epoch 34/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.1227 - accuracy: 0.2706 - val_loss: 3.1712 - val_accuracy: 0.2515\n",
            "Epoch 35/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.1207 - accuracy: 0.2706 - val_loss: 3.1558 - val_accuracy: 0.2559\n",
            "Epoch 36/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.0954 - accuracy: 0.2683 - val_loss: 3.1463 - val_accuracy: 0.2547\n",
            "Epoch 37/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.0931 - accuracy: 0.2707 - val_loss: 3.1316 - val_accuracy: 0.2586\n",
            "Epoch 38/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.0696 - accuracy: 0.2743 - val_loss: 3.1259 - val_accuracy: 0.2576\n",
            "Epoch 39/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.0488 - accuracy: 0.2811 - val_loss: 3.1079 - val_accuracy: 0.2604\n",
            "Epoch 40/40\n",
            "132/132 [==============================] - 4s 28ms/step - loss: 3.0542 - accuracy: 0.2755 - val_loss: 3.0979 - val_accuracy: 0.2627\n",
            "Χρόνος fit: 178.5095090866089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "q0rFC_J0xZ5O",
        "outputId": "2d75ed06-3319-49b1-879b-6342009abee1"
      },
      "source": [
        "model1.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 24ms/step - loss: 3.0788 - accuracy: 0.2725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1REvqVh6wmYv"
      },
      "source": [
        "##### 2o Πείραμα - Unfreeze Layzers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCBXw6ToRhOO",
        "outputId": "97f61a75-accf-4926-e2ba-0d917d53deb4"
      },
      "source": [
        "x=[13,1,0,0.4,0.4,0.07,1]\r\n",
        "model2=create_model_vgg16(x)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13 1 0 0.4 0.4 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6ae0093f50> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae007f7d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b500c0610> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae0093250> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b4029c050> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae01c1650> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b5267b990> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae007f290> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae0110750> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ba38dc050> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1daba10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae003cd10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae003e290> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00e96d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae0057850> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae0046950> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae004b6d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae006a790> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae006af50> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZQU7klvRsI4",
        "outputId": "988a6578-3293-497e-b675-5724dc99b521"
      },
      "source": [
        "start = time.time()\r\n",
        "history2=model2.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 10s 42ms/step - loss: 3.8187 - accuracy: 0.1386 - val_loss: 2.3080 - val_accuracy: 0.4004\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 2.0444 - accuracy: 0.4472 - val_loss: 1.9112 - val_accuracy: 0.4855\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 1.6194 - accuracy: 0.5445 - val_loss: 1.7833 - val_accuracy: 0.5145\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 1.3612 - accuracy: 0.6055 - val_loss: 1.6604 - val_accuracy: 0.5389\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.1629 - accuracy: 0.6622 - val_loss: 1.6480 - val_accuracy: 0.5584\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.9686 - accuracy: 0.7119 - val_loss: 1.5978 - val_accuracy: 0.5672\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.8140 - accuracy: 0.7582 - val_loss: 1.6712 - val_accuracy: 0.5693\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.6604 - accuracy: 0.8040 - val_loss: 1.6978 - val_accuracy: 0.5757\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.5323 - accuracy: 0.8411 - val_loss: 1.7860 - val_accuracy: 0.5721\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.4053 - accuracy: 0.8757 - val_loss: 1.8408 - val_accuracy: 0.5729\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.3134 - accuracy: 0.9066 - val_loss: 2.0578 - val_accuracy: 0.5615\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.2499 - accuracy: 0.9254 - val_loss: 2.1008 - val_accuracy: 0.5719\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.1586 - accuracy: 0.9563 - val_loss: 2.1860 - val_accuracy: 0.5793\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 2.2482 - val_accuracy: 0.5770\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.0904 - accuracy: 0.9766 - val_loss: 2.3868 - val_accuracy: 0.5726\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0733 - accuracy: 0.9814 - val_loss: 2.5351 - val_accuracy: 0.5736\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0555 - accuracy: 0.9864 - val_loss: 2.6288 - val_accuracy: 0.5726\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0656 - accuracy: 0.9826 - val_loss: 2.5545 - val_accuracy: 0.5771\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0566 - accuracy: 0.9854 - val_loss: 2.6235 - val_accuracy: 0.5677\n",
            "Χρόνος fit: 99.53000998497009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "gmqCEDujR0Jb",
        "outputId": "a148d776-c062-42f4-ec09-90005a276b12"
      },
      "source": [
        "model2.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 24ms/step - loss: 2.6391 - accuracy: 0.5756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlKXyKFCwIUe"
      },
      "source": [
        "##### 3o Πείραμα - Learning Rate Decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozM5yp_UJ17",
        "outputId": "75edf5ce-9b3b-4307-f874-0d4574cd4452"
      },
      "source": [
        "x=[19,1,0,0.4,0.4,0.07,1]\r\n",
        "model3=create_model_vgg16(x)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 1 0 0.4 0.4 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6ad6536290> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad6516b50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad651ec90> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad6646e90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad67f4d50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64d2450> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad652d6d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64cbf90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64db0d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64e8590> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad64e8d50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad652d250> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64f5d10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64f59d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad64f5710> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad647dcd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64e8750> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad64ef290> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad64937d0> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffm2cBSBUSzB",
        "outputId": "c6e1ab05-13a8-48fb-e1e2-08a66133dbe5"
      },
      "source": [
        "start = time.time()\r\n",
        "history3=model3.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 10s 45ms/step - loss: 3.7472 - accuracy: 0.1392 - val_loss: 2.2832 - val_accuracy: 0.3973\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 2.0149 - accuracy: 0.4511 - val_loss: 1.8842 - val_accuracy: 0.4867\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 1.6188 - accuracy: 0.5431 - val_loss: 1.7309 - val_accuracy: 0.5182\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 1.3724 - accuracy: 0.6062 - val_loss: 1.6471 - val_accuracy: 0.5425\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 1.1516 - accuracy: 0.6645 - val_loss: 1.5976 - val_accuracy: 0.5539\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.9680 - accuracy: 0.7136 - val_loss: 1.5681 - val_accuracy: 0.5758\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.8333 - accuracy: 0.7522 - val_loss: 1.5840 - val_accuracy: 0.5767\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.6763 - accuracy: 0.7980 - val_loss: 1.6531 - val_accuracy: 0.5788\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.5431 - accuracy: 0.8320 - val_loss: 1.7113 - val_accuracy: 0.5688\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.4057 - accuracy: 0.8765 - val_loss: 1.8180 - val_accuracy: 0.5758\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.3168 - accuracy: 0.9047 - val_loss: 1.9360 - val_accuracy: 0.5770\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.1486 - accuracy: 0.9636 - val_loss: 2.0567 - val_accuracy: 0.5954\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.0584 - accuracy: 0.9908 - val_loss: 2.2028 - val_accuracy: 0.5947\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.0439 - accuracy: 0.9951 - val_loss: 2.3340 - val_accuracy: 0.5955\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0359 - accuracy: 0.9957 - val_loss: 2.4227 - val_accuracy: 0.5910\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0242 - accuracy: 0.9984 - val_loss: 2.5341 - val_accuracy: 0.5936\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0191 - accuracy: 0.9990 - val_loss: 2.6784 - val_accuracy: 0.5929\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0153 - accuracy: 0.9993 - val_loss: 2.6990 - val_accuracy: 0.5977\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0121 - accuracy: 0.9993 - val_loss: 2.7320 - val_accuracy: 0.5952\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0108 - accuracy: 0.9997 - val_loss: 2.7451 - val_accuracy: 0.5975\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0101 - accuracy: 0.9998 - val_loss: 2.7850 - val_accuracy: 0.5934\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0098 - accuracy: 0.9999 - val_loss: 2.8026 - val_accuracy: 0.5944\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.0092 - accuracy: 0.9997 - val_loss: 2.8075 - val_accuracy: 0.5980\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: 2.8272 - val_accuracy: 0.5962\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0090 - accuracy: 0.9997 - val_loss: 2.8454 - val_accuracy: 0.5970\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 2.8520 - val_accuracy: 0.5970\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0086 - accuracy: 0.9999 - val_loss: 2.8701 - val_accuracy: 0.5942\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0085 - accuracy: 0.9999 - val_loss: 2.8991 - val_accuracy: 0.5954\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9007 - val_accuracy: 0.5951\n",
            "Χρόνος fit: 171.1571228504181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "n2C_NjDUXQ-H",
        "outputId": "d4126824-1bb8-4015-8b13-52ba43a8e848"
      },
      "source": [
        "model3.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 2s 23ms/step - loss: 2.8522 - accuracy: 0.6069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZlghATWccI"
      },
      "source": [
        "##### 4ο Πείραμα - Add Extra Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScQSd0p3XG70",
        "outputId": "28568390-f658-47ae-e51e-3ed4423df1a5"
      },
      "source": [
        "x=[19,1,3,0.4,0.3,0.07,1]\r\n",
        "model4=create_model_vgg16(x)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 1 3 0.4 0.3 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6ae1c748d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad6558c50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad6457d50> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad65b1a90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad65b1c10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae021b050> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ad65cd910> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad65cd850> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00d3e10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ad6566690> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae00cb5d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae1ba1b90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00e2810> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00e91d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae1d77e90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00e9650> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae00f0110> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae0110e90> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae0105e50> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN-81UpwXO-R",
        "outputId": "31aa824d-1f8e-4e86-f2d2-b56527e077ed"
      },
      "source": [
        "start = time.time()\r\n",
        "history4=model4.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 10s 47ms/step - loss: 4.5411 - accuracy: 0.0186 - val_loss: 3.7666 - val_accuracy: 0.1019\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 3.7843 - accuracy: 0.1003 - val_loss: 2.9807 - val_accuracy: 0.2394\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 3.0867 - accuracy: 0.2110 - val_loss: 2.4002 - val_accuracy: 0.3704\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 2.5759 - accuracy: 0.3133 - val_loss: 2.1795 - val_accuracy: 0.4165\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 2.2695 - accuracy: 0.3895 - val_loss: 1.9787 - val_accuracy: 0.4621\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.9990 - accuracy: 0.4518 - val_loss: 1.8528 - val_accuracy: 0.4974\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.7678 - accuracy: 0.5066 - val_loss: 1.7771 - val_accuracy: 0.5187\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.5887 - accuracy: 0.5559 - val_loss: 1.7265 - val_accuracy: 0.5361\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.4175 - accuracy: 0.5973 - val_loss: 1.6735 - val_accuracy: 0.5456\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.2671 - accuracy: 0.6369 - val_loss: 1.7010 - val_accuracy: 0.5537\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 1.1427 - accuracy: 0.6686 - val_loss: 1.6688 - val_accuracy: 0.5690\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.9789 - accuracy: 0.7089 - val_loss: 1.6926 - val_accuracy: 0.5783\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.8688 - accuracy: 0.7407 - val_loss: 1.7338 - val_accuracy: 0.5755\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.7511 - accuracy: 0.7735 - val_loss: 1.7721 - val_accuracy: 0.5770\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.6507 - accuracy: 0.8034 - val_loss: 1.9200 - val_accuracy: 0.5719\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.4792 - accuracy: 0.8542 - val_loss: 1.8719 - val_accuracy: 0.6006\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.3769 - accuracy: 0.8831 - val_loss: 1.9575 - val_accuracy: 0.5988\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.3306 - accuracy: 0.8993 - val_loss: 1.9913 - val_accuracy: 0.5977\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.3167 - accuracy: 0.9015 - val_loss: 2.0131 - val_accuracy: 0.5980\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2730 - accuracy: 0.9151 - val_loss: 2.0501 - val_accuracy: 0.5977\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2602 - accuracy: 0.9200 - val_loss: 2.0530 - val_accuracy: 0.6021\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2602 - accuracy: 0.9195 - val_loss: 2.0746 - val_accuracy: 0.5978\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2563 - accuracy: 0.9213 - val_loss: 2.1059 - val_accuracy: 0.5985\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2478 - accuracy: 0.9239 - val_loss: 2.0994 - val_accuracy: 0.6003\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2352 - accuracy: 0.9292 - val_loss: 2.1128 - val_accuracy: 0.6022\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2345 - accuracy: 0.9266 - val_loss: 2.1179 - val_accuracy: 0.6024\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2304 - accuracy: 0.9300 - val_loss: 2.1328 - val_accuracy: 0.6011\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2331 - accuracy: 0.9269 - val_loss: 2.1352 - val_accuracy: 0.6009\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2190 - accuracy: 0.9330 - val_loss: 2.1442 - val_accuracy: 0.6001\n",
            "Epoch 30/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2211 - accuracy: 0.9324 - val_loss: 2.1529 - val_accuracy: 0.6016\n",
            "Epoch 31/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 0.2251 - accuracy: 0.9305 - val_loss: 2.1618 - val_accuracy: 0.6017\n",
            "Epoch 32/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 0.2096 - accuracy: 0.9334 - val_loss: 2.1679 - val_accuracy: 0.6006\n",
            "Χρόνος fit: 193.17223811149597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "Be942yCiXe7J",
        "outputId": "9906746d-2a8a-42ca-9e37-40aa31672cee"
      },
      "source": [
        "model4.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history4)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 2s 22ms/step - loss: 2.1347 - accuracy: 0.6024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nDNhXSVwQ6a"
      },
      "source": [
        "##### 5o Πείραμα - Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zp988kKJz7h",
        "outputId": "2691a71a-7db4-4322-c410-2d281817277b"
      },
      "source": [
        "x=[19,2,0,0.4,0.4,0.07,1]\r\n",
        "model5=create_model_vgg16(x)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 2 0 0.4 0.4 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6ae2763c10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae25cb910> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae270bd50> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2162c50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae25a7e90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae013da90> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2761f90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae276c390> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2076f50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b4ff86d90> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2076950> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b4ff86850> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae0213650> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2053ad0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2053b10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2062490> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2042e50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae203c690> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2043190> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6PqWiHzJ2Bn",
        "outputId": "c4cfaa76-7889-42e4-abcf-f0b5e5571768"
      },
      "source": [
        "start = time.time()\r\n",
        "history5=model5.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 10s 49ms/step - loss: 4.0217 - accuracy: 0.0896 - val_loss: 2.8089 - val_accuracy: 0.2739\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 2.6613 - accuracy: 0.3041 - val_loss: 2.5038 - val_accuracy: 0.3371\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 2.3479 - accuracy: 0.3719 - val_loss: 2.3166 - val_accuracy: 0.3742\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 2.1376 - accuracy: 0.4192 - val_loss: 2.1948 - val_accuracy: 0.4106\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 2.0351 - accuracy: 0.4365 - val_loss: 2.1226 - val_accuracy: 0.4214\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.9391 - accuracy: 0.4643 - val_loss: 2.0150 - val_accuracy: 0.4455\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.8479 - accuracy: 0.4846 - val_loss: 2.0206 - val_accuracy: 0.4471\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.7645 - accuracy: 0.5054 - val_loss: 1.9544 - val_accuracy: 0.4655\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.6863 - accuracy: 0.5253 - val_loss: 1.9752 - val_accuracy: 0.4604\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.6333 - accuracy: 0.5337 - val_loss: 1.8838 - val_accuracy: 0.4937\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 1.5507 - accuracy: 0.5589 - val_loss: 1.8798 - val_accuracy: 0.4852\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.5274 - accuracy: 0.5573 - val_loss: 1.9005 - val_accuracy: 0.4821\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.4748 - accuracy: 0.5755 - val_loss: 1.9145 - val_accuracy: 0.4906\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.3000 - accuracy: 0.6269 - val_loss: 1.7842 - val_accuracy: 0.5169\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.2091 - accuracy: 0.6475 - val_loss: 1.7974 - val_accuracy: 0.5169\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 1.1676 - accuracy: 0.6600 - val_loss: 1.8000 - val_accuracy: 0.5148\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 1.1445 - accuracy: 0.6630 - val_loss: 1.7809 - val_accuracy: 0.5210\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.1446 - accuracy: 0.6663 - val_loss: 1.8206 - val_accuracy: 0.5146\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 1.1139 - accuracy: 0.6730 - val_loss: 1.8122 - val_accuracy: 0.5169\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.1105 - accuracy: 0.6763 - val_loss: 1.8311 - val_accuracy: 0.5220\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.0836 - accuracy: 0.6814 - val_loss: 1.8239 - val_accuracy: 0.5160\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.0638 - accuracy: 0.6874 - val_loss: 1.8087 - val_accuracy: 0.5215\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 6s 48ms/step - loss: 1.0620 - accuracy: 0.6867 - val_loss: 1.8026 - val_accuracy: 0.5272\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.0447 - accuracy: 0.6934 - val_loss: 1.8643 - val_accuracy: 0.5181\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 1.0191 - accuracy: 0.7024 - val_loss: 1.8889 - val_accuracy: 0.5182\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9899 - accuracy: 0.7080 - val_loss: 1.8654 - val_accuracy: 0.5205\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 0.9645 - accuracy: 0.7212 - val_loss: 1.8430 - val_accuracy: 0.5275\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9262 - accuracy: 0.7286 - val_loss: 1.8713 - val_accuracy: 0.5212\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9283 - accuracy: 0.7275 - val_loss: 1.8674 - val_accuracy: 0.5288\n",
            "Epoch 30/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9183 - accuracy: 0.7285 - val_loss: 1.8561 - val_accuracy: 0.5267\n",
            "Epoch 31/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.9044 - accuracy: 0.7345 - val_loss: 1.8691 - val_accuracy: 0.5190\n",
            "Epoch 32/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 0.9124 - accuracy: 0.7321 - val_loss: 1.8497 - val_accuracy: 0.5317\n",
            "Epoch 33/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.8991 - accuracy: 0.7340 - val_loss: 1.8717 - val_accuracy: 0.5260\n",
            "Epoch 34/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.8991 - accuracy: 0.7333 - val_loss: 1.8833 - val_accuracy: 0.5190\n",
            "Epoch 35/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.8971 - accuracy: 0.7345 - val_loss: 1.8966 - val_accuracy: 0.5236\n",
            "Epoch 36/40\n",
            "132/132 [==============================] - 6s 46ms/step - loss: 0.8695 - accuracy: 0.7423 - val_loss: 1.8844 - val_accuracy: 0.5247\n",
            "Epoch 37/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.8877 - accuracy: 0.7386 - val_loss: 1.8760 - val_accuracy: 0.5229\n",
            "Epoch 38/40\n",
            "132/132 [==============================] - 6s 47ms/step - loss: 0.8742 - accuracy: 0.7409 - val_loss: 1.8887 - val_accuracy: 0.5290\n",
            "Χρόνος fit: 239.2156536579132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "LxKYOfupJ8ME",
        "outputId": "9dfaa49e-77c4-41aa-d473-31e5e1e38b6e"
      },
      "source": [
        "model5.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history5)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 31ms/step - loss: 1.8679 - accuracy: 0.5348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAILCAYAAADbiPRKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZgcVb3/8fc3s2Sy7/s2WSB7CBDDqkTAKyAQRJBdcGMRvCCKAqIgIKIoCpfL5QeCIiCL7ASQzbAJAkkIgSyQfd/XmSQzmeX7++NU0z2TWZOZqemez+t56unqqurqU93JfPqcOlXH3B0RERGJT6u4CyAiItLSKYxFRERipjAWERGJmcJYREQkZgpjERGRmCmMRUREYqYwFmkCZvaimZ3b0NuKSGYwXWcsUjUzK0x52hYoBsqi5xe4+0NNX6q9Y2YdgeuBk4GuwFrgOeBGd98QZ9lEWjLVjEWq4e7tExOwDDghZdnnQWxm2fGVsu7MLBd4DRgNHAN0BA4BNgIT92B/aXHcIulAYSxST2Y2ycxWmNnPzGwN8Bcz62JmU8xsvZltjub7p7zmdTP7XjR/npm9bWa/j7ZdbGbH7uG2g83sTTMrMLNXzex/zezBaor+LWAg8HV3n+Pu5e6+zt1vcPcXov25mQ1L2f9fzezGGo57rpkdn7J9dvQZHBA9P9jM3jGzLWb2kZlNStn2PDNbFJV9sZmdteffikh6UxiL7JnehGbeQcD5hP9Lf4meDwR2AnfU8PqDgE+B7sDvgHvNzPZg278D7wPdgOuAc2p4z6OBf7p7YQ3b1KbycT8MnJGy/qvABnefYWb9gOeBG6PX/AR4wsx6mFk74HbgWHfvABwKzNyLcomkNYWxyJ4pB65192J33+nuG939CXff4e4FwK+BI2p4/VJ3v8fdy4D7gT5Ar/psa2YDgS8Av3T3Xe7+NvBsDe/ZDVhdv8PcTYXjJvwYONHM2kbrzyQENMDZwAvu/kJUC38FmAYcl7KvMWbWxt1Xu/vsvSybSNpSGIvsmfXuXpR4YmZtzez/mdlSM9sGvAl0NrOsal6/JjHj7jui2fb13LYvsCllGcDyGsq8kRDke6PCcbv7AmAucEIUyCcSAhpC7fnUqIl6i5ltAQ4H+rj7duA04EJgtZk9b2Yj9rJsImlLYSyyZypfhvBjYDhwkLt3BL4ULa+u6bkhrAa6ptRKAQbUsP2rwFejJuLq7CD0HE/oXWl9VZdfJJqqJwNzooCG8MPgAXfvnDK1c/ebAdz9JXf/CuEHwjzgnhrKJZLRFMYiDaMD4TzxFjPrClzb2G/o7ksJzb7XmVmumR0CnFDDSx4gBOQTZjbCzFqZWTczu9rMEk3HM4EzzSzLzI6h5qb2hEeA/wIuIlkrBniQUGP+arS/vKgTWH8z62Vmk6MfBsVAIaHZWqRFUhiLNIw/AW2ADcB/gH820fueRfLypBuBRwnhtht3LyZ04poHvAJsI3T+6g68F212KSHQt0T7frq2Arj7auBdQiesR1OWLyfUlq8G1hN+CFxB+LvTCrgcWAVsIoT+RXU9aJFMo5t+iGQQM3sUmOfujV4zF5GGo5qxSBozsy+Y2dCoyfkYQk201tqsiDQvuoOOSHrrDTxJuGxpBXCRu38Yb5FEpL7UTC0iIhIzNVOLiIjETGEsIiISM4WxiIhIzBTGIiIiMVMYi4iIxExhLCIiEjOFsYiISMwUxiIiIjFTGIuIiMRMYSwiIhIzhbGIiEjMFMYiIiIxUxiLiIjETGEsIiISM4WxiIhIzBTGIiIiMVMYi4iIxExhLCIiEjOFsYiISMwUxiIiIjFTGIuIiMRMYSwiIhIzhbGIiEjMFMYiIiIxUxiLiIjETGEsIiISM4WxiIhIzBTGIiIiMVMYi4iIxExhLFIFMzvTzKaZWaGZrTazF83s8BjLs8TMdkblSUx31PG1r5vZ9xq7jHVhZueZ2dtxl0OkucmOuwAizY2ZXQ5cCVwIvATsAo4BJgO7BYmZZbt7aRMU7QR3f7Whd9qE5ReRaqhmLJLCzDoB1wMXu/uT7r7d3Uvc/Tl3vyLa5joze9zMHjSzbcB5ZtbXzJ41s01mtsDMvp+yz4lRLXubma01s1uj5XnRPjaa2RYz+8DMeu1Bmc8zs7fN7PdmttnMFpvZsdG6XwNfBO5IrU2bmZvZxWY2H5gfLft+VPZN0bH0TXkPN7P/NrNFZrbBzG4xs1ZmlhttPzZl255mtsPMetTzOA6NPoOt0eOhlY5xkZkVRMd3VrR8mJm9Eb1mg5k9Wt/PT6Q5UBiLVHQIkAc8Vct2k4HHgc7AQ8AjwAqgL3AKcJOZHRltextwm7t3BIYCj0XLzwU6AQOAboSa+M49LPdBwKdAd+B3wL1mZu7+c+At4BJ3b+/ul6S85qTodaOisv4G+CbQB1gaHVOqrwMTgAOi4/+Ou++Ktjs7ZbszgNfcfX1dC29mXYHngdsJn8WtwPNm1s3M2kXLj3X3DsChwMzopTcALwNdgP7A/9T1PUWaE4WxSEXdgA11aLZ9192fdvdyQgAeBvzM3YvcfSbwZ+Bb0bYlwDAz6+7uhe7+n5Tl3YBh7l7m7tPdfVsN7/l0VINOTN9PWbfU3e9x9zLgfkKg1lbL/o27b3L3ncBZwH3uPsPdi4GrgEPMLD9l+99G2y8D/kQIXaL3O8PMLHp+DvBALe9d2deA+e7+gLuXuvvDwDzghGh9OTDGzNq4+2p3nx0tLwEGAX2jz17noyUtKYxFKtoIdDez2vpTLE+Z7wtscveClGVLgX7R/HeBfYF5UfPr8dHyBwjnpB8xs1Vm9jszy6nhPU9y984p0z0p69YkZtx9RzTbvp7HsDRlH4WEz6JfNdsvjV6Du78H7AAmmdkIYBjwbC3vXVmF9095j37uvh04jdBysNrMno/eB+CngAHvm9lsM/tOPd9XpFlQGItU9C5QTGjCrYmnzK8CuppZh5RlA4GVAO4+393PAHoCvwUeN7N20bnoX7n7KELT6/Eka9MNyeuwfBWhhglA1DTcLXEMkQEp8wOj1yTcT2iqPgd43N2L6lnGCu+f8h6Jz/Ald/8KocY/D7gnWr7G3b/v7n2BC4A7zWxYPd9bJHYKY5EU7r4V+CXwv2Z2kpm1NbMcMzvWzH5XzWuWA+8Av4k6ZY0j1IYfBDCzs82sR9SkvSV6WbmZfdnMxppZFrCN0ORa3giHtRYYUss2DwPfNrPxZtYauAl4z92XpGxzhZl1MbMBwKVAamepBwnnlM8G/lbLe1n0OX0+AS8A+1q4pCzbzE4DRgFTzKyXmU2OfiAUA4VEn5OZnWpm/aP9bib8wGiMz1CkUSmMRSpx9z8AlwPXAOsJzbOXAE/X8LIzgHxCDe8p4NqUy5COAWabWSGhM9fp0Xna3oROYNuAucAb1Hyu9TmreJ1xbZ3MEm4DTol6Wt9e1QZRWX8BPAGsJnQ0O73SZs8A0wmdp54H7k15/XJgBiEM36qlPIcSOqqlTlsJLQM/JjSP/xQ43t03EP5OXU74bDcBRwAXRfv6AvBe9Nk+C1zq7otqeX+RZsfcq2vBEhEJzMyBfdx9QQ3b3Aescvdrmq5kIplBN/0Qkb0W9bo+Gdg/3pKIpCc1U4vIXjGzG4BPgFvcfXHc5RFJR2qmFhERiZlqxiIiIjGL7Zxx9+7dPT8/P663FxERaXLTp0/f4O673bc9tjDOz89n2rRpcb29iIhIkzOzyneaA9RMLSIiEjuFsYiISMwUxiIiIjHTTT9ERKRJlJSUsGLFCoqK6juOSPrJy8ujf//+5OTUNBBbUq1hHN3E/U2gdbT94+5+baVtzgNuITnCyx3u/ud6lFtERDLcihUr6NChA/n5+SSHv8487s7GjRtZsWIFgwcPrtNr6lIzLgaOdPfCaKzVt83sxZQB0hMedfdL6llmERFpIYqKijI+iAHMjG7durF+/fo6v6bWc8YeFEZPc6KpWd226623YOhQ+PjjuEsiIiI1yfQgTqjvcdapA5eZZZnZTGAd8Iq7v1fFZt8ws1lm9ng03mlV+znfzKaZ2bT6/GKoTZcusGgRzJrVYLsUERFpMnUKY3cvc/fxQH9gopmNqbTJc0C+u48DXgHur2Y/d7v7BHef0KPHbjcg2WPDh0NOjmrGIiJSvS1btnDnnXfW+3XHHXccW7ZsaYQSJdXr0iZ33wJMJQyWnrp8o7sXR0//DBzYMMWrm5wcGDFCYSwiItWrLoxLS0trfN0LL7xA586dG6tYQN16U/cAStx9i5m1Ab4C/LbSNn3cfXX09ERgboOXtBZjx4ZzxyIi0vxddhnMnNmw+xw/Hv70p+rXX3nllSxcuJDx48eTk5NDXl4eXbp0Yd68eXz22WecdNJJLF++nKKiIi699FLOP/98IHn75sLCQo499lgOP/xw3nnnHfr168czzzxDmzZt9rrsdakZ9wGmmtks4APCOeMpZna9mZ0YbfPfZjbbzD4C/hs4b69LVk9jx8Ly5dDILQkiIpKmbr75ZoYOHcrMmTO55ZZbmDFjBrfddhufffYZAPfddx/Tp09n2rRp3H777WzcuHG3fcyfP5+LL76Y2bNn07lzZ5544okGKVutNWN3nwXsX8XyX6bMXwVc1SAl2kNjx4bHTz6Bww+PsyQiIlKbmmqwTWXixIkVrgO+/fbbeeqppwBYvnw58+fPp1u3bhVeM3jwYMaPHw/AgQceyJIlSxqkLBlzO8xx48KjzhuLiEhdtGvX7vP5119/nVdffZV3332Xjz76iP3337/KO4W1bt368/msrKxazzfXVcaEcf/+0KmTwlhERKrWoUMHCgoKqly3detWunTpQtu2bZk3bx7/+U/l+1o1roy5N7VZaKpWGIuISFW6devGYYcdxpgxY2jTpg29evX6fN0xxxzDXXfdxciRIxk+fDgHH3xwk5bN3OO5mdaECRN82rRpDbrPH/wA/v532Lw5hLOIiDQfc+fOZeTIkXEXo8lUdbxmNt3dJ1TeNmOaqSHUjLduDb2qRURE0kXGhTGoqVpERNJLRoXxmOgmnQpjERFJJxkVxp07w4ABCmMREUkvGRXGoB7VIiKSfjIyjOfNg5KSuEsiIiJSNxkZxiUl8OmncZdERETSXfv27ZvkfTIyjEFN1SIikj4y5g5cCSNGQHZ2COMzzoi7NCIiUqXpl8HmBh5Dsct4OLDmESiuvPJKBgwYwMUXXwzAddddR3Z2NlOnTmXz5s2UlJRw4403Mnny5IYtWy0yrmacmwvDh6tmLCIiuzvttNN47LHHPn/+2GOPce655/LUU08xY8YMpk6dyo9//GOa+u6UGVczhtBU/e67cZdCRESqVUsNtrHsv//+rFu3jlWrVrF+/Xq6dOlC7969+dGPfsSbb75Jq1atWLlyJWvXrqV3795NVq6MDeNHHoFt26Bjx7hLIyIizcmpp57K448/zpo1azjttNN46KGHWL9+PdOnTycnJ4f8/Pwqh09sTBnXTA3JTlyffBJvOUREpPk57bTTeOSRR3j88cc59dRT2bp1Kz179iQnJ4epU6eydOnSJi9TRoexzhuLiEhlo0ePpqCggH79+tGnTx/OOusspk2bxtixY/nb3/7GiBEjmrxMGdlMPWgQdOgAs2bFXRIREWmOPk6prXXv3p13q+loVFhY2CTlyciasZluiykiIukjI8MYkmHcxL3TRURE6i2jw3jLFli5Mu6SiIhIQlNfvxuX+h5nRocxqKlaRKS5yMvLY+PGjRkfyO7Oxo0bycvLq/NrMrIDF1QM42OPjbcsIiIC/fv3Z8WKFaxfvz7uojS6vLw8+vfvX+ftMzaMu3SBfv1UMxYRaS5ycnIYPHhw3MVolmptpjazPDN738w+MrPZZvarKrZpbWaPmtkCM3vPzPIbo7D1pR7VIiKSDupyzrgYONLd9wPGA8eY2cGVtvkusNndhwF/BH7bsMXcM2PHwty5YXxjERGR5qrWMPYgcdVzTjRVPvs+Gbg/mn8cOMrMrMFKuYfGjoVdu2D+/LhLIiIiUr069aY2sywzmwmsA15x9/cqbdIPWA7g7qXAVqBbFfs538ymmdm0pjiBrx7VIiKSDuoUxu5e5u7jgf7ARDMbsydv5u53u/sEd5/Qo0ePPdlFvYwcCVlZCmMREWne6nWdsbtvAaYCx1RatRIYAGBm2UAnYGNDFHBvtG4N++6rMBYRkeatLr2pe5hZ52i+DfAVYF6lzZ4Fzo3mTwH+5c3kqm71qBYRkeauLjXjPsBUM5sFfEA4ZzzFzK43sxOjbe4FupnZAuBy4MrGKW79jR0LixdDQUHcJREREalarTf9cPdZwP5VLP9lynwRcGrDFq1hJDpxzZ4NB1e+IEtERKQZyNh7UyckwlhjG4uISHOV8WGcnw/t2um8sYiINF8ZH8atWsGYMQpjERFpvjI+jAHGjQth3Dz6d4uIiFTUIsJ47FjYtAlWr467JCIiIrvLnDCuodqr22KKiEhzlhlhvOF9+OcBsGNFlasVxiIi0pxlRhjn9YSts+GTG6pc3a0b9OmjMBYRkeYpM8K4fT4MuwAW3gsFC6rcRLfFFBGR5iozwhhg9M+hVWuY9csqV48dC3PmQGlpE5dLRESkFpkTxm16w/BLYenDsPmj3VaPHQvFxbCg6oqziIhIbDInjAFGXQE5neGja3ZbpU5cIiLSXGVWGOd2gVE/hVVTYP07FVaNHBnuxqUwFhGR5iazwhhg+H9DXi/46OoK1x63aQP77KMwFhGR5ifzwji7HYy+Bta9AWteqbBKPapFRKQ5yrwwBhh2PrTL3612PHYsLFoEhYXxFU1ERKSyzAzjrFwYex1smg7Ln/x88dixIZtnz46vaCIiIpVlZhgD5J8NHUfCrGugPFxcrB7VIiLSHGVuGLfKgv1uhG3zYMmDAAwZAm3bKoxFRKR5ydwwBuj/deg6AWZdC2XFtGoFo0crjEVEpHnJ7DA2g/1ugh3LYMHdQLJHdQ0jLoqIiDSpzA5jgN5HQ68vw+wboaSQsWNhwwZYuzbugomIiASZH8aJ2nHROvjsdg4/PCy+7754iyUiIpKQ+WEM0P1g6HcizPkdE8Zu4utfh5tugtWr4y6YiIhISwljCD2rS7bB3Fv43e9g1y64ZvfxJERERJpcrWFsZgPMbKqZzTGz2WZ2aRXbTDKzrWY2M5qqHlQ4Tp3HQv6Z8OltDOu3mksvhb/8BWbMiLtgIiLS0tWlZlwK/NjdRwEHAxeb2agqtnvL3cdH0/UNWsqGMvZXUF4Cn/yaa66Bbt3g8svVs1pEROJVaxi7+2p3nxHNFwBzgX6NXbBG0WEoDP0eLLybTuWzuOEGeOMNeOqpuAsmIiItWb3OGZtZPrA/8F4Vqw8xs4/M7EUzG13N6883s2lmNm39+vX1LmyDGHsdtO4BbxzP985azejRcMUVUFwcT3FERETqHMZm1h54ArjM3bdVWj0DGOTu+wH/Azxd1T7c/W53n+DuE3r06LGnZd47bXrBEVNg1yay/30it926nUWL4Pbb4ymOiIhIncLYzHIIQfyQuz9Zeb27b3P3wmj+BSDHzLo3aEkbUtf94dCHYfMMjso7h+O/Vs4NN8C6dXEXTEREWqK69KY24F5grrvfWs02vaPtMLOJ0X43NmRBG1z/E2D/W2HFU/z1sp+xcyf8svn1ARcRkRYguw7bHAacA3xsZjOjZVcDAwHc/S7gFOAiMysFdgKnu6dBH+Xh/w0F8+k2//c8cO0+nHXt+fzgBzBuXNwFExGRlsTiyswJEyb4tGnTYnnvCspL4Y0T8TUvc8r/vMDWtv/FK6+Eu2iKiIg0JDOb7u4TKi9vOXfgqk6rbDj8UazTaB7+wSms+fQTpkyJu1AiItKSKIwBcjrAEVPIaduel676Gr+5dg27dsVdKBERaSkUxgntBmCTnqNX5w386esncvedO+IukYiItBAK41RdDyTri39nwpBpDFj5LTasL4+7RCIi0gIojCuxAZNZ2/f3TN7/CT7861VxF0dERFoAhXEV+kz6EW+uvpCv9Psdq966J+7iiIhIhlMYV8WMkWf/D6/O/iq9ll4E8/6koZ1ERKTRKIyr0aNXNnO7PcaUD78GM34Eb58Ku7bGXSwREclACuMa/ODSjjy0/Gl+8tAtlC97Gv45ATbPrP2FIiIi9aAwrkFWFjz4oDHPfsIRN7zOjoId8NLBsOAeNVuLiEiDURjXIjcX/vEPyOl7OEMv+ZC1fBHePx/ePRdKt8ddPBERyQAK4zpo0waefRYGj+zJoHP/yfw218GSB+GlibB1btzFExGRNKcwrqP27eGFF2DkqCzGnXktH3V7GYrWw0tfgCV/j7t4IiKSxhTG9dC5M7z8MuTnw+GnHM2HfT6ELvvDO2fB+xdCWVHcRRQRkTSkMK6nHj3g1VfD41HH92NWz6kw6mew4P+Fzl0rp4DrNpoiIlJ3CuM90K8fvPYatG0LX/mvbD5rezN86VnYtRHeOAGeHx16XKumLCIidaAw3kODB4casjscdRQsKT0BTlwEhz4EWW1Cj+unB8LH14dzyyIiItVQGO+FESPglVegsBCOPhpWrcmB/DPhmOlw1L+g2xfg42vhmYHhnPK2T+MusoiINEMK4720337w4ouwdm0I5IULATPo9WWY9Dx8bTbknw2L/gJTRsIbk2Hdm7ppiIiIfE5h3AAOPhimTIHVq2H8ePjrX1OyttMoOOgemLwMxlwDG/4Nrx4BLx8Cmz6Ms9giItJMKIwbyBFHwEcfwQEHwLe/DaefDps3p2zQpheMuz6E8hfuhO1Lw01DPv4VlJfEVm4REYmfwrgBDRwI//oX3HQTPPlkaMJ+881KG2W3hX0uCs3Xg06Dj68Lobx5VhxFFhGRZkBh3MCysuCqq+Cdd6B1a5g0CX7+cyipXPlt3RUOfRC++BTsXAUvTYBPblQtWUSkBVIYN5IvfAE+/DA0Wd90Exx2GCxYUMWGA06C42bDgG/ArF+Ec8lbPmny8oqISHwUxo2ofXu491547DGYPz907vrLX6roSJ3XHQ57GA5/HLYvg38eCLN/A+WlsZRbRESaVq1hbGYDzGyqmc0xs9lmdmkV25iZ3W5mC8xslpkd0DjFTU+nngqzZoXa8ne+A6edVqlzV8LAb4Rzyf0nw0dXw8uHalQoEZEWwLyW613NrA/Qx91nmFkHYDpwkrvPSdnmOOCHwHHAQcBt7n5QTfudMGGCT5s2bW/Ln1bKyuCWW+AXv4DeveFPf4KTTw6XJe9m6WMw7QdQUggjLoPcrlC2M0ylO5PzZTvDbTcT89ntIP8cGPRNyMpr8mMUEZHqmdl0d5+w2/LawriKHT0D3OHur6Qs+3/A6+7+cPT8U2CSu6+ubj8tMYwTpk2D73431JaPPhpuvx1Gjqxiw51rQyAvfzK5rFVuuN1mYspuA63ywmNWm3DJVMF8aN0NhnwHhl0AHYY22bGJiEj1qgvj7HruJB/YH3iv0qp+wPKU5yuiZRXC2MzOB84HGDhwYH3eOqNMmADTp8Ndd4Va8rhxcOml8MtfQseOKRu26QVffAJ2bYVW2SF0W2XVvHN3WDsV5t8J826Fub+HPl+FfX4AfY+r/fUiItLk6lwzNrP2wBvAr939yUrrpgA3u/vb0fPXgJ+5e7VV35ZcM061fj1cfXXo6NWrV2jGPuusapqu62vHSlj4Z1hwd7h8qu1A2OcCGPLdEPRVcYfi9VC4OEzbF4XHVjlhqMh2gxqgYCIiLdNeNVObWQ4wBXjJ3W+tYr2aqffSBx/AJZfA+++Hy6DuuCP0vm4Q5SWw8jn47E5Y+1oI1gGnQL8ToWgNFEaBu30xbF8Cpdsrvj6vJ5RsC/MjfgyjroSc9g1UOBGRlmOPw9jMDLgf2OTul1WzzdeAS0h24Lrd3SfWtF+F8e7Ky8N9ra+8EjZuhAsvhBtugK5dG/BNtn0K8+8KA1eUbA3LsjtA+8Fhapf6OATa54dOYduXwcyrYOnfoU0f2O8mGPwtMF0dJyJSV3sTxocDbwEfA+XR4quBgQDuflcU2HcAxwA7gG/X1EQNCuOabNkC114basddusCvfx06fGXX6wx/LUq3h45ebQeEntp1bRdf/y7M+BFsfA+6HggH/BF6frEBCyYikrkarDd1Q1EY127WLPjhD8P9rUeNgptvhuOPb6DzyXvDy2HJwzDzZ7BzJQw8Fcb/NtSom7QcDqUFodd58TooWgtF0WP7YWFs6dg/LBGRJIVxmnKHp54KTdfz58OXvhQ6eU2s8SRAEyndHnprz/ltCOgRl8PoqyCnw97vu7wsBH3iXHbhItixIhm2RetCAJcVVb+PwefCxLt0vbVIOvByKN4UOpAWrw/9VHI6Q+vu4VLN3K4ZcTWIwjjNlZTAPffAr34F69bBN78Z7nk9tDlcQrxjRTifvORByOsF+/4wDITRqnV0XXT02Cp392VlRSmBm/K4Y1nFQTOsFeT1CfvP65nyGM23Tp3vBnNuDiNidZsYBuNo2ze2j0eaUHlJ+Pez7VPYNg8KPoWCBZDbBTrsCx32gY7RY15vtZw0FncoLYRdm6B4Y5h2bYLiDVC0Phm4qfPFG0IgV8sgNwrn3G7h/3kiqFt3g+yOoSKQEz3u9rx9so/L58G/IZrWJ+eL1ldc/pW3w9+rBqIwzhAFBfD734eppAQuugiuuQZ69Ii7ZMCG92HGZbDh3T17fV7PSh3IUubbDQy9wOtj+VPw7jnhP+MXn4TuB+9ZuaT52bUVts4OoVsQBe+2KHg95Z7ueT3DKYtdm6FwIZTvSq7Lbh9CuXJId9infv0oqlNSEAZ92TIrlA9P+VGaW8UP1ZRlOZ3DD9rcaMpuV7/ylBWlhEoUeiVbw4/V9vnQdlAIsD05xuJN4bMsWAiFC8IVGMUbwvJdKcFb0wh0uV0hrwe0jqbEfF7P5PPsjlCyJQrzDcnHXanPo/myHXUre3b78BmXbKk++LPbRyHfPZTlsL+HHwENRGGcYVavDrXkP/8Z2rYNzdiXXRbmY+Ue/qGXFYc/fInH8sRjpWWtcqPgzQ9/cBralo/hjcmhyXvi3TDk3IZ/D2ka5aWw+mVYdG+4VC/xx75VLnQYBh2GQ8cR0HF4csp5MiEAACAASURBVMrtkvL6stDiUjAftn0WHguix+2LK/5xzukc7lzXfli072HJ+bxeFUOsvDTsY8us8O9ty8dhfvuS5DZZbcOPycT/AS+r37G3ykkGc2pI53QMzbmf1zKj8C0trH2fWW3DfQOqmvJ6hfsUFC4MP3AKFyYDuGRLxf0kWqlyu0VlS32MmpdbV5qv7w/r2pQVhR8/pQXh8yhJeSxNPI+WlRen1Kp7JIM3r0coc3abhi1bJQrjDDV3bhg/+ZlnoG/fENDnngs5DfxvPa0Vb4S3TwvXWA+/DPa/JdzRTNJDwYJwKd6iv4ab17TuAflnQ++jQuC2y9/777NsVwjkbZ+lBNCC8Lh9ScXwzG4H7YeG0NqxArbOCX/gASwr1LQ7j4POY6NpXNi2QoCXgZdU+nGa+LFaBLu2hNrlrk1RjXNTssaZuqxkK+R0Sqlddt99PvGY2wl2rgm3zN2+JHqMph1Lw/6rYtnhM+4wNBx3+6Ep80MgO+4aQHpRGGe4t9+GK66A//wHhgyBn/8czjlHofy58lL48Cfw6W3Q6yg4/NHw6zjdlG4PU3aH0DGtPs2MiburbV8W/QFeFuYTj14agia7fe2PrbuFc65t+oQ/9A3dsaZ0Byx7HBbdB+veCOf6+hwLQ78DfY+HrNyGfb+alJdE93xfsHtIt+kHXcZBpyh4O41M3w6DJYXRv4WloZNk2/4hcNsO0I/XBqQwbgHc4fnn4brrwr2vBw8OofytbymUP7fwL/DBheEPzZeegc5j4i5RzUoKYP2/Yd3rsPYN2DQteU7UspMdVLI7VJqPOq2UFCT/wO5Yvnvv8+x2odbWdkBo7i3dHpo4Kz/W1GvdWoVAbtMnCujeobNdm97heU6nUHvKbhuaRrPaVJxPBLk7bPwgNEMveTg0ObYfFgJ48Legbb9G+YhFmpLCuAVJhPKvfhVGiMrPD6Gs5uvIhv/Am18PIXPIAzDgpIrrvTx0+Kmq12dJQQjD8tLw6KWh5lTheWmyltl2YHQebmDyfFxOx6rLBeGc1rq3Q/iuewM2TQ9NpJYdeob3PALa9I3OjVU6R1bVfHa70Fmn3cAwpZan7cBwTrUutevyMijbHmpPpYVRr9M1odmzaA3sXJ2cTyxP7UhVk1a50TnV7LDfrDbh2vUh34GeX1KPZ8koCuMWyB1eeCGE8gcfJEP5W9+C3CZs5WuWdqyEt06Gje9D36+F3phFqZdYVNPBplVu6HxiOSE8LDvlMafi85JtoTaa2oMXQk0xEcyJcCxaG8J384zwY6BVDnQ7CHpOgl5HQPdDGqeDW2NJXDpStCZ8DmU7Q9Nz2Y7ocWfK/I7kGN1dD4RBp4fzmyIZSGHcgrnDiy+GUH7/fRg0KFlTbtGhXFYE038Ea/9V9WUWifnE5Ratu9f/ekMvD0G7fWnyXO3n52ujZSVbQsh3PziEb88jwrw6xohkHIWx4A7//GcI5ffegwEDwuVQ3/tepXGUpWmVbIuaatO044+I1Fl1Yawhd1oQMzj2WHj33VBTHjwYfvzjEMpXXAHLl8ddwhYqp6OCWKSFUxi3QGZwzDHwxhvhXPJxx8Ef/xguiTrrLJgxI+4Sioi0LArjFm7CBHj4YVi4MIwQ9dxzcOCB8OUvw5QpYYxlERFpXApjAUKnrltvDU3Vt9wCCxbACSfA6NFw992wc2fcJRQRyVwKY6mgUyf4yU9g0SJ46KFwr+sLLgjnlS+9FGbOjLuEIiKZR2EsVcrJgTPPDDcNmToVjjoK7roL9t8/TLfdBhs2xF1KEZHMoDCWGpnBpEnw6KNhpKg77oCsrHBJVN++8I1vhHPLpXW82ZKIiOxOYSx11rUrXHxxqC3PmgWXXAJvvRXOLQ8YAD/9aRhFSkRE6kdhLHtk7NjQ4WvlSnj6aTjooHB51KhRcNhhoVd2TPeTERFJOwpj2Ss5OTB5cgjklSvhD3+AVavgxBNh/Hh47DEoq+c46iIiLY3CWBpMz55w+eXw2Wdw//2waxecdlq4POr++6GkJO4Siog0TwpjaXA5OWFkqE8+CTXjvDw47zzYd9/QI7uohqFxRURaIoWxNJqsLDj1VPjww3AOuVcvuOgiGDo0nF/evj3uEoqINA8KY2l0ZnD88WGAildfheHDQ3N2fj5cfXUYc3n9+rhLKSISn+zaNjCz+4DjgXXuPqaK9ZOAZ4DF0aIn3f36hiykZAazcPOQo46Cd96BX/8abr452et68GCYODE5HXBAuAOYiEimqzWMgb8CdwB/q2Gbt9z9+AYpkbQIhx4Kzz8PBQVhlKj33w/Tu++GG4xAaOYeMyYZzocdBiNGhFAXEckktYaxu79pZvmNXxRpiTp0gCOOCFPC2rVhaMdEQD/+ONxzT1g3dGi4lOrEE0M4Z9fl56SISDPXUH/KDjGzj4BVwE/cfXYD7VdaoF69wjnm46O2FvcwitRrr8Ezz4Rbct56K3TrBl/7Wgjmr34V2rePt9wiInvKvA63SYpqxlOqOWfcESh390IzOw64zd33qWY/5wPnAwwcOPDApUuX7kXRpaUqKICXXgrB/PzzsHkztG4dzkWfeGKY+vSJu5QiIrszs+nuPmG35XsbxlVsuwSY4O41jukzYcIEnzZtWq3vLVKTkhL4979DMD/zDCyOuhF+4xvwyCNqxhaR5qW6MN7rS5vMrLdZ6FJjZhOjfW7c2/2K1EVOThhV6o9/hIUL4eOPw4AVTzwBV14Zd+lEROqmLpc2PQxMArqb2QrgWiAHwN3vAk4BLjKzUmAncLrXpbot0sDMQu/r3/423FDkD38IvbC/+c24SyYiUrM6NVM3BjVTS2PatQu+/GX46CN4771wf2wRkbg1WjO1SHOUmwv/+Ee4dOrrX4etW+MukYhI9RTGkrH69g0DVSxeHAauKC+Pu0QiIlVTGEtG++IXw7njZ5+F3/wm7tKIiFRNYSwZ74c/hLPOgl/8Av75z7hLIyKyO4WxZDwzuPtuGDsWzjwzeS2yiEhzoTCWFqFtW3jyyXBrzZNPhh074i6RiEiSwlhajKFD4aGHwuVOF16YHLpRRCRuCmNpUY47Dq69Fh54AO68M+7SiIgECmNpcX7xizAi1GWXwTvvxF0aERGFsbRArVqFmvGgQXDKKbB6ddwlEpGWTmEsLVLnzqFD19atcPjhcPPNsGxZ3KUSkZZKYSwt1rhxYdjFPn3gqqtCTfmII+Cee8IYySIiTUVhLC3a0UfD22/DokVw442wdi2cfz707h3GRH7ySSgujruUIpLpFMYiwODB8POfw9y5MG0a/OAH8O9/h0Du3TsE9Jtv6v7WItI4NISiSDVKS+G11+DBB+Gpp8IYyV26hObt/fZLTqNHQ15e3KUVkXRQ3RCK2XEURiQdZGfDV78apu3bw/nlN94INw3585+Td/HKyoLhw5PhnAjrPn3CrThFRGqjmrHIHigrg4ULYdasEM6JKbVHdteuMGJEmEaOTM7n54egF5GWp7qascJYpAFt3pwM6DlzYN68cB563brkNrm5sM8+FUN6wIBwuVWnTuGxQ4dwPbSIZBY1U4s0gS5dwuVRRxxRcfmmTfDppyGcEwE9a1Y4F11VpzAz6NgxGc6pQT1gQGgKHzcuhLpq2SLpT/+NRZpA165wyCFhSlVcDAsWhLuAbd0api1bqn5cvhw+/hhWrAidywBat4ZRo5LhnJh69mz6YxSRPacwFolR69ahN/bo0XV/TXFxqF3PmhWmjz+Gl1+G++9PbtOzZwjlQYNCbb1Ll1CrTn1Mnc/NbfhjE5G6UxiLpJnWrZM9t1OtXx+CORHSs2bB7NnhPHZRUc37bNs29P7Ozw/T4MHJ+fz8sE7nsEUaj8JYJEP06AFHHhmmyoqKQnP35s3Jx8rzK1fCkiUwZUq4E1mq3NxQy06E86BB4dz1wIHhsX//8CNBRPaMwlikBcjLC3cS6927btvv2BEu01qyBBYvDo+J6emnQy28sl69kuGc+tinT2g279Ur9BLXtdciu1MYi8hu2rZNXhddlZ07Q0eyZctCx7LUx7lz4aWXwo1SKmvdOhnMPXvuPt+nD/TtG6aOHRXc0nIojEWk3tq0CZdV7bNP1evdQxP4smWwZk24znrdutD8nXhcsyZcj71uHZSU7L6Pdu2SwVzVlJ8fmsd1LlsyQa1hbGb3AccD69x9TBXrDbgNOA7YAZzn7jMauqAikj7Mkj22K3c0q8w9XLq1dm24xGvVqt2n998P57Qrd0Rr3Tp0Nhs6FIYNC4+J+fx89RKX9FGXmvFfgTuAv1Wz/lhgn2g6CPi/6FFEpFZmyRubDB9e/XaJ0F61KgTz4sXhGu2FC8P0+usVm8ZbtQrnrSuHdGK+fftGPzSROqs1jN39TTPLr2GTycDfPNxX8z9m1tnM+rj76gYqo4hIhdAeNWr39e6hyXvhwoohvWBBGJd6w4aK2/fsuXtQDxsG48erZ7g0vYY4Z9wPWJ7yfEW0bLcwNrPzgfMBBg4c2ABvLSISmIXOYL16waGH7r5+69aKAZ2YnzoVHngguV2HDnDssXDSSeGxc+emOwZpuZq0A5e73w3cDWGgiKZ8bxFp2Tp1ggMOCFNlO3eGZu958+DFF+HZZ+Gxx8J9vydNCsF84omh2VukMTREP8SVQOo/0f7RMhGRtNCmTWj6PvlkuOeecF763/+Gyy8PPcIvuSRcMz1hAtxwQ7i7WUwD3kmGqtMQitE54ynV9Kb+GnAJoTf1QcDt7j6xtn1qCEURSRfz5sEzz4QbnvznP2FZfj4ceGDF883DhkG/frrcSqq3x+MZm9nDwCSgO7AWuBbIAXD3u6JLm+4AjiFc2vRtd681ZRXGIpKO1qyB556DF14IIb1oEezalVzfujUMGZIM56FDw/M2bZLbpN7MJDFf3bKa5lu1St4sJSen4Y9VGt4eh3FjURiLSCYoKwt3I1uwIDklOoktWBDORzc2sxDK/fpVPyVuhVpcHH48pE6Vl5WWhruwdewYOrSlTllZjX88may6MNYduERE9kJWVhg4Y9AgOOqoiuvcw41MFi9O3mUstf6TmK9uWW3zpaXhZikrVyanpUvhnXdg48aGPc6Etm1DKKcGdV5e3abc3PA5lJSE0K/8mDpvFjrMpY4eNmBA5t7IRWEsItJIzJK372xqRUXJG6SsXBlCu1Wr0Iyem1txqrwsKysMFlJQANu2hcfEVPl5QUG49WlRUdVTcXHN5czODk3subkVH8vLQ/nLypLbmoVafmpADx4cLmfbubNimQoLdy9nQUEI+o4dk9esd+qUnK/q+aBBTdMaoDAWEclAeXnhXPWQIfGWo7w8BGBRUXjMzk4Gbk5OzZ3dSkuTQ3tWHj3srbfg738P+69KTs7uTewdO4YfHtu2hf1t2RKuP9+6tfoybNoUbuva2BTGIiLSaFq1SjZT11d2dvIUwBFH7L6+pCRZ6080nyem+jRnl5Ula/hbt4bHxNSxY/3LvScUxiIikpZycpLN1XsjKyvZLB0XXQ0nIiISM4WxiIhIzBTGIiIiMVMYi4iIxExhLCIiEjOFsYiISMwUxiIiIjGLbaAIM1sPLG3AXXYHNjTg/poTHVt60rGlJx1b+kmn4xrk7j0qL4wtjBuamU2raiSMTKBjS086tvSkY0s/mXBcaqYWERGJmcJYREQkZpkUxnfHXYBGpGNLTzq29KRjSz9pf1wZc85YREQkXWVSzVhERCQtZUQYm9kxZvapmS0wsyvjLk9DMrMlZvaxmc00s2lxl2dvmNl9ZrbOzD5JWdbVzF4xs/nRYxMM493wqjm268xsZfTdzTSz4+Is454wswFmNtXM5pjZbDO7NFqe9t9bDceWCd9bnpm9b2YfRcf2q2j5YDN7L/pb+aiZ1WPU3+ahhmP7q5ktTvnexsdd1vpI+2ZqM8sCPgO+AqwAPgDOcPc5sRasgZjZEmCCu6fLNXTVMrMvAYXA39x9TLTsd8Amd785+iHVxd1/Fmc590Q1x3YdUOjuv4+zbHvDzPoAfdx9hpl1AKYDJwHnkebfWw3H9k3S/3szoJ27F5pZDvA2cClwOfCkuz9iZncBH7n7/8VZ1vqq4dguBKa4++OxFnAPZULNeCKwwN0Xufsu4BFgcsxlkiq4+5vApkqLJwP3R/P3E/4Ypp1qji3tuftqd58RzRcAc4F+ZMD3VsOxpT0PCqOnOdHkwJFAIqzS9Xur7tjSWiaEcT9gecrzFWTIf6iIAy+b2XQzOz/uwjSCXu6+OppfA/SKszCN4BIzmxU1Y6ddU24qM8sH9gfeI8O+t0rHBhnwvZlZlpnNBNYBrwALgS3uXhptkrZ/Kysfm7snvrdfR9/bH82sdYxFrLdMCONMd7i7HwAcC1wcNYdmJA/nTNL+F26K/wOGAuOB1cAf4i3OnjOz9sATwGXuvi11Xbp/b1UcW0Z8b+5e5u7jgf6EFsQRMRepwVQ+NjMbA1xFOMYvAF2BtDptkglhvBIYkPK8f7QsI7j7yuhxHfAU4T9VJlkbnbtLnMNbF3N5Goy7r43+aJQD95Cm3110Xu4J4CF3fzJanBHfW1XHlinfW4K7bwGmAocAnc0sO1qV9n8rU47tmOi0g7t7MfAX0ux7y4Qw/gDYJ+olmAucDjwbc5kahJm1izqWYGbtgP8CPqn5VWnnWeDcaP5c4JkYy9KgEmEV+Tpp+N1FnWXuBea6+60pq9L+e6vu2DLke+thZp2j+TaEDq5zCcF1SrRZun5vVR3bvJQfh0Y4F55W31va96YGiC49+BOQBdzn7r+OuUgNwsyGEGrDANnA39P52MzsYWASYYSVtcC1wNPAY8BAwihe33T3tOsIVc2xTSI0dTqwBLgg5TxrWjCzw4G3gI+B8mjx1YRzq2n9vdVwbGeQ/t/bOEIHrSxCpesxd78++pvyCKEZ90Pg7KgmmTZqOLZ/AT0AA2YCF6Z09Gr2MiKMRURE0lkmNFOLiIikNYWxiIhIzBTGIiIiMVMYi4iIxExhLCIiEjOFsYiISMwUxiIiIjFTGIuIiMRMYSwtXjSY/IONuP/ZZjYpmjcz+4uZbY4GSP+imX3aCO850MwKo/G+RaSZUxhLi2BmZ5rZtCigVpvZi9HtEBudu49299ejp4cT7qXb390nuvtb7j58b9/DzJaY2dEp77nM3du7e9ne7rua9zMzW2Rmcxpj/yItjcJYMp6ZXU64d/lNhHF3BwJ3ApNjKM4gYIm7b4/hvRvSl4CewBAz+0JTvnHKqEMiGUNhLBnNzDoB1wMXu/uT7r7d3Uvc/Tl3v6Ka1/zDzNaY2VYze9PMRqesO87M5phZgZmtNLOfRMu7m9kUM9tiZpvM7C0zaxWtW2JmR5vZd4E/A4dENfRfmdkkM1uRsv8BZvakma03s41mdke0fKiZ/StatsHMHkoZueYBwg+M56L9/tTM8s3ME8FlZn3N7NmobAvM7Psp73mdmT1mZn+Ljmu2mU2o5aNNjPjzAsnRmxL7G21mr0TvtdbMro6WZ5nZ1Wa2MHqf6dHxVihrtO3rZva9aP48M/u3hQHjNwLX1fR5VPc5mlluVKaxKdv1NLMdZtajluMVaVQKY8l0hwB5JEe/qosXgX0INb8ZwEMp6+4ljOLTARgD/Cta/mNgBWHUmF6E0X8qjMLi7vcCFwLvRk3I16auj87vTiGMgpQP9COMsANhJJrfAH2BkYQxvK+L9nsOsAw4Idrv76o4pkei8vUlDKF3k5kdmbL+xGibzoThEe+o7sMxs7bRPh6KptMtDF+KhSE/XwX+Gb3XMOC16KWXE0ZEOg7oCHwH2FHd+1RyELCI8Nn+uqbPo7rP0d13Rcd4dsp+zwBec/f1dSyHSKNQGEum6wZscPfSur7A3e9z94JoaLnrgP2iGjZACTDKzDq6+2Z3n5GyvA8wKKp5v+X1HxJtIiFcrohq8EXu/nZUpgXu/oq7F0fBcStwRF12amYDgMOAn0X7nEmooX8rZbO33f2F6BzzA8B+NezyZKAYeBl4HsgBvhatOx5Y4+5/iN6rwN3fi9Z9D7jG3T+NBoH/yN031uUYgFXu/j/uXuruO2v5PKr9HAlD751hZhY9Pyc6XpFYKYwl020Eutf1PGPUlHpz1JS6jTCeLYRxigG+QajZLTWzN8zskGj5LcAC4OWoY9OVe1DWAcDSqn44mFkvM3skahrfBjyYUqba9AU2uXtByrKlhBpjwpqU+R1AXg2f2bmEMWRL3b0IeIJkU/UAYGE1r6tpXW2Wpz6p5fOo9nOMfhjsACaZ2QhCzf3ZPSyTSINRGEume5dQizupjtufSejYdTTQidDMCaFZFHf/wN0nE5qwnwYei5YXuPuP3X0Iocn3cjM7qp5lXQ4MrCYEbyI0e491946EplZLWV9TLXwV0DVqQk4YCKysZ/kws/7AkcDZ0Xn1NYQm6+PMrHt0DEOqeflyYGgVyxOd2dqmLOtdaZvKx1fT51HT5wihdnw2oVb8ePSDQiRWCmPJaO6+Ffgl8L9mdpKZtTWzHDM71syqOrfagRDeGwnhcFNiRdQB6Cwz6+TuJcA2oDxad7yZDYuaP7cCZYl19fA+sBq42czamVmemR2WUq5CYKuZ9QMqdz5bSzUh6O7LgXeA30T7HAd8l1CbrK9zgM+A4cD4aNqXcD76DMK52j5mdpmZtTazDmZ2UPTaPwM3mNk+Fowzs25RM/NKQsBnmdl3qDq0U9X0edT0ORId99cJgfy3PfgMRBqcwlgynrv/gdB56BpgPaHmdAmhZlvZ3whNuCuBOcB/Kq0/B1gSNY1eCJwVLd+H0HGpkFAbv9Pdp9aznGXACYSm02WEgDstWv0r4ABC0D8PPFnp5b8BrrHQm/snVez+DEItfxWhM9u17v5qfcoXOZdwbGtSJ+Au4NyoKfwr0XGsAeYDX45eeyuhJeFlwg+Ze4E20brvEwJ1IzCa8OOhJtV+HrV8jokfJzMINeu36v8RiDQ8q38fExGR9GZm9xE6hV0Td1lEAHTxvIi0KGaWT+gRvn+8JRFJUjO1iLQYZnYD8Alwi7svjrs8IglqphYREYmZasYiIiIxi+2ccffu3T0/Pz+utxcREWly06dP3+Duu90LPbYwzs/PZ9q0aXG9vYiISJMzs6VVLVcztYiISMwUxiIiIjFTGIuIiMRMYSwiIhIzhbGIiEjMFMYiIiIx072pRUQkLW3eDB9+CIsWQdu20LEjdOiw+2NeHphVfG15OWzdChs3Vj9t2gQPPAA5OY1/LApjERFp9lavhhkzQvh++GGYX7Kkbq/Nzk6Gc25uCPFNm0IgV8UMunSBbt2goAC6dm2ww6i+jI3/FiIiEpfiYpg/HxYsgNLSiutSa4up8+5QVha2r24qKUk+FhdDUVFyqvw8MZWUQLt20L59CMfEY1XzALNmJYN37dpk+fbZByZOhAsugP33h+HDw3tu2xbCs6bH4uJk0FY3de4MrZr4JK7CWEQkZmVlIahKSsJ8mzbQunX99rFjB8ybB3Pnwpw5YZo7N4RwWVnjlDshNzeUNy+v6ql9e+jePdRQd+wIwbhuHRQWhvnCwhDWlWVlwejRcMwxIXQPOAD22y/UcDONwlhEZC/s3BlqbanTmjUV59evT9YMq5qqGjwvJyeEWGJK1BhT53Nzw/nSOXNCk21iP9nZofY4ejSceiqMGhWe5+Ul95/6npXf3z28f3Z23aaGqEWWlIRQTgR0aSnsu2/FMmcyhbGISD2UlsJDD8Ftt8HChaHpsypdukCvXmEaNy7UdnNyap+yskLApwZTYr6wEJYuTc7v3An5+XDQQfDtb4fQHTkShg0LQZ1OcnLCZ9alS9wliYfCWESkDkpL4eGH4YYbwjnY/faD885LBm7v3sn5nj3r38wsLZvCWESkBmVl8MgjcP318NlnIYSfegomT979chmRPaWbfoiIVKGsLNSEx4yBs88ONd0nngg9e086SUEsDUthLCKSorwcHn0Uxo6FM88MHZT+8Q+YORNOPrnpL3mRlkHN1CLS4m3bFnolf/QR3HILzJ4dOkM9+iiccooCWBpfncLYzI4BbgOygD+7+82V1v8R+HL0tC3Q0907N2RBRUT2VFkZrFgRAreqacOG5LYjR4ZzxKecEno2izSFWsPYzLKA/wW+AqwAPjCzZ919TmIbd/9RyvY/BPZvhLKKiNSquDjUcN9/P0wffBAuQSopSW6TnQ2DBsGQIfCNb4THIUNg6NBwGZJCWJpaXWrGE4EF7r4IwMweASYDc6rZ/gzg2oYpnohI9crLw2VG778P770XHmfOTAZvr17htoknnZQM3CFDYMCAEMgizUVd/jn2A5anPF8BHFTVhmY2CBgM/Kua9ecD5wMMHDiwXgUVkZbNHRYvDr2ZZ8wINd4PPggj70C4I9WECfCjH4UAnjgR+vdXr2dJDw392/B04HF3r/JOqO5+N3A3wIQJE6q4AZyISDjHO39+MngTo/Vs2RLWZ2eH5uQzzkgG74gRal6W9FWXMF4JDEh53j9aVpXTgYv3tlAi0jLs3AnLloVbPC5ZAh9/HIJ35swwoACE63v32w9OPz05WMCYMS3nnsXSMtQljD8A9jGzwYQQPh04s/JGZjYC6AK826AlFJG0tXVrCNmlS6ue1q2ruH27diFwv/e9ELoHHBBqvE0xuLtInGoNY3cvNbNLgJcIlzbd5+6zzex6YJq7PxttejrwiHtV44+ISCbatSuE6uLF4RKhyo+bN1fcPi8PBg4MPZn32y88JqaBA8Oka3qlJbK4snPChAk+bdq0WN5bRGpXVhZqritXhmnFiuT80qUhbFesqDj8Xm5uGEVo8ODQa3nw4PA8Ebg9e6pDlbRsZjbd3SdUXq7O/SItzM6dIWQT09q14XHVqmTYrlwJq1fvPih9Vhb06ROCddKkiqE7ZAj07auarcieUBiLZJiystAJ6l//ggULKgbvunVhHNyqdOwI/fqF6aijym+moAAAIABJREFUkvOpU8+e6rEs0hgUxiJpzh3mzoXXXgsB/PrryUuAEmPs9uwZ7i7Vs2fVU48eofOUiMRDYSyShpYtC+GbCODVq8PywYPDPZWPOgq+/OUQxCLS/CmMRZqZHTuS53FTz+km5hP3WoYQtkceGcL3yCNDGItI+lEYizSxnTvhs89C03JiWr48Gbrbt1f9uo4dQ5PyqFHwwx+GAB49Wr2TRTKBwlikkWzZUjFwE9PixcnLgVq1Cr2Q8/PDOd3E+d3ElHjeowe0aRPr4YhII1IYizSQ5ctD56mpU8Pj4sXJda1bw777hoEMzjknjJk7cmRYpts6iojCWGQPrVqVDN+pU5Pncbt0gSOOgAsuCE3KI0eGc7m6JEhEqqMwFqmjjRvh1VeT4fvZZ2F5p//f3p2HR1Xe/R9/f7MRlgABIiBBSREFBQoSEcXys67QVtA+7lr154JP1aq1T1usPtZqtVatrbbuilbrWq0VFYsLUCoRJSDKvooSEBJiEsISst3PH/fEDCEhEzLJyUw+r+uaa2bOnJn5Hk44n7nPct/dfPhefbU/g3n4cHV8ISJNozAW2Yddu+CNN+Bvf4O334bKSkhLg3HjYPJk3wvViBFq9YpI8yiMReqoqoJ//9sH8CuvQGmp7+bx+uv9NbyjRvnxdEVEokWbFJGQzz7zAfz8875v5rQ0H74XXuh3Q6v1KyItRWEs7VphITz5pA/hxYt9i3fCBLjvPjjtNF1OJCKtQ2Es7VZVFZx6KixYAMccAw8+CGefDb16BV2ZiLQ3CmNptx5+2Afxc8/B+ecHXY2ItGe6AEPapa++gptugpNPhvPOC7oaEWnvFMbSLv3P/0BZmd81rb6dRSRoCmNpd2bO9GdMT5kCgwYFXY2IiMJY2pndu+Gqq/ygDFOmBF2NiIinE7ikXfnDH2DlSt+bli5bEpG2Qi1jaTc+/xxuv9135DF+fNDViIjUiiiMzWy8ma00szVmVu/OPTM728yWmdlSM3s+umWKNI9z8JOf+F60/vjHoKsREdlTo7upzSwReBA4GcgD5pvZNOfcsrB5BgE3AmOdc0VmdkBLFSyyP15/Hd56C+69FzIzg65GRGRPkbSMRwNrnHPrnHPlwIvApDrzXAE86JwrAnDO5Ue3TJH9t2MHXHstDBvm70VE2ppIwrgfsCHseV5oWrhDgUPNbK6ZzTOzeo/ImdlkM8s1s9yCgoL9q1ikiW67DTZs8D1uJScHXY2IyN6idQJXEjAIOB44D3jczLrXnck595hzLts5l52RkRGlrxZp2NKlftCHSy+FsWODrkZEpH6RhPFGoH/Y88zQtHB5wDTnXIVz7nNgFT6cRQLjnL+muGtX+P3vg65GRKRhkYTxfGCQmWWZWQpwLjCtzjz/xLeKMbNe+N3W66JYp0iTPfsszJnjg1gjMYlIW9ZoGDvnKoFrgBnAcuBl59xSM7vNzCaGZpsBFJrZMmAW8HPnXGFLFS3SmKIi3//0mDF+F7WISFsWUQ9czrnpwPQ6024Je+yAG0I3kcD96ldQWAjvvAMJ6tpGRNo4baYk7nzwATz6qL+MacSIoKsREWmcwljiQnk5vPKKH5/4O9+BAw+E3/wm6KpERCKjMJaYtnatH32pf3846yxYtcpfV5yb68+iFhGJBRq1SWJOebnv3vKxx+C993x/0z/4AUyeDKee6p+LiMQShbHEjLVr4fHH4amnID8fDjrIt4IvvRT61e0TTkQkhiiMpU2pqvJdV65evfdt1Srf6j3tNN8KPuUUtYJFJD4ojCUweXl+JKXwwF271u+GrtGpEwwa5Ad5uOQSuOgitYJFJP4ojKXVlZXBPffA734Hu3ZBaioccggMHuxbvYMG1d769gWzoCsWEWlZCmNpNc75E69uuAE+/xzOPBNuvx0OPVQdc4hI+6ZNoLSKFStg/Hg44wy/6/n99+Hvf/etYQWxiLR32gxKi9q2zfcRPWwYfPQR3H8/fPIJnHBC0JWJiLQd2k0tLaK6Gp55xnfIkZ8Pl10Gd94JGsZaRGRvCmOJuvnz4Sc/8S3hMWPgzTchOzvoqkRE2i7tppaoqKz0oXv66TB6NKxfD3/9K8ydqyAWEWmMWsbSLGvWwNSp8PTT8NVX0Ls33HQT/OIX6htaJGZV7oLEVF1X2IoUxtJku3bBq6/Ck0/C7Nn+bOjvfQ8uv9zfJycHXaFIjHLVsOMLsCRI6Q5JXVovEHd/DV++DOv/BgVzIaUHdBsCXQ8P3Q+BbodDp/7xH9LOQVk+lK6EA8a1ylcqjCViCxf6AH7uOSgpgYED/UlZF1/shywUaZLqKtjxOZQsh23LYdtKv6HvcwL0HAOJKUFXuCdXDaVr4OsFULQQipdAxz7QfXjtLbWJZyiWbYXCj2DrPH9f+DFUlNS+bgmQ1NUHc3I3SOkGyWGPU3pA+reh59HQaT+6pqsqg41v+QDe9BZUV/jAPeJXsLsQSpZB3muw9vHa9yR19sFcE87dDof0kdApMzZDurwIipdCyRK/TktCj3dv9a+f+TWkpLd4Geaca/EvqU92drbLzc0N5LslchUV8Le/wQMPwKJFvresM8/0Z0ePG6drhONGdZXf8LfExrSqHEpXw7ZlPnhLltWGb/Xu2vk6ZIQ2gA4SO0LGd3ww9z4B0o+EhFbsiNxVw7ZVPnS/XhAK4E+gYpt/PaGDby3u2gxlm2vf17HvnuHcfTh0Hex/WFSVQ9GiPcN3+1r/Pkvw8/Y8GnqM8tMqSqC8OHRfAhV1HpeXhII7tA3vlOnf32uM/zHT40hI6lT/shV8AJ8/C1/+3X9Gah8YcD4MuBDSR+z9d1BW4NdZ+PorWQa7NtbO0yHD197jyND9KOh0UOR/UxXb/Y+z7aHbrjyo3Ol/MFSVQdUuf19d5nejV5fVvuYq/Y+EpDRITmv4PjnNt3q3LQ8F7xLYtam2hqQ06D4Uuh0B3Yb6xxnHQWKHyJYhAma2wDm315k0CmOp165d/ljw3XfDl1/C8OFw5ZVw/vnQvXvQ1cU4V+03NsWL/a1kCWCQPhy6f9tvlFuilVFdCTu/hG2rYfsaH5Clofsdn0NC6t4bom5DIfWAyGopL4ZtK/a8lSz3geOqQjMZdB6w527PrkP885TuvpWSPwc2z4Qt7/tWCviWYO/jfTD3PsHX2NR/H+egstR/R3nxnvcVofvdhX6dFH0Cldv9+xJT/XqpCZgeo3zdCaHjMWX5oXX5mb8VfebrrvmhYUnQJQt2fFk7reOBodAMhWePUT5Mmqpqtw/4rfOgcB5s/civSwBL9HX3OtqHc9ohsPFNWP+c/ztI6gyZP4SsH/l/0/35sVNe4kM5/EdLydLa9d2hJ6SPqg3prof5HzA7Poft62qDd8fntS3RGompvsaEVP84sWPovs7zhFRfe+UOqCj167iidM/H4T/6aj676+G1f+M1f/etsAteYSwRKS2FRx6BP/wBtmyBsWP9CVnjx8fmHqhGbf0YtsyMfP6ElNpdhXV3GSZ333vX6jcb6rBbyVKo2hmawfyG2lXDjvW170vuHgrnmtu3ofsRe2+wnfOttYo64VJz27lhz8Ctrqh9b1Jn6HIIpA2CtIG+ZVISai3sLqydr0OvOgF9hG+x1A3e8BZiQjKkHeo3vuGh2/Ww+ltrDdm1BbbM8utoy8zalmSHDP8jAef/DQjdXHWd5w6oDm2ci/3rDTK/LrsN8eGRfmRY8DbxiF51pf83L/rUB3TpSujyrdrw7ZTZtM9rirJ8H8o14Vz4sQ8l8AHd5xTIuhAyJ+3fD4DGVJX5HyRFoXD+eqH/u3eVe86XkAydDvZ//12yoHOd+w69orfRqa6oDWdX7VvsrbmnJYzCWPbp66/hz3/2PWQVFcHJJ/sQHjcuTkPYVcPS38HiWxrZQDdRYmptUJcX+Q1jjQ4Z0H1Y7a3bsD0DtrwkdNwq1LqqaWnVtNAw37pJ7lobvI0FTGKnUNjWhG7Y49Q+9a/cmpNXSkLHz2p255Usrd1NWyMlPRSyg/e8dclqeoBFYscXvtWc/+9QwJi/WULo3sKmGRDa9Z6U5lveKem198k1z0PTkruGPifOVFfV/mDKOA469m79Gqp2+0AuXQOdDvSB2/HAwAIxSApjqdeWLXDfffDQQ7B9O0yc6EN49OigK2tBZfmQ8yPY/A4cfB5k/znyFkJVWf3H7WqO7X0zrdifCRsevPuzEaxpMYeHc9WusCBpLGC6Re/XlHOwM8+HclInH7odMuL015pIy2gojCP66Wpm44H7gUTgCefcXXVevwS4B6g5mv8X59wTzapYWtSmTX4Iwyee8OMHn302/OpXvg/puLZlNuSc71uWox+DgZc3LUwSU33ItcDevXpZgt+92eVb0P/0VvrShmox6Nzf30QkqhoNYzNLBB4ETgbygPlmNs05t6zOrC85565pgRolisrK4I9/hDvugN274aKLfP/RgwYFXVkLq66CpXfCklv9cdLj/+WPyYqItAGRtIxHA2ucc+sAzOxFYBJQN4ylDXMOpk3zYwmvWweTJvmTtAYODLqyVrBrC3x4IWx+DwZcAEc97C9xEBFpIyI5W6EfsCHseV5oWl3/ZWafmdkrZqb9WG3IsmVw6qm+3+gOHeCdd+Cf/2wnQbx5Jrw9wl9XefQTcMyzCmIRaXOidergG8AA59xw4F3gr/XNZGaTzSzXzHILCgqi9NXSkKIiuO46f43w/Pn+TOlPP/VnSreYqnJ/HWs0z1DeH9VVsPg3MPMkf4z31I9h4GU62UhE2qRIdlNvBMJbupnUnqgFgHMu7KJEngDuru+DnHOPAY+BP5u6SZVKxKqq4PHH4eabfSBPngy33dYKYwmXbYXZ4/21hcnd/WUUB3zH9+2afmTrdG/onO/ZKfdqf13qgB/BUQ9BcpeW/24Rkf0USRjPBwaZWRY+hM8Fzg+fwcz6Oue+Cj2dCCyPapUSsTlz4NprfQt43DjfGh4xohW+eOcmmHWy71Xn23f6+/w5sOlN/3piR+h1jO/i8IBxvuODpnT+0JDqKn8NbP5/oGCOvy/b7L/v6KnwrUvUGhaRNq/RMHbOVZrZNcAM/KVNU51zS83sNiDXOTcNuNbMJgKVwNfAJS1Ys9Rjwwb4+c/hpZegf39/f9ZZrZRD29fB+yfB7gI4/m3fbWGNXVug4D+1YbnkNsD5LgJ7ZPsejjr2gdTevkel8Pv6rv2tKvct75rgLfigtmP9Tv2hz4k+8A+cAJ0PaoWFFxFpPnX6EePKyvxZ0XfeCdXV8Mtf+rGEO0Wh0RmRkmUw82TfEcXx/4JejfQWUl4CW3N8qzl/TqhXp5L6503stGdAV5T6zvWrdvnXuw6ubWkf8B3ofHB0l01EJMqa1emHtE1vvgnXXw9r18IZZ/ietAYMaMUCvl4As04FS4aT5vh+ixuT0s23Wg+cUDutardvVZdt8b1j7XWf7zvZT0iCQyb78M04LtQ3sYhI7FMYx6DVq30IT58Ogwf7S5Va9Azp+uT/B2Z/Hzr0gBPe8/0d76/EDr7j/JbsPF9EpA2Lw17R49f27XDjjTB0KPznP3Dvva1wqVJ9Nv3Lt4g79YOTP2heEIuIiFrGscA5ePFFf4LWxo2+C8u77oK+fQMo5stXfN/O3YbCd2dAaktfLyUiEv8Uxm3c0qVw1VX+kqUjj4SXX4Zjj43CBxcv8ePEdj7YD6fX5Vt+d/G+rH0KPr7cX6L0/970nWmIiEizKYzbqPJy3/r97W8hLQ0efRQuuwwSmzv8Z+ka+OzX8MUL+AHYQyzBD7hdM9Ztl7Dxb7tkwepHYOH1fmDycf9omUHJRUTaKYVxGzR/vg/exYvhvPN8xx3N7j1rxwZYcjusmwoJHeDwX/ozk8vyoXS1D+nS1f62/gU/Hm8NS/DdW2aeAWNfaLwFLSIiTaIwbkN27oRf/9pfotS3rx9l6bTTmvmhZfmw9Hew+mHAwaCr4YgbfUcb4Fu9vY7e+327C/cM6aQuMPin/vIiERGJKm1Z24jZs+GKK2DNGt+X9N13Q7duzfjA8mJYfi+s/JPvJCPrEhh2S+QdY3To6W+9xjSjCBERiYTCOGAlJb7XrEcf9UMazpwJ3/1uMz6wcgesfACW3e13NR90Dgz/DXQ9LGo1i4hIdCmMA/TWW3DllfDVV/Czn/mRlfbqxrKqHArn+W4kK7f7sK3cHnYLPa8IPS9a6HdNH/gD+PbtkN4ao0SIiEhzKIwDUFjoR1Z6/nnfgcc//gGj6+vSuegz+PAiKP60/g9KSPHHcpO6+CECk7pAr7Ew5OeQcUyLLoOIiESPwriVvf++77SjoABuvdX3qJVSd5jf6kp/vHfxLZDSA4551u9mDg/exM6tMz6wiIi0OIVxK9m9G26+2XdhOXiw30Vd7zjD21b71nDhPOh/Jhz1MKT2avV6RUSk9SiMW8Hy5XD++bBoEfz4xz6Q9zo27Kph1UOw6Bf+OuBjn4ODz2ulAYlFRCRICuMW5Bw88gjccAN06bKP64Z3bIB5/x+2vA99x8PRT/hBGEREpF1QGLeQggLfi9Ybb8Cpp8LTT0OfPnVmcg4+fwYWXAuuCkY/CgOvUGtYRKSdURi3gH/9Cy65BIqLfVeW11wDCXUHq9y1BeZfCXmvQ8Z34Jin/WANIiLS7iiMo6isDKZM8QF8xBHw7rswbFjYDK4aCj+GvGmw9nGoKIWR98Jh10NCc0eAEBGRWKUwjpJ162DSJFiyxF9DfNdd0LEjULkTNr8HG6fBxjehbAtYIvQ+AUb9CbodHnTpIiISMIVxFGzYACecAKWlMH06TDh+sw/ejdNg87tQVQbJXaHvBMicCAdOgJT0oMsWEZE2QmHcTJs3w4knQsXOUj574S/0c6/Dax/5Fzsf7E/IypwIGePUSYeIiNRLYdwMW7fCSSdBSeF2Vj82ga5b50KPo2D47dBvInQfpjOjRUSkUXXP8a2XmY03s5VmtsbMpuxjvv8yM2dm2dErsW0qLoZTToGNX+5ixaMT6Vr+IYx9CcZ/DENvhvThCmIREYlIo2FsZonAg8AE4HDgPDPb66wjM0sDrgM+inaRbU1pKUyYAKtW7GbVkz8kvXw2jPkrHHx20KWJiEgMiqRlPBpY45xb55wrB14EJtUz3+3A74GyKNbX5uzc6XvR+mRhBaufOoeMin/B6Mcg68KgSxMRkRgVSRj3AzaEPc8LTfuGmR0J9HfOvbWvDzKzyWaWa2a5BQUFTS42aLt3wxlnwNwPKln11AX0rXodRv0ZDrk86NJERCSGRXTMeF/MLAG4D/hZY/M65x5zzmU757IzMjKa+9WtqqICzj4b3n23muVPXcpB/D3UYcc1QZcmIiIxLpIw3gj0D3ueGZpWIw0YCsw2s/XAGGBaPJ3EVVUFP/oRvPFGNYufvJJDEp/1Z0wPafT3h4iISKMiCeP5wCAzyzKzFOBcYFrNi865EudcL+fcAOfcAGAeMNE5l9siFbey6mq4/HJ46SVH7iPXcUSHJ+CIm/wZ0yIiIlHQaBg75yqBa4AZwHLgZefcUjO7zcwmtnSBQXLOD/Lw9NOOuX/5BUd2+QsMvsG3ikVERKIkok4/nHPTgel1pt3SwLzHN7+stuGJJ+Dhh+G9+37Nsen3wqCr/HFiXT8sIiJR1OwTuOJVSQncdBM8eu2dnNj7dhh4GWT/WUEsIiJRpzBuwB13wAWj/sTko2+CARfAUY+C6Z9LRESiT31T12PNGihZ+ASPXvpT6P9DGPO0xhsWEZEWo6ZePab9+QUevmQyZT0mwLEvQIJ+s4iISMtRGNex+O3XuTb7R2woH0fqSa9q2EMREWlxCuMwVRvf5bCCs1myaRS9z3oDkjoGXZKIiLQDCuMa+R9QPft0lm8czPqst0lNSwu6IhERaScUxgBfL8DN/j5fFGTyv7PeYdJZPYKuSERE2hGdmVS8FGadSvHOdE747Xu8NqO3LiUWEZFW1b5bxqVrYOZJVFancOzN73Piaf0ZNSrookREpL1pvy3jHRvg/RPBVfA/0+ewoXgg798RdFEiItIetc+W8a7NMPNEqChmQdd3uP/pw7nxRjjwwKALExGR9qj9tYzLS2DWKbBzI1XHv8sVE47koIPghhuCLkxERNqr9hfGi38DJUvhuzN4+s1j+eQTePFF6KhLikVEJCDtazd16RpY/Rf41qVs63QSN90Exx4LZ58ddGEiItKeta+W8aIpkJACw2/nd7fBli3wxhsaFVFERILVflrG+R/AhldhyC/5fHMf7rsPLr4Yjjoq6MJERKS9ax8tY1cNn/wMOh4IQ37GL86DpCS4886gCxMREWkvYfzFS1D4MYx5igWfduKVV+D223Upk4iItA3xv5u6qgw+vRHSR0DWRcyY4Sf/+MfBliUiIlIj/lvGK++HHV/A0VPBEsjJgSFDoGfPoAsTERHx4rtlXFYAS++EA38AfU6guhpycmDs2KALExERqRVRGJvZeDNbaWZrzGxKPa//t5ktNrNFZvaBmR0e/VL3w+JboXIHjLwHgJUroajIX1ssIiLSVjQaxmaWCDwITAAOB86rJ2yfd84Nc86NAO4G7ot6pU1VshzWPAqHXAndBgMwd65/SWEsIiJtSSQt49HAGufcOudcOfAiMCl8BufctrCnnQEXvRL30ye/gKTOMOzWbybl5PhjxYceGlxZIiIidUVyAlc/YEPY8zzg6LozmdnVwA1ACnBCfR9kZpOByQAHHXRQU2uN3OaZsOlNGHEXpGZ8M3nuXN8qVo9bIiLSlkTtBC7n3IPOuYHAL4GbG5jnMedctnMuOyMjo75Zmq+6ynfw0flgOOy6byZv3QqrVunkLRERaXsiCeONQP+w55mhaQ15ETi9OUU1y/pnoWgRfPt3kJj6zeScHH+v48UiItLWRBLG84FBZpZlZinAucC08BnMbFDY0+8Dq6NXYhNU7oBPb4Keo+Hgc/d4KScHkpMhOzuQykRERBrU6DFj51ylmV0DzAASganOuaVmdhuQ65ybBlxjZicBFUARcHFLFt2g5X+AXZtg7Et7HRjOyYEjj9S4xSIi0vZE1AOXc246ML3OtFvCHl+315ta266vYPnd0P+HcMBxe7xUXg7z58NVVwVUm4iIyD7ETw9cn/0vVJfDiN/v9dInn0BZmY4Xi4hI2xQfYVz0GaydCoOuhrRD9npZnX2IiEhbFh9hnJACmafD0P+t9+WcHMjKgr59W7kuERGRCMTHqE3dBsO4f9T7knO+ZXzSSa1ck4iISITio2W8D+vXw+bN2kUtIiJtV9yHsY4Xi4hIWxf3YZyTA2lpMHRo0JWIiIjULz6OGe/D3LkwZgwkJgZdiYhI+1ZRUUFeXh5lZWVBl9LiUlNTyczMJDk5OaL54zqMt22DxYvhhz8MuhIREcnLyyMtLY0BAwZgcTx8nnOOwsJC8vLyyMrKiug9cb2b+qOP/NnUOl4sIhK8srIyevbsGddBDGBm9OzZs0l7AOI6jOfOhYQEOHqv0ZdFRCQI8R7ENZq6nHEdxjk5MGwYdO0adCUiIiINi9swrqqCefNg7NigKxERkbaguLiYhx56qMnv+973vkdxcXELVFQrbsN4yRIoLdXxYhER8RoK48rKyn2+b/r06XTv3r2lygLi+Gzqms4+1DIWEWl7rr8eFi2K7meOGAF/+lPDr0+ZMoW1a9cyYsQIkpOTSU1NJT09nRUrVrBq1SpOP/10NmzYQFlZGddddx2TJ08GYMCAAeTm5rJ9+3YmTJjAcccdR05ODv369eP111+nY8eOza49blvGOTl+YIiDDw66EhERaQvuuusuBg4cyKJFi7jnnntYuHAh999/P6tWrQJg6tSpLFiwgNzcXB544AEKCwv3+ozVq1dz9dVXs3TpUrp3786rr74aldriumU8diy0kxP3RERiyr5asK1l9OjRe1wH/MADD/Daa68BsGHDBlavXk3Pnj33eE9WVhYjRowAYNSoUaxfvz4qtcRly3jTJj9AhI4Xi4hIQzp37vzN49mzZ/Pee+/x4Ycf8umnnzJy5Mh6rxPu0KHDN48TExMbPd4cqbgM45wcf68wFhGRGmlpaZSWltb7WklJCenp6XTq1IkVK1Ywb968Vq0tLndT5+RAaiqMHBl0JSIi0lb07NmTsWPHMnToUDp27Ejv3r2/eW38+PE88sgjDBkyhMMOO4wxY8a0am3mnGvVL6yRnZ3tcnNzW+Szx4yBlBSYM6dFPl5ERPbD8uXLGTJkSNBltJr6ltfMFjjnsuvOG3e7qXftgoULdUmTiIjEjojC2MzGm9lKM1tjZlPqef0GM1tmZp+Z2ftmFtgFRbm5UFGh48UiIhI7Gg1jM0sEHgQmAIcD55nZ4XVm+wTIds4NB14B7o52oZGq6ezjmGOCqkBERKRpImkZjwbWOOfWOefKgReBSeEzOOdmOed2hp7OAzKjW2bkcnLgsMOgV6+gKhAREWmaSMK4H7Ah7HleaFpDLgPeru8FM5tsZrlmlltQUBB5lRFyzoexjheLiEgsieoJXGZ2IZAN3FPf6865x5xz2c657IyMjGh+NQCrVkFhoY4Xi4hIbIkkjDcC/cOeZ4am7cHMTgJuAiY653ZHp7ym0eAQIiISTV26dGmV74kkjOcDg8wsy8xSgHOBaeEzmNlI4FF8EOdHv8zI5ORAjx5w6KFBVSAiItJ0jfbA5ZyrNLNrgBlAIjDVObfUzG4Dcp1z0/C7pbsAfzc/MsOXzrmJLVh3vebO9WdRJ8Td1dMiInFmwfVQFOUxFNNHwKh9j0AxZcoU+vfvz9VXXw3ArbfeSlJSErNmzaKoqIiKigp++9vfMmnSpH1+TrRF1B2mc246ML3OtFvCHp8U5bqarLAQVqyAiy4KuhIREWmrzjnnHK6//vpvwvjll19mxowZXHvttXTt2pWtW7cyZswYJk6ciLXisH9x0zf1hx/6e528JSISAxppwbYuvkmxAAAF1ElEQVSUkSNHkp+fz6ZNmygoKCA9PZ0+ffrw05/+lDlz5pCQkMDGjRvZsmULffr0abW64iaMc3IgKQmOOiroSkREpC0766yzeOWVV9i8eTPnnHMOzz33HAUFBSxYsIDk5GQGDBhQ7/CJLSmuwnjkSOjUKehKRESkLTvnnHO44oor2Lp1K//+9795+eWXOeCAA0hOTmbWrFl88cUXrV5TXJzqVFEBH3+sS5pERKRxRxxxBKWlpfTr14++fftywQUXkJuby7Bhw3jmmWcYPHhwq9cUFy3jRYv8aE06XiwiIpFYvHjxN4979erFhzUnHtWxffv2VqknLlrGaWnw4x/DcccFXYmIiEjTxUXLePBgeOihoKsQERHZP3HRMhYRkdjgnAu6hFbR1OVUGIuISKtITU2lsLAw7gPZOUdhYSGpqakRvycudlOLiEjbl5mZSV5eHi0xhG5bk5qaSmZmZsTzK4xFRKRVJCcnk5WVFXQZbZJ2U4uIiARMYSwiIhIwhbGIiEjALKiz2sysAIhmB6C9gK1R/Ly2RMsWm7RssUnLFntiabkOds5l1J0YWBhHm5nlOueyg66jJWjZYpOWLTZp2WJPPCyXdlOLiIgETGEsIiISsHgK48eCLqAFadlik5YtNmnZYk/ML1fcHDMWERGJVfHUMhYREYlJCmMREZGAxUUYm9l4M1tpZmvMbErQ9USTma03s8VmtsjMcoOupznMbKqZ5ZvZkrBpPczsXTNbHbpPD7LG/dXAst1qZhtD626RmX0vyBr3h5n1N7NZZrbMzJaa2XWh6TG/3vaxbPGw3lLN7GMz+zS0bL8JTc8ys49C28qXzCwl6Fqbah/L9rSZfR623kYEXWtTxPwxYzNLBFYBJwN5wHzgPOfcskALixIzWw9kO+di5YL2BpnZOGA78Ixzbmho2t3A1865u0I/pNKdc78Mss790cCy3Qpsd87dG2RtzWFmfYG+zrmFZpYGLABOBy4hxtfbPpbtbGJ/vRnQ2Tm33cySgQ+A64AbgH845140s0eAT51zDwdZa1PtY9n+G3jTOfdKoAXup3hoGY8G1jjn1jnnyoEXgUkB1yT1cM7NAb6uM3kS8NfQ47/iN4Yxp4Fli3nOua+ccwtDj0uB5UA/4mC97WPZYp7ztoeeJoduDjgBqAmrWF1vDS1bTIuHMO4HbAh7nkec/IcKccA7ZrbAzCYHXUwL6O2c+yr0eDPQO8hiWsA1ZvZZaDd2zO3KDWdmA4CRwEfE2Xqrs2wQB+vNzBLNbBGQD7wLrAWKnXOVoVlidltZd9mcczXr7Y7QevujmXUIsMQmi4cwjnfHOeeOBCYAV4d2h8Yl54+ZxPwv3DAPAwOBEcBXwB+CLWf/mVkX4FXgeufctvDXYn291bNscbHenHNVzrkRQCZ+D+LggEuKmrrLZmZDgRvxy3gU0AOIqcMm8RDGG4H+Yc8zQ9PignNuY+g+H3gN/58qnmwJHburOYaXH3A9UeOc2xLaaFQDjxOj6y50XO5V4Dnn3D9Ck+NivdW3bPGy3mo454qBWcAxQHczSwq9FPPbyrBlGx867OCcc7uBp4ix9RYPYTwfGBQ6SzAFOBeYFnBNUWFmnUMnlmBmnYFTgCX7flfMmQZcHHp8MfB6gLVEVU1YhZxBDK670MkyTwLLnXP3hb0U8+utoWWLk/WWYWbdQ4874k9wXY4PrjNDs8Xqeqtv2VaE/Tg0/LHwmFpvMX82NUDo0oM/AYnAVOfcHQGXFBVm9i18axggCXg+lpfNzF4AjscPd7YF+DXwT+Bl4CD8kJpnO+di7kSoBpbtePyuTgesB64MO84aE8zsOOA/wGKgOjT5V/hjqzG93vaxbOcR++ttOP4ErUR8o+tl59xtoW3Ki/jduJ8AF4ZakjFjH8s2E8gADFgE/HfYiV5tXlyEsYiISCyLh93UIiIiMU1hLCIiEjCFsYiISMAUxiIiIgFTGIuIiARMYSwiIhIwhbGIiEjA/g8XsZXyw5LLggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WDKSTYSwUB1"
      },
      "source": [
        "##### 6o Πείραμα - Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Pojn305I9g",
        "outputId": "479f163f-5126-4cab-f197-e817c16c983d"
      },
      "source": [
        "x=[19,2,0,0.4,0.4,0.07,0]\r\n",
        "model6=create_model_vgg16(x)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 2 0 0.4 0.4 0.07 0\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6b020c67d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae278b610> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae25a7490> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae203ca90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae219e7d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae25a7890> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b020667d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b40247fd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b50197e10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae25a7790> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2768090> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2768b10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2761e90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae2783f90> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae27b91d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b02162750> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae279e9d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ae263d5d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ae2502650> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4CATOa5JO0",
        "outputId": "b1ae98a3-6233-4fed-d348-db3c9f551ab1"
      },
      "source": [
        "start = time.time()\r\n",
        "history6=model6.fit(train_32_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 10s 46ms/step - loss: 4.8609 - accuracy: 0.0049 - val_loss: 4.8128 - val_accuracy: 0.0055\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.7989 - accuracy: 0.0062 - val_loss: 4.7687 - val_accuracy: 0.0076\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.7593 - accuracy: 0.0070 - val_loss: 4.7342 - val_accuracy: 0.0101\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 4.7203 - accuracy: 0.0092 - val_loss: 4.7010 - val_accuracy: 0.0098\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.6988 - accuracy: 0.0100 - val_loss: 4.6707 - val_accuracy: 0.0119\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.6662 - accuracy: 0.0103 - val_loss: 4.6378 - val_accuracy: 0.0117\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 4.6301 - accuracy: 0.0136 - val_loss: 4.6069 - val_accuracy: 0.0142\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.6024 - accuracy: 0.0148 - val_loss: 4.5776 - val_accuracy: 0.0166\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.5677 - accuracy: 0.0174 - val_loss: 4.5455 - val_accuracy: 0.0177\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.5358 - accuracy: 0.0212 - val_loss: 4.5159 - val_accuracy: 0.0200\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.5088 - accuracy: 0.0260 - val_loss: 4.4865 - val_accuracy: 0.0233\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.4763 - accuracy: 0.0304 - val_loss: 4.4616 - val_accuracy: 0.0246\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 4.4521 - accuracy: 0.0296 - val_loss: 4.4329 - val_accuracy: 0.0260\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 6s 45ms/step - loss: 4.4204 - accuracy: 0.0321 - val_loss: 4.4085 - val_accuracy: 0.0280\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.4012 - accuracy: 0.0319 - val_loss: 4.3846 - val_accuracy: 0.0304\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.3664 - accuracy: 0.0343 - val_loss: 4.3568 - val_accuracy: 0.0345\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.3447 - accuracy: 0.0392 - val_loss: 4.3315 - val_accuracy: 0.0386\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.3155 - accuracy: 0.0423 - val_loss: 4.3034 - val_accuracy: 0.0431\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.2814 - accuracy: 0.0445 - val_loss: 4.2744 - val_accuracy: 0.0479\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.2580 - accuracy: 0.0492 - val_loss: 4.2442 - val_accuracy: 0.0547\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.2202 - accuracy: 0.0533 - val_loss: 4.2122 - val_accuracy: 0.0581\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.1966 - accuracy: 0.0569 - val_loss: 4.1795 - val_accuracy: 0.0602\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.1561 - accuracy: 0.0609 - val_loss: 4.1465 - val_accuracy: 0.0636\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.1183 - accuracy: 0.0652 - val_loss: 4.1090 - val_accuracy: 0.0687\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 4.0768 - accuracy: 0.0689 - val_loss: 4.0740 - val_accuracy: 0.0729\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.0317 - accuracy: 0.0787 - val_loss: 4.0326 - val_accuracy: 0.0786\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 4.0057 - accuracy: 0.0788 - val_loss: 3.9923 - val_accuracy: 0.0819\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.9548 - accuracy: 0.0838 - val_loss: 3.9459 - val_accuracy: 0.0889\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 3.8976 - accuracy: 0.0939 - val_loss: 3.9034 - val_accuracy: 0.0954\n",
            "Epoch 30/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.8583 - accuracy: 0.1000 - val_loss: 3.8510 - val_accuracy: 0.1027\n",
            "Epoch 31/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 3.8028 - accuracy: 0.1091 - val_loss: 3.8103 - val_accuracy: 0.1079\n",
            "Epoch 32/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.7634 - accuracy: 0.1109 - val_loss: 3.7620 - val_accuracy: 0.1138\n",
            "Epoch 33/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.7141 - accuracy: 0.1241 - val_loss: 3.7188 - val_accuracy: 0.1216\n",
            "Epoch 34/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 3.6645 - accuracy: 0.1298 - val_loss: 3.6700 - val_accuracy: 0.1250\n",
            "Epoch 35/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.6224 - accuracy: 0.1351 - val_loss: 3.6279 - val_accuracy: 0.1362\n",
            "Epoch 36/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.5589 - accuracy: 0.1441 - val_loss: 3.5864 - val_accuracy: 0.1396\n",
            "Epoch 37/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.5449 - accuracy: 0.1454 - val_loss: 3.5461 - val_accuracy: 0.1484\n",
            "Epoch 38/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.4879 - accuracy: 0.1588 - val_loss: 3.5022 - val_accuracy: 0.1532\n",
            "Epoch 39/40\n",
            "132/132 [==============================] - 6s 43ms/step - loss: 3.4484 - accuracy: 0.1643 - val_loss: 3.4668 - val_accuracy: 0.1606\n",
            "Epoch 40/40\n",
            "132/132 [==============================] - 6s 44ms/step - loss: 3.3989 - accuracy: 0.1713 - val_loss: 3.4272 - val_accuracy: 0.1667\n",
            "Χρόνος fit: 234.58835363388062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "H_RPuR3Z5Jgl",
        "outputId": "d2f07d6e-07d3-491c-e156-d3c8ddf93688"
      },
      "source": [
        "model6.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history6)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 23ms/step - loss: 3.3888 - accuracy: 0.1774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUVNlbEr5a-l"
      },
      "source": [
        "##### 7o Πείραμα - Μέγεθος Εικόνας"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnmmQrZs68Ev",
        "outputId": "733cf65b-6129-4b75-c599-50b97eeb0f05"
      },
      "source": [
        "x=[19,2,0,0.4,0.4,0.07,1]\r\n",
        "model7=create_model_vgg16(x)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 2 0 0.4 0.4 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6ab628fb90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab628fe10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab6287750> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ab629a5d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab6288450> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab642f550> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ab628fa10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab657bdd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab6287710> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab6288290> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ab6285910> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab629a2d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab63c4350> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab63a6cd0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ab629ab10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab63c4610> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab63aadd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6ab63aaa10> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6ab63b5890> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqjkwhj17Chd",
        "outputId": "587d8d66-782f-465b-97e0-a67bd4e424e6"
      },
      "source": [
        "start = time.time()\r\n",
        "history7=model7.fit(train_75_b256, epochs=40, batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_75_b256,validation_steps=24,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 38s 188ms/step - loss: 3.4559 - accuracy: 0.1988 - val_loss: 1.6673 - val_accuracy: 0.5352\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 1.3379 - accuracy: 0.6178 - val_loss: 1.3122 - val_accuracy: 0.6190\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.9170 - accuracy: 0.7255 - val_loss: 1.2288 - val_accuracy: 0.6497\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 23s 173ms/step - loss: 0.6411 - accuracy: 0.8076 - val_loss: 1.2289 - val_accuracy: 0.6670\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.4406 - accuracy: 0.8640 - val_loss: 1.2453 - val_accuracy: 0.6795\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.2724 - accuracy: 0.9177 - val_loss: 1.2812 - val_accuracy: 0.6790\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 23s 174ms/step - loss: 0.1846 - accuracy: 0.9470 - val_loss: 1.4364 - val_accuracy: 0.6735\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.1139 - accuracy: 0.9657 - val_loss: 1.5379 - val_accuracy: 0.6745\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0395 - accuracy: 0.9922 - val_loss: 1.6369 - val_accuracy: 0.7048\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 1.8093 - val_accuracy: 0.7043\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 1.9097 - val_accuracy: 0.6984\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 24s 180ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 1.9844 - val_accuracy: 0.7017\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.7031\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 23s 175ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0340 - val_accuracy: 0.7026\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 23s 176ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0733 - val_accuracy: 0.7013\n",
            "Χρόνος fit: 360.66873717308044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "Hua3dAue7Kad",
        "outputId": "2d7bade2-b99a-47c0-c03f-792e35f06390"
      },
      "source": [
        "model7.evaluate(test_75_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(history7)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 8s 78ms/step - loss: 1.9704 - accuracy: 0.7146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmZEcmdTwf3a"
      },
      "source": [
        "##### 8o Πείραμα - Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7KEkWlwFCPq",
        "outputId": "2e817f92-076d-4f05-b5aa-013e8d806e7b"
      },
      "source": [
        "x=[19,0,2,0.4,0.4,0.07,1]\r\n",
        "model9=create_model_vgg16(x)\r\n",
        "start = time.time()\r\n",
        "history9=model9.fit(train_75_b64, epochs=40, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_75_b64,validation_steps=94,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19 0 2 0.4 0.4 0.07 1\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6a5c4d9590> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4d1990> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c5a0650> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6a5c519dd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a68617c90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4f1a50> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6a5c500c90> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c511650> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c58d2d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4cc8d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6a5c4a8750> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4cc790> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c49ef10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4ac150> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6a5c4b79d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4a86d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4a0dd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6a5c4c50d0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6a5c450b90> True\n",
            "Epoch 1/40\n",
            "532/532 [==============================] - 38s 53ms/step - loss: 4.4294 - accuracy: 0.0287 - val_loss: 3.0025 - val_accuracy: 0.2399\n",
            "Epoch 2/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 2.9374 - accuracy: 0.2449 - val_loss: 1.9234 - val_accuracy: 0.4767\n",
            "Epoch 3/40\n",
            "532/532 [==============================] - 26s 50ms/step - loss: 1.9503 - accuracy: 0.4662 - val_loss: 1.4823 - val_accuracy: 0.5898\n",
            "Epoch 4/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 1.4300 - accuracy: 0.5956 - val_loss: 1.3369 - val_accuracy: 0.6217\n",
            "Epoch 5/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 1.1139 - accuracy: 0.6775 - val_loss: 1.2462 - val_accuracy: 0.6529\n",
            "Epoch 6/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.8703 - accuracy: 0.7410 - val_loss: 1.2348 - val_accuracy: 0.6719\n",
            "Epoch 7/40\n",
            "532/532 [==============================] - 26s 50ms/step - loss: 0.6846 - accuracy: 0.7934 - val_loss: 1.1679 - val_accuracy: 0.6905\n",
            "Epoch 8/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.5236 - accuracy: 0.8363 - val_loss: 1.1473 - val_accuracy: 0.7021\n",
            "Epoch 9/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.4071 - accuracy: 0.8723 - val_loss: 1.2413 - val_accuracy: 0.6950\n",
            "Epoch 10/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.3135 - accuracy: 0.9022 - val_loss: 1.2512 - val_accuracy: 0.7036\n",
            "Epoch 11/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.2375 - accuracy: 0.9248 - val_loss: 1.4284 - val_accuracy: 0.7006\n",
            "Epoch 12/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.1998 - accuracy: 0.9383 - val_loss: 1.3538 - val_accuracy: 0.7073\n",
            "Epoch 13/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.1588 - accuracy: 0.9501 - val_loss: 1.5258 - val_accuracy: 0.7000\n",
            "Epoch 14/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.1433 - accuracy: 0.9544 - val_loss: 1.5627 - val_accuracy: 0.7023\n",
            "Epoch 15/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.1098 - accuracy: 0.9665 - val_loss: 1.5473 - val_accuracy: 0.6970\n",
            "Epoch 16/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 1.4958 - val_accuracy: 0.7350\n",
            "Epoch 17/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 1.6439 - val_accuracy: 0.7372\n",
            "Epoch 18/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 1.7793 - val_accuracy: 0.7359\n",
            "Epoch 19/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 1.7453 - val_accuracy: 0.7339\n",
            "Epoch 20/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 1.8616 - val_accuracy: 0.7357\n",
            "Epoch 21/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 1.8573 - val_accuracy: 0.7407\n",
            "Epoch 22/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 1.9104 - val_accuracy: 0.7395\n",
            "Epoch 23/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 1.9202 - val_accuracy: 0.7412\n",
            "Epoch 24/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 1.9910 - val_accuracy: 0.7390\n",
            "Epoch 25/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 2.0285 - val_accuracy: 0.7387\n",
            "Epoch 26/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 2.0524 - val_accuracy: 0.7394\n",
            "Epoch 27/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 2.0503 - val_accuracy: 0.7415\n",
            "Epoch 28/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 2.0729 - val_accuracy: 0.7387\n",
            "Epoch 29/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.0876 - val_accuracy: 0.7379\n",
            "Epoch 30/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 2.0895 - val_accuracy: 0.7424\n",
            "Epoch 31/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.0886 - val_accuracy: 0.7404\n",
            "Epoch 32/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 2.1162 - val_accuracy: 0.7400\n",
            "Epoch 33/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.1361 - val_accuracy: 0.7400\n",
            "Epoch 34/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.1449 - val_accuracy: 0.7384\n",
            "Epoch 35/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.1642 - val_accuracy: 0.7395\n",
            "Epoch 36/40\n",
            "532/532 [==============================] - 26s 49ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.1937 - val_accuracy: 0.7405\n",
            "Χρόνος fit: 950.8452911376953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "lkI-SvJsI4UE",
        "outputId": "641aa17b-c213-49f1-c21e-55ee73a286fb"
      },
      "source": [
        "model9.evaluate(test_75_b64, verbose=1,steps=128)\r\n",
        "summarize_diagnostics(history9)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 7s 17ms/step - loss: 2.1741 - accuracy: 0.7462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA_skS9DCRhT"
      },
      "source": [
        "##### Συμπεράσματα\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oELCdfGFKWP7"
      },
      "source": [
        "Το τελικό μας πείραμα είναι και αυτό που πετυχαίνει τη βέλτιστη ακρίβεια στο Test set με 0.7462. Επίσης σημειώνεται ότι σημείωσε 951sec στην εκπαίδευση , χρόνος που αποτελεί τον τριπλάσιο τουλάχιστον από όλα τα υπόλοιπα πειράματα, όμως κατάφερε να φτάσει στην 36η εποχή , ενώ τα υπόλοιπα μοντέλα ολοκλήρωσαν λιγότερες εποχές λόγω του Early Stopping\r\n",
        "\r\n",
        "Οι τελική αρχιτεκτονική, δηλαδή οι υπερπαράμετροι που αποφασίσαμε είναι :\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Όλα τα στρώματα Trainable\r\n",
        "*   Adam Optimizer\r\n",
        "*   Όχι Data Augmentation\r\n",
        "*   Ναι learning Decay\r\n",
        "*   Mέγεθος εικόνας (75,75,3)\r\n",
        "*   2 Extra Dense Layers\r\n",
        "*   GlobalAvgPooling2D\r\n",
        "*   Starting value for learning rate 0.00001\r\n",
        "*   Batch Size = 64\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Σύμφωνα με τα πειράματα οι πιο σημαντικές υπερπαράμετροι είναι οι εξής :\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Αριθμός εκπαιδεύσιμων στρωμάτων\r\n",
        "*   Optimizer \r\n",
        "*   Learining Rate\r\n",
        "\r\n",
        "\r\n",
        "Παρατηρούμε σε όλα τα πειράματα οριακά να εμφανίζεται το φαινόμενο που γίνεται overfitting το μοντέλου στο train set. Αυτό φαίνεται από την καμπύλη του Validation Accuracy που αρχίζει και έχει διαφορά από το TrainSet Accuracy. Θα ήταν πιο ξεκάθαρο σημάδι αν η καμπύλη του Val Acc είχε πτωτική πορεία!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GBBBjkRKum4"
      },
      "source": [
        "## Model from \"scratch\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdyHWHziK1VG"
      },
      "source": [
        "Aρχικά θα ξεκινήσουμε σαν βάση με το μοντέλο που προσφέρεται στο demo notebook και με διάφορα πειράματα θα βελτιώσουμε την απόδοση του."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2XH2RiULIVW"
      },
      "source": [
        "### Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0tZMuKkLL-K"
      },
      "source": [
        "def init_simple_model(summary):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(64, activation='relu'))\r\n",
        "  model.add(layers.Dense(100, activation='softmax'))\r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\r\n",
        "  if summary: \r\n",
        "    model.summary()\r\n",
        "  return model"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DoHPE3FLQa8",
        "outputId": "3778a2ab-35e0-4ab3-9530-e9b4d3017de6"
      },
      "source": [
        "scratch=init_simple_model(True)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               6500      \n",
            "=================================================================\n",
            "Total params: 128,420\n",
            "Trainable params: 128,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wlMiOzJMMAb",
        "outputId": "2156da89-053a-4c8d-dbec-2bb59d1da97e"
      },
      "source": [
        "start = time.time()\r\n",
        "historys=scratch.fit(train_32_b256, epochs=40,batch_size=256,steps_per_epoch=132 ,verbose=1,validation_data=validation_32_b256,validation_steps=24,callbacks=[EarlyStopper])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 [==============================] - 9s 43ms/step - loss: 4.5713 - accuracy: 0.0146 - val_loss: 4.4139 - val_accuracy: 0.0291\n",
            "Epoch 2/40\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.3283 - accuracy: 0.0332 - val_loss: 4.1194 - val_accuracy: 0.0498\n",
            "Epoch 3/40\n",
            "132/132 [==============================] - 5s 41ms/step - loss: 4.0476 - accuracy: 0.0640 - val_loss: 3.9585 - val_accuracy: 0.0923\n",
            "Epoch 4/40\n",
            "132/132 [==============================] - 5s 40ms/step - loss: 3.9118 - accuracy: 0.0940 - val_loss: 3.8652 - val_accuracy: 0.0975\n",
            "Epoch 5/40\n",
            "132/132 [==============================] - 5s 39ms/step - loss: 3.7909 - accuracy: 0.1142 - val_loss: 3.7760 - val_accuracy: 0.1120\n",
            "Epoch 6/40\n",
            "132/132 [==============================] - 5s 36ms/step - loss: 3.7214 - accuracy: 0.1233 - val_loss: 3.7271 - val_accuracy: 0.1224\n",
            "Epoch 7/40\n",
            "132/132 [==============================] - 4s 32ms/step - loss: 3.6497 - accuracy: 0.1366 - val_loss: 3.6500 - val_accuracy: 0.1362\n",
            "Epoch 8/40\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 3.5978 - accuracy: 0.1455 - val_loss: 3.6044 - val_accuracy: 0.1424\n",
            "Epoch 9/40\n",
            "132/132 [==============================] - 3s 26ms/step - loss: 3.5340 - accuracy: 0.1567 - val_loss: 3.5742 - val_accuracy: 0.1496\n",
            "Epoch 10/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.4827 - accuracy: 0.1672 - val_loss: 3.5219 - val_accuracy: 0.1610\n",
            "Epoch 11/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.4655 - accuracy: 0.1693 - val_loss: 3.4907 - val_accuracy: 0.1613\n",
            "Epoch 12/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.4092 - accuracy: 0.1749 - val_loss: 3.4419 - val_accuracy: 0.1717\n",
            "Epoch 13/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.3863 - accuracy: 0.1852 - val_loss: 3.4277 - val_accuracy: 0.1756\n",
            "Epoch 14/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.3521 - accuracy: 0.1887 - val_loss: 3.3913 - val_accuracy: 0.1794\n",
            "Epoch 15/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.3289 - accuracy: 0.1909 - val_loss: 3.3708 - val_accuracy: 0.1828\n",
            "Epoch 16/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.2951 - accuracy: 0.1979 - val_loss: 3.3613 - val_accuracy: 0.1886\n",
            "Epoch 17/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.2589 - accuracy: 0.2062 - val_loss: 3.3103 - val_accuracy: 0.1955\n",
            "Epoch 18/40\n",
            "132/132 [==============================] - 3s 26ms/step - loss: 3.2438 - accuracy: 0.2046 - val_loss: 3.3035 - val_accuracy: 0.1911\n",
            "Epoch 19/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.2297 - accuracy: 0.2076 - val_loss: 3.2740 - val_accuracy: 0.2013\n",
            "Epoch 20/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.1927 - accuracy: 0.2135 - val_loss: 3.2561 - val_accuracy: 0.2030\n",
            "Epoch 21/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.1649 - accuracy: 0.2205 - val_loss: 3.2301 - val_accuracy: 0.2070\n",
            "Epoch 22/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.1389 - accuracy: 0.2283 - val_loss: 3.2166 - val_accuracy: 0.2142\n",
            "Epoch 23/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.1352 - accuracy: 0.2260 - val_loss: 3.1962 - val_accuracy: 0.2174\n",
            "Epoch 24/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0923 - accuracy: 0.2329 - val_loss: 3.1824 - val_accuracy: 0.2170\n",
            "Epoch 25/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0726 - accuracy: 0.2351 - val_loss: 3.1680 - val_accuracy: 0.2202\n",
            "Epoch 26/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0601 - accuracy: 0.2420 - val_loss: 3.1518 - val_accuracy: 0.2249\n",
            "Epoch 27/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0652 - accuracy: 0.2392 - val_loss: 3.1390 - val_accuracy: 0.2264\n",
            "Epoch 28/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0349 - accuracy: 0.2467 - val_loss: 3.1159 - val_accuracy: 0.2318\n",
            "Epoch 29/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0029 - accuracy: 0.2542 - val_loss: 3.1030 - val_accuracy: 0.2323\n",
            "Epoch 30/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 3.0108 - accuracy: 0.2508 - val_loss: 3.0973 - val_accuracy: 0.2349\n",
            "Epoch 31/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9671 - accuracy: 0.2647 - val_loss: 3.0759 - val_accuracy: 0.2399\n",
            "Epoch 32/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9672 - accuracy: 0.2641 - val_loss: 3.0792 - val_accuracy: 0.2381\n",
            "Epoch 33/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9483 - accuracy: 0.2622 - val_loss: 3.0751 - val_accuracy: 0.2425\n",
            "Epoch 34/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9442 - accuracy: 0.2669 - val_loss: 3.0581 - val_accuracy: 0.2471\n",
            "Epoch 35/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9227 - accuracy: 0.2710 - val_loss: 3.0450 - val_accuracy: 0.2441\n",
            "Epoch 36/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.9199 - accuracy: 0.2729 - val_loss: 3.0109 - val_accuracy: 0.2546\n",
            "Epoch 37/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.8900 - accuracy: 0.2766 - val_loss: 3.0217 - val_accuracy: 0.2476\n",
            "Epoch 38/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.8798 - accuracy: 0.2760 - val_loss: 3.0008 - val_accuracy: 0.2492\n",
            "Epoch 39/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.8713 - accuracy: 0.2804 - val_loss: 2.9935 - val_accuracy: 0.2536\n",
            "Epoch 40/40\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 2.8457 - accuracy: 0.2825 - val_loss: 2.9765 - val_accuracy: 0.2563\n",
            "Χρόνος fit: 148.74054765701294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "5SV7neh2MAE4",
        "outputId": "e6e63149-8ed7-4d91-e31a-4ffe075c2955"
      },
      "source": [
        "scratch.evaluate(test_32_b256, verbose=1,steps=32)\r\n",
        "summarize_diagnostics(historys)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 23ms/step - loss: 2.9666 - accuracy: 0.2642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oanhBgPxMjw3"
      },
      "source": [
        "### Learning Rate Decay/Dropout/Larger Input shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcO52hkMz9y"
      },
      "source": [
        "def simple_model_v1(summary):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(75,75,3)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Dropout(0.4))\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Dropout(0.4))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(128,activation='relu'))\r\n",
        "  model.add(layers.Dense(100, activation='softmax'))\r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\r\n",
        "  if summary: \r\n",
        "    model.summary()\r\n",
        "  return model"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxscOp3ANtQW",
        "outputId": "632c654c-9d6d-4fdd-9ef2-1f50c5730828"
      },
      "source": [
        "scratch1=simple_model_v1(True)\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "historys1=scratch1.fit(train_75_b64, epochs=40, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_75_b64,validation_steps=94,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 73, 73, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 128)       73856     \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               3686528   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 3,792,676\n",
            "Trainable params: 3,792,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "532/532 [==============================] - 25s 29ms/step - loss: 4.3808 - accuracy: 0.0318 - val_loss: 3.9063 - val_accuracy: 0.0886\n",
            "Epoch 2/40\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 3.7757 - accuracy: 0.1122 - val_loss: 3.6710 - val_accuracy: 0.1395\n",
            "Epoch 3/40\n",
            "532/532 [==============================] - 15s 28ms/step - loss: 3.5404 - accuracy: 0.1586 - val_loss: 3.5546 - val_accuracy: 0.1538\n",
            "Epoch 4/40\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.3650 - accuracy: 0.1919 - val_loss: 3.4227 - val_accuracy: 0.1755\n",
            "Epoch 5/40\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.2385 - accuracy: 0.2148 - val_loss: 3.3110 - val_accuracy: 0.1953\n",
            "Epoch 6/40\n",
            "532/532 [==============================] - 14s 27ms/step - loss: 3.1408 - accuracy: 0.2350 - val_loss: 3.2406 - val_accuracy: 0.2050\n",
            "Epoch 7/40\n",
            "532/532 [==============================] - 14s 26ms/step - loss: 3.0252 - accuracy: 0.2554 - val_loss: 3.2012 - val_accuracy: 0.2188\n",
            "Epoch 8/40\n",
            "532/532 [==============================] - 13s 25ms/step - loss: 2.9104 - accuracy: 0.2768 - val_loss: 3.1638 - val_accuracy: 0.2284\n",
            "Epoch 9/40\n",
            "532/532 [==============================] - 12s 22ms/step - loss: 2.8210 - accuracy: 0.2937 - val_loss: 3.0613 - val_accuracy: 0.2369\n",
            "Epoch 10/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.7329 - accuracy: 0.3081 - val_loss: 3.0233 - val_accuracy: 0.2505\n",
            "Epoch 11/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.6507 - accuracy: 0.3301 - val_loss: 3.0071 - val_accuracy: 0.2568\n",
            "Epoch 12/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.5914 - accuracy: 0.3379 - val_loss: 2.9628 - val_accuracy: 0.2598\n",
            "Epoch 13/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.5191 - accuracy: 0.3581 - val_loss: 2.9436 - val_accuracy: 0.2686\n",
            "Epoch 14/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 2.4439 - accuracy: 0.3738 - val_loss: 2.8886 - val_accuracy: 0.2819\n",
            "Epoch 15/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.3934 - accuracy: 0.3837 - val_loss: 2.8962 - val_accuracy: 0.2836\n",
            "Epoch 16/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.3266 - accuracy: 0.3991 - val_loss: 2.8718 - val_accuracy: 0.2936\n",
            "Epoch 17/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 2.2405 - accuracy: 0.4205 - val_loss: 2.9070 - val_accuracy: 0.2881\n",
            "Epoch 18/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 2.1829 - accuracy: 0.4315 - val_loss: 2.8422 - val_accuracy: 0.2959\n",
            "Epoch 19/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 2.1023 - accuracy: 0.4469 - val_loss: 2.8721 - val_accuracy: 0.2939\n",
            "Epoch 20/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 2.0474 - accuracy: 0.4633 - val_loss: 2.8158 - val_accuracy: 0.3073\n",
            "Epoch 21/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.9946 - accuracy: 0.4703 - val_loss: 2.8754 - val_accuracy: 0.3022\n",
            "Epoch 22/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.9331 - accuracy: 0.4918 - val_loss: 2.8443 - val_accuracy: 0.3117\n",
            "Epoch 23/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.8702 - accuracy: 0.5042 - val_loss: 2.8776 - val_accuracy: 0.3140\n",
            "Epoch 24/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.7880 - accuracy: 0.5260 - val_loss: 2.8788 - val_accuracy: 0.3143\n",
            "Epoch 25/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.7253 - accuracy: 0.5407 - val_loss: 2.9150 - val_accuracy: 0.3140\n",
            "Epoch 26/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.6731 - accuracy: 0.5540 - val_loss: 3.0001 - val_accuracy: 0.3027\n",
            "Epoch 27/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.5947 - accuracy: 0.5693 - val_loss: 2.9691 - val_accuracy: 0.3122\n",
            "Epoch 28/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.4539 - accuracy: 0.6087 - val_loss: 2.9569 - val_accuracy: 0.3203\n",
            "Epoch 29/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.3951 - accuracy: 0.6233 - val_loss: 2.9797 - val_accuracy: 0.3201\n",
            "Epoch 30/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.3833 - accuracy: 0.6296 - val_loss: 3.0146 - val_accuracy: 0.3201\n",
            "Epoch 31/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.3703 - accuracy: 0.6338 - val_loss: 3.0440 - val_accuracy: 0.3137\n",
            "Epoch 32/40\n",
            "532/532 [==============================] - 10s 19ms/step - loss: 1.3307 - accuracy: 0.6389 - val_loss: 3.0285 - val_accuracy: 0.3168\n",
            "Epoch 33/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.3233 - accuracy: 0.6440 - val_loss: 3.0454 - val_accuracy: 0.3155\n",
            "Epoch 34/40\n",
            "532/532 [==============================] - 10s 18ms/step - loss: 1.3168 - accuracy: 0.6467 - val_loss: 3.0428 - val_accuracy: 0.3173\n",
            "Χρόνος fit: 382.9011869430542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "G4bVkg5EQB0p",
        "outputId": "937d8918-00a6-4bb8-9d17-25e08e66d9be"
      },
      "source": [
        "scratch1.evaluate(test_75_b64, verbose=1,steps=128)\r\n",
        "summarize_diagnostics(historys1)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 7s 16ms/step - loss: 3.0328 - accuracy: 0.3259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqQsg0VDQSzn"
      },
      "source": [
        "### Batch Normalization/Smaller input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Y0uGg0QYVw"
      },
      "source": [
        "def simple_model_v2(summary):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32,32,3)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.BatchNormalization())\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(256,activation='relu'))\r\n",
        "  model.add(layers.Dense(100, activation='softmax'))\r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\r\n",
        "  if summary: \r\n",
        "    model.summary()\r\n",
        "  return model"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TWs1Ys_Qt47",
        "outputId": "c873c813-bb3f-4a1a-dc8a-763d798eeb20"
      },
      "source": [
        "scratch2=simple_model_v2(True)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 100)               25700     \n",
            "=================================================================\n",
            "Total params: 659,172\n",
            "Trainable params: 659,044\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhgDGloLR6Ek",
        "outputId": "24e43316-0dc1-4814-8b64-035a800be700"
      },
      "source": [
        "start = time.time()\r\n",
        "historys2=scratch2.fit(train_32_b64, epochs=40, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_32_b64,validation_steps=94,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "532/532 [==============================] - 10s 12ms/step - loss: 3.7819 - accuracy: 0.1109 - val_loss: 3.1583 - val_accuracy: 0.2475\n",
            "Epoch 2/40\n",
            "532/532 [==============================] - 7s 12ms/step - loss: 2.7267 - accuracy: 0.2980 - val_loss: 2.7054 - val_accuracy: 0.2990\n",
            "Epoch 3/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 2.2352 - accuracy: 0.4024 - val_loss: 2.6119 - val_accuracy: 0.3348\n",
            "Epoch 4/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.9607 - accuracy: 0.4604 - val_loss: 2.3795 - val_accuracy: 0.3802\n",
            "Epoch 5/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.6805 - accuracy: 0.5323 - val_loss: 2.5761 - val_accuracy: 0.3635\n",
            "Epoch 6/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.4575 - accuracy: 0.5842 - val_loss: 2.3894 - val_accuracy: 0.4044\n",
            "Epoch 7/40\n",
            "532/532 [==============================] - 5s 10ms/step - loss: 1.2327 - accuracy: 0.6403 - val_loss: 2.5505 - val_accuracy: 0.4054\n",
            "Epoch 8/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 1.0158 - accuracy: 0.7010 - val_loss: 2.6647 - val_accuracy: 0.3891\n",
            "Epoch 9/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.8569 - accuracy: 0.7410 - val_loss: 2.8675 - val_accuracy: 0.4006\n",
            "Epoch 10/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.4927 - accuracy: 0.8546 - val_loss: 2.8771 - val_accuracy: 0.4435\n",
            "Epoch 11/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.3175 - accuracy: 0.9143 - val_loss: 3.0336 - val_accuracy: 0.4455\n",
            "Epoch 12/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.2498 - accuracy: 0.9357 - val_loss: 3.1664 - val_accuracy: 0.4432\n",
            "Epoch 13/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.2028 - accuracy: 0.9512 - val_loss: 3.3883 - val_accuracy: 0.4390\n",
            "Epoch 14/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.1439 - accuracy: 0.9726 - val_loss: 3.3949 - val_accuracy: 0.4500\n",
            "Epoch 15/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.1235 - accuracy: 0.9775 - val_loss: 3.4763 - val_accuracy: 0.4493\n",
            "Epoch 16/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.1179 - accuracy: 0.9796 - val_loss: 3.5474 - val_accuracy: 0.4501\n",
            "Epoch 17/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.1055 - accuracy: 0.9836 - val_loss: 3.5927 - val_accuracy: 0.4506\n",
            "Epoch 18/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.0983 - accuracy: 0.9849 - val_loss: 3.6566 - val_accuracy: 0.4500\n",
            "Epoch 19/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.0918 - accuracy: 0.9867 - val_loss: 3.7246 - val_accuracy: 0.4458\n",
            "Epoch 20/40\n",
            "532/532 [==============================] - 5s 9ms/step - loss: 0.0843 - accuracy: 0.9895 - val_loss: 3.7359 - val_accuracy: 0.4488\n",
            "Epoch 21/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.0824 - accuracy: 0.9896 - val_loss: 3.7548 - val_accuracy: 0.4493\n",
            "Epoch 22/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.0752 - accuracy: 0.9920 - val_loss: 3.7605 - val_accuracy: 0.4483\n",
            "Epoch 23/40\n",
            "532/532 [==============================] - 4s 8ms/step - loss: 0.0771 - accuracy: 0.9911 - val_loss: 3.7668 - val_accuracy: 0.4491\n",
            "Χρόνος fit: 117.38656401634216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "CpiaWmAXXYzU",
        "outputId": "e7935ee6-efb5-4efa-aa29-3e6a6702af92"
      },
      "source": [
        "scratch2.evaluate(test_32_b64, verbose=1,steps=128)\r\n",
        "summarize_diagnostics(historys2)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 3s 7ms/step - loss: 3.6429 - accuracy: 0.4546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRFINxyyXqge"
      },
      "source": [
        "### Deeper Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xninobc-V634"
      },
      "source": [
        "def simple_model_v3(summary):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32,32,3)))\r\n",
        "  model.add(layers.BatchNormalization())\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(512, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(2024,activation='relu'))\r\n",
        "  model.add(layers.Dense(512,activation='relu'))\r\n",
        "  model.add(layers.Dense(100, activation='softmax'))\r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\r\n",
        "  if summary: \r\n",
        "    model.summary()\r\n",
        "  return model"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6F2AnigWQ70",
        "outputId": "5058189b-ab44-41f9-adb4-f416c2b5439e"
      },
      "source": [
        "scratch3=simple_model_v3(True)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 30, 30, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 2024)              4147176   \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 512)               1036800   \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 6,786,508\n",
            "Trainable params: 6,786,380\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwTFFXzrWeol",
        "outputId": "d1c86c01-8017-4fab-c117-73f5a50c60ed"
      },
      "source": [
        "start = time.time()\r\n",
        "historys3=scratch3.fit(train_32_b64, epochs=40, batch_size=64,steps_per_epoch=532 ,verbose=1,validation_data=validation_32_b64,validation_steps=94,callbacks=[EarlyStopper,reduce_lr])\r\n",
        "print(\"Χρόνος fit:\",time.time()-start)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "532/532 [==============================] - 10s 12ms/step - loss: 3.9573 - accuracy: 0.0780 - val_loss: 3.3119 - val_accuracy: 0.2121\n",
            "Epoch 2/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 2.9695 - accuracy: 0.2476 - val_loss: 2.7020 - val_accuracy: 0.3082\n",
            "Epoch 3/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 2.4206 - accuracy: 0.3612 - val_loss: 2.5150 - val_accuracy: 0.3514\n",
            "Epoch 4/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.9923 - accuracy: 0.4553 - val_loss: 2.3702 - val_accuracy: 0.3836\n",
            "Epoch 5/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.6438 - accuracy: 0.5342 - val_loss: 2.4224 - val_accuracy: 0.3961\n",
            "Epoch 6/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 1.2757 - accuracy: 0.6286 - val_loss: 2.5243 - val_accuracy: 0.4056\n",
            "Epoch 7/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.9646 - accuracy: 0.7136 - val_loss: 2.9194 - val_accuracy: 0.3948\n",
            "Epoch 8/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 0.6742 - accuracy: 0.7930 - val_loss: 3.0216 - val_accuracy: 0.3865\n",
            "Epoch 9/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.3034 - accuracy: 0.9112 - val_loss: 3.5089 - val_accuracy: 0.4437\n",
            "Epoch 10/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0811 - accuracy: 0.9812 - val_loss: 4.0670 - val_accuracy: 0.4397\n",
            "Epoch 11/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0378 - accuracy: 0.9933 - val_loss: 4.6211 - val_accuracy: 0.4402\n",
            "Epoch 12/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0183 - accuracy: 0.9979 - val_loss: 4.7091 - val_accuracy: 0.4458\n",
            "Epoch 13/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0142 - accuracy: 0.9984 - val_loss: 4.8598 - val_accuracy: 0.4466\n",
            "Epoch 14/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 5.0237 - val_accuracy: 0.4461\n",
            "Epoch 15/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 5.1237 - val_accuracy: 0.4478\n",
            "Epoch 16/40\n",
            "532/532 [==============================] - 5s 10ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 5.3562 - val_accuracy: 0.4473\n",
            "Epoch 17/40\n",
            "532/532 [==============================] - 5s 10ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 5.5010 - val_accuracy: 0.4458\n",
            "Epoch 18/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 5.5289 - val_accuracy: 0.4520\n",
            "Epoch 19/40\n",
            "532/532 [==============================] - 6s 11ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 5.5737 - val_accuracy: 0.4488\n",
            "Epoch 20/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 5.6215 - val_accuracy: 0.4496\n",
            "Epoch 21/40\n",
            "532/532 [==============================] - 5s 10ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 5.6258 - val_accuracy: 0.4506\n",
            "Epoch 22/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 5.6459 - val_accuracy: 0.4515\n",
            "Epoch 23/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 5.6521 - val_accuracy: 0.4513\n",
            "Epoch 24/40\n",
            "532/532 [==============================] - 6s 10ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 5.6615 - val_accuracy: 0.4508\n",
            "Χρόνος fit: 139.23400783538818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "qG8717FsXw3r",
        "outputId": "004e8bb3-f063-4da4-f078-3b105d49d706"
      },
      "source": [
        "scratch3.evaluate(test_32_b64, verbose=1,steps=128)\r\n",
        "summarize_diagnostics(historys3)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 3s 7ms/step - loss: 5.4728 - accuracy: 0.4596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnL8yOsvX-C5"
      },
      "source": [
        "### Συμπεράσματα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAo70j2nYB2s"
      },
      "source": [
        "Έπειτα από διάφορες δόκιμες η μέγιστη ακρίβεια που καταφέρνουμε είναι στο τελευταίο μοντέλο με TestSet Accuracy  = 0.4596 ενώ στο αρχικό μοντέλο επιτύχαμε TestSet Accuracy = 0.2642.\r\n",
        "\r\n",
        "Οι βασικές αλλαγές φαίνονται και στη δομή του κώδικα αλλά αναφορικά να πούμε ότι είναι το λίγο μεγαλύτερο βάθος του μοντέλου, η εισαγωγή στρώματος Batch Normalization και η προσαρμογή του Learning Rate. Στο τελευταίο πείραμα αλλάξαμε το patience από 3 σε 2 και παρατηρήσαμε ελάχιστα καλύτερα αποτελέσματα. Κρίσιμη ήταν και η επιλογή του input_size καθώς τείνει να εκπαιδεύεται καλύτερα για μικρότερα μεγέθη.\r\n",
        "\r\n",
        "Τέλος από τα διαγράμματα πάλι παρατηρούμε ότι το μοντέλο προσαρμόζεται αρκετά καλά στο train set, δίχως να έχει την ίδια επιτυχία στο validation set."
      ]
    }
  ]
}